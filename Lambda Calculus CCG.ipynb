{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk import Tree\n",
    "\n",
    "def parser(expression):\n",
    "    old = expression.replace(' ', '_').replace('>_(', '> (').replace(')_(', ') (').replace(')_)', ') )').replace(')_)', ') )').replace(' (', '(')\n",
    "    new = ''\n",
    "    flag = False\n",
    "    for x in range(0, len(old) - 1):        \n",
    "        if old[x] == '<':\n",
    "            flag = True\n",
    "        if old[x] == '>':\n",
    "            flag = False\n",
    "            \n",
    "        if flag == True:\n",
    "            if old[x] == '(':\n",
    "                new += '{'\n",
    "            elif old[x] == ')':\n",
    "                new += '}'\n",
    "            else:\n",
    "                new += old[x]\n",
    "        else:\n",
    "            new += old[x]\n",
    "    new += old[len(old)-1]\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "import json\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "dependency_parser = nlp.annotate\n",
    "\n",
    "def pos_tag(sentence):\n",
    "    result = dependency_parser(sentence, properties={\"outputFormat\": \"json\", \"annotators\": \"pos\"})['sentences'][0]['tokens']\n",
    "    res = []\n",
    "    for pos in result:\n",
    "        res.append(pos['pos'])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_pos_tag(exp, pos):\n",
    "    count = 0\n",
    "    res = ''\n",
    "    for x in range(0, len(exp)):\n",
    "        if exp[x] == 'S' and exp[x+1]==' ' and exp[x+2] == 'P':\n",
    "            res += 'S '\n",
    "            res += pos[count]\n",
    "            count += 1\n",
    "            x += 4\n",
    "        else:\n",
    "            res += exp[x]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction(exp):\n",
    "    cont = False\n",
    "    for x in exp:\n",
    "        if x == '{':\n",
    "            cont = True\n",
    "        elif x == '}':\n",
    "            cont = False\n",
    "            continue\n",
    "        if cont == True:\n",
    "            continue\n",
    "        if x == '/':\n",
    "            return '/'\n",
    "        elif x == '\\\\':\n",
    "            return '\\\\'\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_type_raising(tree):\n",
    "    tree_string = str(tree)\n",
    "    \n",
    "    # check type raising\n",
    "    exp = tree_string.split('_')[1]\n",
    "    pattern_1 = r'(.*?)\\\\(.*?){(.*?)/(.*?)}'\n",
    "    pattern_2 = r'(.*?)/(.*?){(.*?)\\\\(.*?)}'\n",
    "    \n",
    "    match = False\n",
    "    if re.search(pattern_1, exp):\n",
    "        match = True\n",
    "    elif re.search(pattern_2, exp):\n",
    "        match = True\n",
    "        \n",
    "    sub = []\n",
    "    for subtree in tree:\n",
    "        sub.append(subtree)\n",
    "    if len(sub) == 1 and match:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sem.logic import *\n",
    "\n",
    "read_expr = nltk.sem.Expression.fromstring\n",
    "\n",
    "def lambda_calculus(tree):\n",
    "    tree_string = str(tree)\n",
    "    \n",
    "    if tree_string[2] == 'L':\n",
    "        pos = tree_string.split('_')[3]\n",
    "        word = tree_string.split('_')[5]\n",
    "        \n",
    "        #                        #\n",
    "        # masukin rulenya disini #\n",
    "        #                        #\n",
    "        if 'NN' in pos :\n",
    "            return read_expr(r'(' + word + ')')\n",
    "        elif 'JJ' in pos:\n",
    "            return read_expr(r'(' + word + '_1)')\n",
    "        elif 'VB' in pos:\n",
    "            if '{S[dcl]\\\\NP}/{S[adj]\\\\NP}' in tree_string.split('_')[1]:\n",
    "                return read_expr(r'\\X.X')\n",
    "            else:\n",
    "                return read_expr(r'\\X.\\Y.' + word + '(X, Y)')\n",
    "        else:\n",
    "            return read_expr(r'\\X.X')\n",
    "    \n",
    "    # ini cuma masukin ke array \n",
    "    chunk = []\n",
    "    sub = []\n",
    "    for subtree in tree:\n",
    "        if type(subtree) == nltk.tree.Tree:\n",
    "            sub.append(subtree)\n",
    "            \n",
    "            # chunk temp array\n",
    "            subtree_str_array = str(subtree).split('_')\n",
    "            if subtree_str_array[0][2] == 'L':\n",
    "                if subtree_str_array[3] == 'NN':\n",
    "                    chunk.append(subtree_str_array[5])\n",
    "    \n",
    "    \n",
    "    # chunk noun phrase\n",
    "    if len(chunk) == 2:\n",
    "        chunk_str = '_'.join(chunk)\n",
    "        return read_expr(r'(' + chunk_str + ')')\n",
    "    \n",
    "    # error anak 1\n",
    "    if len(sub) == 1:            \n",
    "        return lambda_calculus(sub[0])\n",
    "                        \n",
    "    # urutan operasi lambda calculusnya    \n",
    "    first = sub[0]\n",
    "    second = sub[1]\n",
    "    \n",
    "    if is_type_raising(first):\n",
    "        if direction(str(first).split('_')[1]) == '/':\n",
    "            x = read_expr(r'\\F x.F(x, ' + str(lambda_calculus(first)) + ')')\n",
    "            y = lambda_calculus(second)\n",
    "            return ApplicationExpression(x, y).simplify()\n",
    "    \n",
    "    if is_type_raising(second):\n",
    "        if direction(str(second).split('_')[1]) == '/':\n",
    "            x = lambda_calculus(first)\n",
    "            y = read_expr(r'\\F x.F(x, ' + str(lambda_calculus(second)) + ')')\n",
    "            return ApplicationExpression(x, y).simplify()\n",
    "        \n",
    "    length_1 = len(str(sub[0]).split('_')[1].replace('\\\\', '/').split('/'))\n",
    "    length_2 = len(str(sub[1]).split('_')[1].replace('\\\\', '/').split('/'))\n",
    "    if length_2 > length_1:\n",
    "        first = sub[1]\n",
    "        second = sub[0]\n",
    "            \n",
    "    \n",
    "    # rekursi\n",
    "    return ApplicationExpression(lambda_calculus(first), lambda_calculus(second)).simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_res = '(<T S[dcl] 0 2> (<T NP 0 2> (<L NP[nb]/N POS POS the NP[nb]/N>) (<L N POS POS hotel N>) ) (<T S[dcl]\\\\NP 0 2> (<L (S[dcl]\\\\NP)/NP POS POS had (S[dcl]\\\\NP)/NP>) (<T NP 0 2> (<L NP[nb]/N POS POS an NP[nb]/N>) (<T N 0 2> (<L N/N POS POS exceptional N/N>) (<L N POS POS service N>) ) ) ) )'\n",
    "pos_tagged = insert_pos_tag(from_res, pos_tag('the hotel had a exceptional service'))\n",
    "\n",
    "hasil = parser(pos_tagged)\n",
    "\n",
    "from nltk import Tree\n",
    "tree = Tree.fromstring(hasil)\n",
    "# t.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ApplicationExpression had(exceptional_1(service),hotel)>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_calculus(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(str(tree).replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def glue_process(sent):\n",
    "    url = \"http://localhost:5000/ccgParsing\"\n",
    "    data = {\"sent\": sent}\n",
    "    r = requests.post(url, data=data)\n",
    "\n",
    "    res = r.json()\n",
    "    \n",
    "    from_res = res['tree']\n",
    "    pos_tagged = insert_pos_tag(from_res, pos_tag(data['sent']))\n",
    "\n",
    "    hasil = parser(pos_tagged)\n",
    "\n",
    "    tree = Tree.fromstring(hasil)\n",
    "#     print(str(tree).replace('_', ' '))\n",
    "    return lambda_calculus(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ApplicationExpression have(\\Y.say(satisfied_1(\\X.X),Y),\\X.X,month(\\Y.bought(canon_g3,Y),\\X.X))>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_process('I bought my canon g3 about a month ago and i have to say i am very satisfied')\n",
    "# glue_process('the hotel had an exceptional service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ApplicationExpression excellent_1(daily_1(\\X Y.served(X,Y),breakfast,restaurant))>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_process('the breakfast that the restaurant served daily was excellent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ApplicationExpression bites(john,dog)>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_process('the dog bites john')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = read_expr(r'(restaurant)')\n",
    "b = read_expr(r'((\\X.served(X)))')\n",
    "# ApplicationExpression(a, b).simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = read_expr(r'X')\n",
    "restaurant = read_expr(r'restaurant')\n",
    "\n",
    "second = read_expr(r'\\X.serve(X)')\n",
    "third = second(x, restaurant).simplify()\n",
    "z = read_expr(r'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = read_expr(r'\\X.' + str(third))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero = read_expr(r'\\F x.F(x, ' + 'res' + ')')\n",
    "\n",
    "# one = read_expr(r'\\x.\\y.serve(x, y)')\n",
    "# third = zero(one).simplify()\n",
    "# print(zero)\n",
    "# print(one)\n",
    "# print(third)\n",
    "# ApplicationExpression(third, read_expr(r'breakfast')).simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
