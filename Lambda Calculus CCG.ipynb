{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk import Tree\n",
    "\n",
    "def parser(expression):\n",
    "    old = expression.replace(' ', '_').replace('>_(', '> (').replace(')_(', ') (').replace(')_)', ') )').replace(')_)', ') )').replace(' (', '(')\n",
    "    new = ''\n",
    "    flag = False\n",
    "    for x in range(0, len(old) - 1):        \n",
    "        if old[x] == '<':\n",
    "            flag = True\n",
    "        if old[x] == '>':\n",
    "            flag = False\n",
    "            \n",
    "        if flag == True:\n",
    "            if old[x] == '(':\n",
    "                new += '{'\n",
    "            elif old[x] == ')':\n",
    "                new += '}'\n",
    "            else:\n",
    "                new += old[x]\n",
    "        else:\n",
    "            new += old[x]\n",
    "    new += old[len(old)-1]\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "import json\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "dependency_parser = nlp.annotate\n",
    "\n",
    "def pos_tag(sentence):\n",
    "    result = dependency_parser(sentence, properties={\"outputFormat\": \"json\", \"annotators\": \"pos\"})['sentences'][0]['tokens']\n",
    "    res = []\n",
    "    for pos in result:\n",
    "        res.append(pos['pos'])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_pos_tag(exp, pos):\n",
    "    count = 0\n",
    "    res = ''\n",
    "    for x in range(0, len(exp)):\n",
    "        if exp[x] == 'S' and exp[x+1]==' ' and exp[x+2] == 'P':\n",
    "            res += 'S '\n",
    "            res += pos[count]\n",
    "            count += 1\n",
    "            x += 4\n",
    "        else:\n",
    "            res += exp[x]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction(exp):\n",
    "    cont = False\n",
    "    for x in exp:\n",
    "        if x == '{':\n",
    "            cont = True\n",
    "        elif x == '}':\n",
    "            cont = False\n",
    "            continue\n",
    "        if cont == True:\n",
    "            continue\n",
    "        if x == '/':\n",
    "            return '/'\n",
    "        elif x == '\\\\':\n",
    "            return '\\\\'\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sem.logic import *\n",
    "\n",
    "read_expr = nltk.sem.Expression.fromstring\n",
    "\n",
    "def lambda_calculus(tree):\n",
    "    tree_string = str(tree)\n",
    "    \n",
    "    if tree_string[2] == 'L':\n",
    "        pos = tree_string.split('_')[3]\n",
    "        word = tree_string.split('_')[5]\n",
    "        \n",
    "        #                        #\n",
    "        # masukin rulenya disini #\n",
    "        #                        #\n",
    "        if pos == 'NN':\n",
    "            return read_expr(r'(' + word + ')')\n",
    "        elif pos == 'VBD':\n",
    "            return read_expr(r'\\X \\Y.' + word + '(X, Y)')\n",
    "        else:\n",
    "            return read_expr(r'\\X.X')\n",
    "    \n",
    "    # ini cuma masukin ke array \n",
    "    chunk = []\n",
    "    sub = []\n",
    "    for subtree in tree:\n",
    "        if type(subtree) == nltk.tree.Tree:\n",
    "            sub.append(subtree)\n",
    "            \n",
    "            # chunk temp array\n",
    "            subtree_str_array = str(subtree).split('_')\n",
    "            if subtree_str_array[0][2] == 'L':\n",
    "                if subtree_str_array[3] == 'NN':\n",
    "                    chunk.append(subtree_str_array[5])\n",
    "    \n",
    "    # chunk noun phrase\n",
    "    if len(chunk) == 2:\n",
    "        chunk_str = '_'.join(chunk)\n",
    "        return read_expr(r'(' + chunk_str + ')')\n",
    "    \n",
    "    # urutan operasi lambda calculusnya\n",
    "    first = sub[0]\n",
    "    second = sub[1]\n",
    "    notation = str(sub[1]).split('_')[1]\n",
    "    if direction(notation) == '\\\\':\n",
    "        first = sub[1]\n",
    "        second = sub[0]\n",
    "    \n",
    "    # rekursi\n",
    "    return ApplicationExpression(lambda_calculus(first), lambda_calculus(second)).simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_res = '(<T S[dcl] 0 2> (<T NP 0 2> (<L NP[nb]/N POS POS the NP[nb]/N>) (<L N POS POS hotel N>) ) (<T S[dcl]\\\\NP 0 2> (<L (S[dcl]\\\\NP)/NP POS POS had (S[dcl]\\\\NP)/NP>) (<T NP 0 2> (<L NP[nb]/N POS POS an NP[nb]/N>) (<T N 0 2> (<L N/N POS POS exceptional N/N>) (<L N POS POS service N>) ) ) ) )'\n",
    "pos_tagged = insert_pos_tag(from_res, pos_tag('the hotel had a exceptional service'))\n",
    "\n",
    "hasil = parser(pos_tagged)\n",
    "\n",
    "from nltk import Tree\n",
    "tree = Tree.fromstring(hasil)\n",
    "# t.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_calculus(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(str(tree).replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def glue_process(sent):\n",
    "    url = \"http://localhost:5000/ccgParsing\"\n",
    "    data = {\"sent\": sent}\n",
    "    r = requests.post(url, data=data)\n",
    "\n",
    "    res = r.json()\n",
    "    \n",
    "    from_res = res['tree']\n",
    "    pos_tagged = insert_pos_tag(from_res, pos_tag(data['sent']))\n",
    "\n",
    "    hasil = parser(pos_tagged)\n",
    "\n",
    "    tree = Tree.fromstring(hasil)\n",
    "    print(tree)\n",
    "    return lambda_calculus(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<T_S[dcl]_0_2>\n",
      "  (<T_S[dcl]_0_2>\n",
      "    (<L_NP_POS_PRP_POS_I_NP> )\n",
      "    (<T_S[dcl]\\NP_0_2>\n",
      "      (<T_S[dcl]\\NP_0_2>\n",
      "        (<L_{S[dcl]\\NP}/NP_POS_VBD_POS_bought_{S[dcl]\\NP}/NP> )\n",
      "        (<T_NP_0_2>\n",
      "          (<L_NP[nb]/N_POS_PRP$_POS_my_NP[nb]/N> )\n",
      "          (<T_N_0_2>\n",
      "            (<L_N/N_POS_NN_POS_canon_N/N> )\n",
      "            (<L_N_POS_NN_POS_g3_N> ))))\n",
      "      (<T_{S\\NP}\\{S\\NP}_0_2>\n",
      "        (<T_NP_0_2>\n",
      "          (<L_NP/NP_POS_IN_POS_about_NP/NP> )\n",
      "          (<T_NP_0_2>\n",
      "            (<L_NP[nb]/N_POS_DT_POS_a_NP[nb]/N> )\n",
      "            (<L_N_POS_NN_POS_month_N> )))\n",
      "        (<L_{{S\\NP}\\{S\\NP}}\\NP_POS_RB_POS_ago_{{S\\NP}\\{S\\NP}}\\NP> ))))\n",
      "  (<T_S[dcl]\\S[dcl]_0_2>\n",
      "    (<L_conj_POS_CC_POS_and_conj> )\n",
      "    (<T_S[dcl]_0_2>\n",
      "      (<L_NP_POS_FW_POS_i_NP> )\n",
      "      (<T_S[dcl]\\NP_0_2>\n",
      "        (<L_{S[dcl]\\NP}/{S[to]\\NP}_POS_VBP_POS_have_{S[dcl]\\NP}/{S[to]\\NP}>)\n",
      "        (<T_S[to]\\NP_0_2>\n",
      "          (<L_{S[to]\\NP}/{S[b]\\NP}_POS_TO_POS_to_{S[to]\\NP}/{S[b]\\NP}>)\n",
      "          (<T_S[b]\\NP_0_2>\n",
      "            (<L_{S[b]\\NP}/S[dcl]_POS_VB_POS_say_{S[b]\\NP}/S[dcl]> )\n",
      "            (<T_S[dcl]_0_2>\n",
      "              (<L_NP_POS_FW_POS_i_NP> )\n",
      "              (<T_S[dcl]\\NP_0_2>\n",
      "                (<L_{S[dcl]\\NP}/{S[adj]\\NP}_POS_VBP_POS_am_{S[dcl]\\NP}/{S[adj]\\NP}>)\n",
      "                (<T_S[adj]\\NP_0_2>\n",
      "                  (<L_{S[adj]\\NP}/{S[adj]\\NP}_POS_RB_POS_very_{S[adj]\\NP}/{S[adj]\\NP}>)\n",
      "                  (<L_S[adj]\\NP_POS_JJ_POS_satisfied_S[adj]\\NP> ))))))))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ApplicationExpression month(\\Y.bought(canon_g3,Y),\\X.X)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_process('I bought my canon g3 about a month ago and i have to say i am very satisfied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
