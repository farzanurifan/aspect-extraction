{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools, nltk, string \n",
    "import requests, re\n",
    "from nltk import Tree\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "import os\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_single_df = pd.read_csv('../restaurant-single-categories.csv')\n",
    "res_multiple_df = pd.read_csv('../restaurant-multiple-categories.csv')\n",
    "\n",
    "lap_single_df = pd.read_csv('../laptop-single-categories.csv')\n",
    "lap_multiple_df = pd.read_csv('../laptop-multiple-categories.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewID</th>\n",
       "      <th>sentenceID</th>\n",
       "      <th>review</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:0</td>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>RESTAURANT#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:1</td>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:2</td>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:3</td>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:4</td>\n",
       "      <td>After all that, they complained to me about th...</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewID sentenceID                                             review  \\\n",
       "0   1004293  1004293:0  Judging from previous posts this used to be a ...   \n",
       "1   1004293  1004293:1  We, there were four of us, arrived at noon - t...   \n",
       "2   1004293  1004293:2  They never brought us complimentary noodles, i...   \n",
       "3   1004293  1004293:3  The food was lousy - too sweet or too salty an...   \n",
       "4   1004293  1004293:4  After all that, they complained to me about th...   \n",
       "\n",
       "             category  polarity  \n",
       "0  RESTAURANT#GENERAL  negative  \n",
       "1     SERVICE#GENERAL  negative  \n",
       "2     SERVICE#GENERAL  negative  \n",
       "3        FOOD#QUALITY  negative  \n",
       "4     SERVICE#GENERAL  negative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_single_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restaurant categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FOOD#QUALITY                383\n",
       "RESTAURANT#GENERAL          245\n",
       "SERVICE#GENERAL             183\n",
       "AMBIENCE#GENERAL            111\n",
       "FOOD#STYLE_OPTIONS           51\n",
       "RESTAURANT#MISCELLANEOUS     50\n",
       "RESTAURANT#PRICES            24\n",
       "DRINKS#QUALITY               21\n",
       "FOOD#PRICES                  17\n",
       "DRINKS#STYLE_OPTIONS         16\n",
       "LOCATION#GENERAL             16\n",
       "DRINKS#PRICES                 3\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_single_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_lexicon = []\n",
    "negative_lexicon = []\n",
    "\n",
    "def read_lexicon():\n",
    "    global positive_lexicon;\n",
    "    global negative_lexicon;\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('../opinion-lexicon-English/') , 'positive-words.txt'), 'r') as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "         \n",
    "        positive_lexicon = file.readlines()\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('../opinion-lexicon-English/') , 'negative-words.txt'), 'r', encoding = \"ISO-8859-1\") as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "        \n",
    "        negative_lexicon = file.readlines()\n",
    "        \n",
    "    positive_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), positive_lexicon))\n",
    "    negative_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), negative_lexicon))\n",
    "\n",
    "read_lexicon()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "linking_verbs_be = [\n",
    "    'be',\n",
    "    'is',\n",
    "    'are',\n",
    "    'am',\n",
    "    'was',\n",
    "    'were',\n",
    "    'can be',\n",
    "    'could be',\n",
    "    'will be',\n",
    "    'would be',\n",
    "    'shall be',\n",
    "    'should be',\n",
    "    'may be',\n",
    "    'might be',\n",
    "    'must be',\n",
    "    'has been',\n",
    "    'have been',\n",
    "    'had been'\n",
    "];\n",
    "\n",
    "linking_verbs_v = [\n",
    "    'feel',\n",
    "    'look',\n",
    "    'smell',\n",
    "    'sound',\n",
    "    'taste',\n",
    "    'act',\n",
    "    'appear',\n",
    "    'become',\n",
    "    'get',\n",
    "    'grow',\n",
    "    'prove',\n",
    "    'remain', \n",
    "    'seem',\n",
    "    'stay',\n",
    "    'turn'\n",
    "];\n",
    "\n",
    "def check_is_noun(pos):\n",
    "    return re.match('NN.*', pos)\n",
    "\n",
    "def check_is_verb(pos):\n",
    "    return re.match('VB.*', pos)\n",
    "\n",
    "def check_is_adjective(pos):\n",
    "    return re.match('JJ.*', pos)\n",
    "\n",
    "def check_is_adverb(pos):\n",
    "    return re.match('RB.*', pos)\n",
    "\n",
    "def lemmatize(word, pos):\n",
    "    tag = wn.NOUN\n",
    "    if(check_is_noun(pos)):\n",
    "        tag = wn.NOUN\n",
    "    elif(check_is_verb(pos)):\n",
    "        tag = wn.VERB\n",
    "    elif(check_is_adjective(pos)):\n",
    "        tag = wn.ADJ\n",
    "    elif(check_is_adverb(pos)):\n",
    "        tag = wn.ADV\n",
    "            \n",
    "    lemma = wordnet_lemmatizer.lemmatize(word, tag)\n",
    "    return lemma\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    #res = re.sub(' +', ' ', re.sub(r'[^\\w\\s]','',sentence.replace(\"'m\", \"am\").replace(\"n't\", \"not\").replace(\"'s\", ''))).lower()\n",
    "    res = re.sub(r'[^\\w\\s]','', sentence.replace(\"'m\", \"am\").replace(\"n't\", \"not\").replace(\"'s\", '')).lower()\n",
    "    #checking for parallel clauses\n",
    "    #splitted = res.split(', and but')\n",
    "    res = re.sub(r'\\b\\d+\\b', 'NUM', res)\n",
    "    return res\n",
    "\n",
    "def pos_tag(sentence):\n",
    "    url = \"http://localhost:9000\"\n",
    "    request_params = {\"annotators\": \"pos\"}\n",
    "    r = requests.post(url, data=sentence, params=request_params, timeout=120)\n",
    "    try:\n",
    "        results = r.json()['sentences'][0]['tokens']\n",
    "        res = []\n",
    "        for pos in results:\n",
    "            res.append((pos['word'], pos['pos']))\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "def get_tregex(text, tregex):\n",
    "    url = \"http://localhost:9000/tregex\"\n",
    "    request_params = {\"pattern\": tregex}\n",
    "    r = requests.post(url, data=text, params=request_params, timeout=120)\n",
    "    try:\n",
    "        return r.json()['sentences'][0]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def sentence_from_tree(s):\n",
    "    pattern = r'(?<= )[a-zA-Z].*?(?=\\))'\n",
    "    replaced = s.replace('\\r\\n', '')\n",
    "    res = ' '.join(re.findall(pattern, replaced))\n",
    "    return res\n",
    "        \n",
    "def sentence_type(clauses):\n",
    "    IC = 0\n",
    "    DC = 0\n",
    "    for clause in clauses:\n",
    "        if(clause[1] == 'IC'):\n",
    "            IC += 1\n",
    "        elif(clause[1] == 'DC'):\n",
    "            DC += 1\n",
    "\n",
    "    if IC == 1 and DC == 0:\n",
    "        return 'simple_sentence'\n",
    "    elif IC >= 2 and DC == 0:\n",
    "        return 'compound_sentence'\n",
    "    elif IC ==1 and DC >= 1:\n",
    "        return 'complex_sentence'\n",
    "    elif IC > 1 and DC >= 1:\n",
    "        return 'compound_complex_sentence'\n",
    "    else:\n",
    "        return 'phrase'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phrase extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrases(sentence):\n",
    "    np_tree = get_tregex(sentence, 'NP < NN | < NNS')\n",
    "    np_temp = []\n",
    "    \n",
    "    if np_tree:\n",
    "        for x in range(0, len(np_tree)):\n",
    "            phrase = \" \".join(Tree.fromstring(np_tree[str(x)]['match']).leaves())\n",
    "            if not any(phrase in s for s in np_temp):\n",
    "                np_temp.append(phrase)\n",
    "     \n",
    "    advp_tree = get_tregex(sentence, 'ADVP')\n",
    "    advp_temp = []\n",
    "    \n",
    "    if advp_tree:\n",
    "         for x in range(0, len(advp_tree)):\n",
    "            phrase = \" \".join(Tree.fromstring(advp_tree[str(x)]['match']).leaves())\n",
    "            if not any(phrase in s for s in advp_temp):\n",
    "                advp_temp.append(phrase)\n",
    "     \n",
    "        \n",
    "    adjp_tree = get_tregex(sentence, 'ADJP')\n",
    "    adjp_temp = []\n",
    "    \n",
    "    if adjp_tree:\n",
    "        for x in range(0, len(adjp_tree)):\n",
    "            phrase = \" \".join(Tree.fromstring(adjp_tree[str(x)]['match']).leaves())\n",
    "            if not any(phrase in s for s in adjp_temp):\n",
    "                adjp_temp.append(phrase)\n",
    "    \n",
    "    pp_tree = get_tregex(sentence, 'PP')\n",
    "    pp_temp = []\n",
    "    \n",
    "    if pp_tree:\n",
    "        for x in range(0, len(pp_tree)):\n",
    "            phrase = \" \".join(Tree.fromstring(pp_tree[str(x)]['match']).leaves())\n",
    "            if not any(phrase in s for s in pp_temp):\n",
    "                pp_temp.append(phrase)\n",
    "    \n",
    "    sent_tagged = pos_tag(sentence)\n",
    "    chunking = []\n",
    "    \n",
    "    finish = False\n",
    "    index = 0\n",
    "    concat_word = ''\n",
    "    concat_pos = ''\n",
    "    while not finish:\n",
    "        word_tagged = sent_tagged[index]\n",
    "        concat_word = (concat_word + ' ' + word_tagged[0]).strip()\n",
    "        concat_pos = (concat_pos + ' ' + word_tagged[1]).strip()\n",
    "        \n",
    "        if not check_is_verb(word_tagged[1]) and not word_tagged[1] == 'MD':\n",
    "            if concat_word in np_temp:\n",
    "                chunking.append((concat_word.strip(), 'NP', concat_pos))\n",
    "                concat_word = ''\n",
    "                concat_pos = ''\n",
    "           \n",
    "            if concat_word in pp_temp:\n",
    "                chunking.append((concat_word.strip(), 'PP', concat_pos))\n",
    "                concat_word = ''\n",
    "                concat_pos = ''\n",
    "                \n",
    "            if concat_word in adjp_temp:\n",
    "                chunking.append((concat_word.strip(), 'ADJP', concat_pos))\n",
    "                concat_word = ''\n",
    "                concat_pos = ''\n",
    "            \n",
    "            if concat_word in advp_temp:\n",
    "                chunking.append((concat_word.strip(), 'ADVP', concat_pos))\n",
    "                concat_word = ''\n",
    "                concat_pos = ''\n",
    "                \n",
    "            if word_tagged[1] == 'PRP' or word_tagged[1] == 'FW' and len(concat_word.split()) == 1:\n",
    "                chunking.append((concat_word.strip(), word_tagged[1], concat_pos))\n",
    "                concat_word = ''\n",
    "                concat_pos = ''\n",
    "                \n",
    "        else:\n",
    "            if len(concat_word.split()) == 1:\n",
    "                next_word = sent_tagged[index + 1] if index + 1 < len(sent_tagged) else ('.', 'END')\n",
    "                next_next_word = sent_tagged[index + 2] if index + 2 < len(sent_tagged) else ('.', 'END')\n",
    "                if (check_is_verb(next_word[1]) and check_is_verb(next_next_word[1])) or (check_is_verb(next_next_word[1]) and next_word[1] == 'TO'):\n",
    "                    chunking.append( (concat_word + ' ' + next_word[0] + ' ' + next_next_word[0], 'VP', \n",
    "                                     concat_pos + \" \" + next_word[1] + ' ' + next_next_word[1]) )\n",
    "                    concat_word = ''\n",
    "                    concat_pos = ''\n",
    "                    index += 2\n",
    "                elif check_is_verb(next_word[1]) or next_word[1] == 'RP':\n",
    "                    chunking.append( (concat_word + ' ' + next_word[0], 'VP', concat_pos + ' ' + next_word[1]))\n",
    "                    concat_word = ''\n",
    "                    concat_pos = ''\n",
    "                    index += 1\n",
    "                else:\n",
    "                    chunking.append((concat_word.strip(), 'VP', concat_pos))\n",
    "                    concat_word = ''\n",
    "                    concat_pos = ''\n",
    "        \n",
    "        index += 1\n",
    "       \n",
    "        if index >= len(sent_tagged):\n",
    "            if concat_word != '' and concat_word != '.':\n",
    "                fail_words = concat_word.split()\n",
    "                index = index - len(fail_words)\n",
    "                index = index + 1 if sent_tagged[index][0].strip() != fail_words[0].strip() else index\n",
    "                chunking.append((sent_tagged[index][0], sent_tagged[index][1], sent_tagged[index][1]))\n",
    "                concat_word = ''\n",
    "                concat_pos = ''\n",
    "                index += 1\n",
    "            \n",
    "            if index >= len(sent_tagged):\n",
    "                finish = True \n",
    "\n",
    "    return chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get clause function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clauses(sentence):\n",
    "    temp = []\n",
    "    clauses = []\n",
    "    \n",
    "    res_all_clauses = get_tregex(sentence, 'S < (NP $ VP)') \n",
    "    res_sbar_clause = get_tregex(sentence, 'SBAR < S')\n",
    "    #filter clauses with dependency clauses\n",
    "    for x in range(0, len(res_all_clauses)):\n",
    "        s = sentence_from_tree(res_all_clauses[str(x)]['match'])\n",
    "        ic = True    \n",
    "        for y in range(0, len(res_sbar_clause)):\n",
    "            sbar = sentence_from_tree(res_sbar_clause[str(y)]['match'])            \n",
    "            if sbar in s and sbar != s:\n",
    "                s = s.replace(sbar, '')\n",
    "                if(len(res_sbar_clause) == 1 and sbar != ''):\n",
    "                    temp.append([sbar.strip(), 'DC'])\n",
    "            elif s in sbar and sbar != '':\n",
    "                ic = False\n",
    "                temp.append( [sbar.strip(), 'DC'])\n",
    "        if ic:\n",
    "            temp.append( [s.strip(), 'IC'] )\n",
    "\n",
    "    #overwrite sentence that already exist in list\n",
    "    len_clause = len(temp)\n",
    "    for x in range(0, len_clause):\n",
    "        for y in range(x + 1, len_clause):\n",
    "            temp[x][0] = temp[x][0].replace(temp[y][0], '').strip()\n",
    "        \n",
    "        temp[x][0] = re.sub(r\"  \", \" \", temp[x][0])\n",
    "        if(temp[x][0] != ''):\n",
    "            clauses.append( tuple(temp[x]) )\n",
    "    #sorted by index sentence\n",
    "    \n",
    "    if(len(clauses) == 0):\n",
    "        clauses.append((sentence, 'Phrase'))\n",
    "    \n",
    "    return sorted(clauses, key=lambda clause: 999 if sentence.find(clause[0]) == -1 else sentence.find(clause[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aspect extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    " def aspect_extraction(r):\n",
    "    clauses = get_clauses(r)\n",
    "    stype = sentence_type(clauses)\n",
    "    candidate_aspect_per_sentence = []\n",
    "    candidate_opinion_per_sentence = []\n",
    "    for c,t in clauses:\n",
    "        candidate_aspect_per_clause = []\n",
    "        candidate_opinion_per_clause = []\n",
    "            \n",
    "        if stype == 'phrase':\n",
    "            c_tagged = pos_tag(c)\n",
    "            \n",
    "            #Find all noun and append to aspect term\n",
    "            #for opinion find adjective, verb, and adverb and append to opinion term\n",
    "            for word, pos in c_tagged:\n",
    "                if check_is_noun(pos):\n",
    "                    candidate_aspect_per_clause.append(lemmatize(word, pos))\n",
    "                elif (check_is_verb(pos) or check_is_adverb(pos) or check_is_adjective(pos)) and (word in positive_lexicon or word in negative_lexicon):\n",
    "                    candidate_opinion_per_clause.append(lemmatize(word, pos))\n",
    "        else:\n",
    "            phrases = get_phrases(c)\n",
    "                \n",
    "            is_finish = False;\n",
    "            index_word = 0\n",
    "            while not is_finish:\n",
    "                phrase = phrases[index_word]\n",
    "                next_phrase = phrases[index_word + 1] if (index_word + 1) != len(phrases) else ('.', 'END', '.')\n",
    "                #checking verb\n",
    "                   \n",
    "                if phrase[1] == 'VP':\n",
    "                    #aspect always in independet clause:\n",
    "                    if t == 'IC':\n",
    "                        if phrase[0] in linking_verbs_be or (phrase[0] in linking_verbs_v and next_phrase[1] != 'NP'):\n",
    "                            print(phrase, 'linking verb', c, phrases)\n",
    "\n",
    "                            #linking verb condition\n",
    "                            #find aspect in subject\n",
    "                            for i in range(0, index_word):\n",
    "                                p = phrases[i]\n",
    "                                if p[1] == 'NP':\n",
    "                                    if p[1] not in stopWords:\n",
    "                                        candidate_aspect_per_clause.append(p[0])\n",
    "                        else:\n",
    "                            #action verb\n",
    "                            print(phrase, 'action verb', c, phrases)\n",
    "\n",
    "                            #checking verb is opinion or not\n",
    "                            if phrase[0] not in stopWords and (phrase[0] in positive_lexicon or phrase[0] in negative_lexicon):\n",
    "                                candidate_opinion_per_clause.append(lemmatize(phrase[0], 'VB'))\n",
    "\n",
    "                            #find aspect in object\n",
    "                            for i in range(index_word+1, len(phrases)):\n",
    "                                p = phrases[i]\n",
    "                                if p[1] == 'NP':\n",
    "                                    if p[1] not in stopWords:\n",
    "                                        candidate_aspect_per_clause.append(p[0])\n",
    "                   \n",
    "                            #if subject preposition find aspect in preposition\n",
    "                            if len(candidate_aspect) == 0:\n",
    "                                #find in pp after verb\n",
    "                                for i in range(index_word+1, len(phrases)):\n",
    "                                    p = phrases[i]\n",
    "                                    words = nltk.word_tokenize(p[0])\n",
    "                                    word_taggeds = nltk.word_tokenize(p[2])\n",
    "\n",
    "                                    if p[1] == 'PP':\n",
    "                                        for i,w in enumerate(words):\n",
    "                                            if w not in stopWords and check_is_noun(word_taggeds[i]):\n",
    "                                                candidate_aspect_per_clause.append(lemmatize(w, word_taggeds[i]))\n",
    "\n",
    "                                #find in pp before verb\n",
    "                                for i in range(0, index_word):\n",
    "                                    p = phrases[i]\n",
    "                                    words = nltk.word_tokenize(p[0])\n",
    "                                    word_taggeds = nltk.word_tokenize(p[2])\n",
    "\n",
    "                                    if p[1] == 'PP':\n",
    "                                        for i,w in enumerate(words):\n",
    "                                            if w not in stopWords and check_is_noun(word_taggeds[i]):\n",
    "                                                candidate_aspect_per_clause.append(lemmatize(w, word_taggeds[i]))\n",
    "\n",
    "                    #find opinion both in IC and DC\n",
    "                    for i in range(index_word+1, len(phrases)):\n",
    "                        p = phrases[i]\n",
    "                        words = nltk.word_tokenize(p[0])\n",
    "                        word_taggeds = nltk.word_tokenize(p[2])\n",
    "\n",
    "                        #check opinion in adjective\n",
    "                        if p[1] == 'ADJP' or p[1] == 'JJ':\n",
    "                            for i,w in enumerate(words):\n",
    "                                if w not in stopWords:\n",
    "                                    candidate_opinion_per_clause.append(lemmatize(w, word_taggeds[i]))          \n",
    "                        #check opinion in adverb\n",
    "                        elif p[1] == 'ADVP' or p[1] == 'RB':\n",
    "                            for i,w in enumerate(words):\n",
    "                                if w not in stopWords and (w in positive_lexicon or w in negative_lexicon):\n",
    "                                    candidate_opinion_per_clause.append(lemmatize(w, word_taggeds[i])) \n",
    "                        elif p[1] == 'PP':\n",
    "                            for i,w in enumerate(words):\n",
    "                                if w not in stopWords and (w in positive_lexicon or w in negative_lexicon):\n",
    "                                    candidate_opinion_per_clause.append(lemmatize(w, word_taggeds[i]))\n",
    "                        elif p[1] == 'VP':\n",
    "                            for i,w in enumerate(words):\n",
    "                                if w not in stopWords and (w in positive_lexicon or w in negative_lexicon):\n",
    "                                    candidate_opinion_per_clause.append(lemmatize(w, word_taggeds[i]))\n",
    "                        elif p[1] == 'NP':\n",
    "                            for i,w in enumerate(words):\n",
    "                                if w not in stopWords and (w in positive_lexicon or w in negative_lexicon):\n",
    "                                    candidate_opinion_per_clause.append(lemmatize(w, word_taggeds[i]))\n",
    "                                elif w not in stopWords and check_is_noun(word_taggeds[i]):\n",
    "                                    candidate_aspect_per_clause.append(lemmatize(w, word_taggeds[i]))\n",
    "                        \n",
    "                    is_finish = True\n",
    "                else:\n",
    "                    index_word += 1\n",
    "                    if index_word >= len(phrases):\n",
    "                        is_finish = True\n",
    "        if len(candidate_aspect_per_clause) > 0 or len(candidate_opinion_per_clause) > 0:\n",
    "            candidate_aspect_per_sentence.append(candidate_aspect_per_clause)\n",
    "            candidate_opinion_per_sentence.append(candidate_opinion_per_clause)\n",
    "            \n",
    "    return candidate_aspect_per_sentence, candidate_opinion_per_sentence\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessed sentence and append to new coloum df\n",
    "arr = []\n",
    "for r in res_single_df['review']:\n",
    "    preprocessed_sent = preprocessing(r)\n",
    "  \n",
    "    arr.append(preprocessed_sent)\n",
    "    \n",
    "preprocess_sent_series = pd.Series(arr)\n",
    "res_single_df['preprocessed_sentence'] = preprocess_sent_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aspect and opinion extraction using grammartical rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('were imposing', 'VP', 'VBD VBG') action verb like we were imposing on them [('like we', 'PRP', 'IN PRP'), ('were imposing', 'VP', 'VBD VBG'), ('on them', 'PP', 'IN PRP'), ('', 'PRP', '')]\n",
      "('arrived', 'VP', 'VBD') action verb we arrived [('we', 'PRP', 'PRP'), ('arrived', 'VP', 'VBD')]\n",
      "('was', 'VP', 'VBD') linking verb at noon the place was empty and the staff acted and they were very rude [('at noon', 'PP', 'IN NN'), ('the place', 'NP', 'DT NN'), ('was', 'VP', 'VBD'), ('empty', 'ADJP', 'JJ'), ('and the staff acted and they', 'PRP', 'CC DT NN VBD CC PRP'), ('were', 'VP', 'VBD'), ('very rude', 'ADJP', 'RB JJ')]\n",
      "('were imposing', 'VP', 'VBD VBG') action verb at noon the place was empty and the staff acted like we were imposing on them and they were very rude [('at noon the place was empty and the staff acted like we', 'PRP', 'IN NN DT NN VBD JJ CC DT NN VBD IN PRP'), ('were imposing', 'VP', 'VBD VBG'), ('on them', 'PP', 'IN PRP'), ('', 'PRP', ''), ('and they', 'PRP', 'CC PRP'), ('were', 'VP', 'VBD'), ('very rude', 'ADJP', 'RB JJ')]\n",
      "('ignored repeated', 'VP', 'VBN VBD') action verb complimentary noodles ignored repeated requests for sugar [('complimentary noodles', 'NP', 'JJ NNS'), ('ignored repeated', 'VP', 'VBN VBD'), ('requests', 'NP', 'NNS'), ('for sugar', 'PP', 'IN NN')]\n",
      "('brought', 'VP', 'VBD') action verb they never brought us and threw our dishes on the table [('they', 'PRP', 'PRP'), ('never', 'ADVP', 'RB'), ('brought', 'VP', 'VBD'), ('us', 'PRP', 'PRP'), ('and', 'CC', 'CC'), ('threw', 'VP', 'VBD'), ('our dishes', 'NP', 'PRP$ NNS'), ('on the table', 'PP', 'IN DT NN')]\n",
      "('was', 'VP', 'VBD') linking verb the food was lousy too sweet or too salty and the portions tiny [('the food', 'NP', 'DT NN'), ('was', 'VP', 'VBD'), ('lousy', 'JJ', 'JJ'), ('too sweet or too salty', 'ADJP', 'RB JJ CC RB JJ'), ('and', 'CC', 'CC'), ('the portions', 'NP', 'DT NNS'), ('tiny', 'ADJP', 'JJ')]\n",
      "('is', 'VP', 'VBZ') linking verb saul is the best restaurant on smith street and in brooklyn [('saul', 'NP', 'NN'), ('is', 'VP', 'VBZ'), ('the best restaurant', 'NP', 'DT JJS NN'), ('on smith street and in brooklyn', 'PP', 'IN NN NN CC IN NN')]\n",
      "('is', 'VP', 'VBZ') linking verb the duck confit is always amazing [('the duck confit', 'NP', 'DT NN NN'), ('is', 'VP', 'VBZ'), ('always', 'ADVP', 'RB'), ('amazing', 'ADJP', 'JJ')]\n",
      "('gras', 'VP', 'VBZ') action verb the foie gras [('the foie', 'NP', 'DT NN'), ('gras', 'VP', 'VBZ')]\n",
      "('was', 'VP', 'VBD') linking verb terrine with figs was out of this world [('terrine', 'NP', 'NN'), ('with figs', 'PP', 'IN NNS'), ('was', 'VP', 'VBD'), ('out', 'ADVP', 'IN'), ('of this world', 'PP', 'IN DT NN')]\n",
      "('is', 'VP', 'VBZ') linking verb the wine list is interesting and has many good values [('the wine list', 'NP', 'DT NN NN'), ('is', 'VP', 'VBZ'), ('interesting', 'ADJP', 'JJ'), ('and', 'CC', 'CC'), ('has', 'VP', 'VBZ'), ('many good values', 'NP', 'JJ JJ NNS')]\n",
      "('can', 'VP', 'MD') action verb for the price you can not eat this well in manhattan [('for the price', 'PP', 'IN DT NN'), ('you', 'PRP', 'PRP'), ('can', 'VP', 'MD'), ('not', 'RB', 'RB'), ('eat', 'VP', 'VB'), ('this', 'DT', 'DT'), ('well', 'ADVP', 'RB'), ('in manhattan', 'PP', 'IN NN')]\n",
      "('was', 'VP', 'VBD') linking verb i was very disappointed with this restaurant [('i', 'LS', 'LS'), ('was', 'VP', 'VBD'), ('very disappointed', 'ADJP', 'RB JJ'), ('with this restaurant', 'PP', 'IN DT NN')]\n",
      "('asked', 'VP', 'VBD') action verb ive asked [('ive', 'JJ', 'JJ'), ('asked', 'VP', 'VBD')]\n",
      "('wrapped', 'VP', 'VBD') action verb a cart attendant for a lotus leaf wrapped rice and she replied back rice and just walked away [('a cart attendant', 'NP', 'DT NN NN'), ('for a lotus leaf', 'PP', 'IN DT NN NN'), ('wrapped', 'VP', 'VBD'), ('rice', 'NP', 'NN'), ('and she', 'PRP', 'CC PRP'), ('replied', 'VP', 'VBD'), ('back', 'RB', 'RB'), ('rice', 'NP', 'NN'), ('and', 'CC', 'CC'), ('just', 'ADVP', 'RB'), ('walked', 'VP', 'VBD'), ('away', 'ADVP', 'RB')]\n",
      "('was', 'VP', 'VBD') linking verb food was okay nothing great [('food', 'NP', 'NN'), ('was', 'VP', 'VBD'), ('okay nothing great', 'ADJP', 'JJ NN JJ')]\n",
      "('was', 'VP', 'VBD') linking verb pork shu mai was more than usually greasy [('pork shu mai', 'NP', 'NN NN NN'), ('was', 'VP', 'VBD'), ('more than', 'ADVP', 'JJR IN'), ('usually', 'RB', 'RB'), ('greasy', 'JJ', 'JJ')]\n",
      "('was', 'VP', 'VBD') linking verb chow fun was dry and had to share a table with loud and rude family [('chow fun', 'NP', 'NN NN'), ('was', 'VP', 'VBD'), ('dry', 'ADJP', 'JJ'), ('and', 'CC', 'CC'), ('had to share', 'VP', 'VBD TO VB'), ('a table', 'NP', 'DT NN'), ('with loud and rude family', 'PP', 'IN JJ CC JJ NN')]\n",
      "('will', 'VP', 'MD') action verb iwe will never go back to this place again [('iwe', 'NP', 'NN'), ('will', 'VP', 'MD'), ('never', 'ADVP', 'RB'), ('go', 'VP', 'VB'), ('back to this place', 'ADVP', 'RB TO DT NN'), ('again', 'ADVP', 'RB')]\n",
      "('was', 'VP', 'VBD') linking verb service was divine oysters [('service', 'NP', 'NN'), ('was', 'VP', 'VBD'), ('divine oysters', 'NP', 'JJ NNS')]\n",
      "('come', 'VP', 'VBP') action verb as they come [('as they', 'PRP', 'IN PRP'), ('come', 'VP', 'VBP')]\n",
      "('be beat', 'VP', 'VB VBN') action verb where a sensual and the price canot be beat [('where', 'WRB', 'WRB'), ('a sensual and the price canot', 'NP', 'DT JJ CC DT NN NN'), ('be beat', 'VP', 'VB VBN')]\n",
      "('canot go', 'VP', 'VBP VB') action verb you canot go wrong here [('you', 'PRP', 'PRP'), ('canot go', 'VP', 'VBP VB'), ('wrong', 'ADJP', 'JJ'), ('here', 'ADVP', 'RB')]\n",
      "('is', 'VP', 'VBZ') linking verb the service is excellent the decor cool [('the service', 'NP', 'DT NN'), ('is', 'VP', 'VBZ'), ('excellent', 'ADJP', 'JJ'), ('the decor cool', 'NP', 'DT NN NN')]\n",
      "('is', 'VP', 'VBZ') linking verb everything is always cooked to perfection and understated [('everything', 'NP', 'NN'), ('is', 'VP', 'VBZ'), ('always', 'ADVP', 'RB'), ('cooked', 'VP', 'VBN'), ('to perfection', 'PP', 'TO NN'), ('and', 'CC', 'CC'), ('understated', 'VP', 'VBD')]\n",
      "('had', 'VP', 'VBD') action verb i had the duck breast special on my last visit [('i', 'LS', 'LS'), ('had', 'VP', 'VBD'), ('the duck breast special', 'NP', 'DT NN NN JJ'), ('on my last visit', 'PP', 'IN PRP$ JJ NN')]\n",
      "('was', 'VP', 'VBD') linking verb it was incredible [('it', 'PRP', 'PRP'), ('was', 'VP', 'VBD'), ('incredible', 'ADJP', 'JJ')]\n",
      "('is', 'VP', 'VBZ') linking verb the food is very averagethe [('the food', 'NP', 'DT NN'), ('is', 'VP', 'VBZ'), ('very averagethe', 'ADJP', 'RB JJ')]\n",
      "('is', 'VP', 'VBZ') linking verb thai fusion stuff is a bit too sweet [('thai fusion stuff', 'NP', 'JJ NN NN'), ('is', 'VP', 'VBZ'), ('a bit', 'NP', 'DT NN'), ('too', 'RB', 'RB'), ('sweet', 'JJ', 'JJ')]\n",
      "('is', 'VP', 'VBZ') linking verb thai fusion stuff is a bit too sweet [('thai fusion stuff', 'NP', 'JJ NN NN'), ('is', 'VP', 'VBZ'), ('a bit', 'NP', 'DT NN'), ('too', 'RB', 'RB'), ('sweet', 'JJ', 'JJ')]\n",
      "('serve', 'VP', 'VBP') action verb they serve [('they', 'PRP', 'PRP'), ('serve', 'VP', 'VBP')]\n",
      "('is', 'VP', 'VBZ') linking verb every thing is too sweet here [('every thing', 'NP', 'DT NN'), ('is', 'VP', 'VBZ'), ('too sweet', 'ADJP', 'RB JJ'), ('here', 'ADVP', 'RB')]\n",
      "('enjoyed', 'VP', 'VBN') action verb i moderately enjoyed [('i', 'LS', 'LS'), ('moderately', 'ADVP', 'RB'), ('enjoyed', 'VP', 'VBN')]\n",
      "('was', 'VP', 'VBD') linking verb the only thing was their grilled chicken special with edamame puree [('the only thing', 'NP', 'DT JJ NN'), ('was', 'VP', 'VBD'), ('their grilled chicken', 'NP', 'PRP$ JJ NN'), ('special', 'JJ', 'JJ'), ('with edamame puree', 'PP', 'IN NN NN')]\n",
      "('had', 'VP', 'VBD') action verb i had never had edamame pureed before [('i', 'LS', 'LS'), ('had', 'VP', 'VBD'), ('never', 'ADVP', 'RB'), ('had', 'VP', 'VBN'), ('edamame pureed', 'NP', 'NN NN'), ('before', 'PP', 'IN')]\n",
      "('was', 'VP', 'VBD') linking verb it was innovative and tasty couldve [('it', 'PRP', 'PRP'), ('was', 'VP', 'VBD'), ('innovative and tasty', 'ADJP', 'JJ CC JJ'), ('couldve', 'NN', 'NN')]\n",
      "('thought used', 'VP', 'VBN VBN') action verb but i thought used a bit more salt [('but', 'CC', 'CC'), ('i', 'FW', 'FW'), ('thought used', 'VP', 'VBN VBN'), ('a bit', 'NP', 'DT NN'), ('more', 'RBR', 'RBR'), ('salt', 'NP', 'NN')]\n",
      "('need to clean', 'VP', 'VBP TO VB') action verb night thobut they really need to clean that vent in the ceilingits quite unappetizing and kills your effort to make this place look sleek [('night', 'NP', 'NN'), ('thobut they', 'PRP', 'IN PRP'), ('really', 'ADVP', 'RB'), ('need to clean', 'VP', 'VBP TO VB'), ('that', 'IN', 'IN'), ('vent', 'VP', 'VB'), ('in the ceilingits quite unappetizing', 'PP', 'IN DT NNS RB JJ'), ('and', 'CC', 'CC'), ('kills', 'VP', 'VBZ'), ('your effort to make this place look sleek', 'NP', 'PRP$ NN TO VB DT NN NN JJ')]\n",
      "('is', 'VP', 'VBZ') linking verb the decor is and modern [('the decor', 'NP', 'DT NN'), ('is', 'VP', 'VBZ'), ('and', 'CC', 'CC'), ('modern', 'JJ', 'JJ')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('was', 'VP', 'VBD') linking verb their sake list was extensive [('their sake list', 'NP', 'PRP$ NN NN'), ('was', 'VP', 'VBD'), ('extensive', 'ADJP', 'JJ')]\n",
      "('were looking', 'VP', 'VBD VBG') action verb but we were looking for purple haze which wasnot listed but made for us upon request [('but we', 'PRP', 'CC PRP'), ('were looking', 'VP', 'VBD VBG'), ('for purple haze which wasnot listed but made for us', 'PRP', 'IN JJ NN WDT VBP VBN CC VBN IN PRP'), ('upon', 'IN', 'IN'), ('request', 'NP', 'NN')]\n",
      "('was', 'VP', 'VBD') linking verb the spicy tuna roll was unusually good [('the spicy tuna roll', 'NP', 'DT NN NN NN'), ('was', 'VP', 'VBD'), ('unusually good', 'ADJP', 'RB JJ')]\n",
      "('was', 'VP', 'VBD') linking verb the rock shrimp tempura was awesome great appetizer to share [('the rock shrimp tempura', 'NP', 'DT NN NN NN'), ('was', 'VP', 'VBD'), ('awesome great appetizer', 'NP', 'JJ JJ NN'), ('to share', 'PP', 'TO NN')]\n",
      "('went', 'VP', 'VBD') action verb we went around NUM on a friday and [('we', 'PRP', 'PRP'), ('went', 'VP', 'VBD'), ('around NUM', 'PP', 'IN NNP'), ('on a friday', 'PP', 'IN DT NNP'), ('and', 'ADVP', 'CC')]\n",
      "('had died', 'VP', 'VBD VBN') action verb it had died down a bit by then [('it', 'PRP', 'PRP'), ('had died', 'VP', 'VBD VBN'), ('down', 'RP', 'RP'), ('a bit', 'NP', 'DT NN'), ('by then', 'PP', 'IN RB')]\n",
      "('was', 'VP', 'VBD') linking verb so the service was great [('so', 'IN', 'IN'), ('the service', 'NP', 'DT NN'), ('was', 'VP', 'VBD'), ('great', 'ADJP', 'JJ')]\n",
      "('love', 'VP', 'VBP') action verb we love th pink pony [('we', 'PRP', 'PRP'), ('love', 'VP', 'VBP'), ('th pink pony', 'NP', 'DT JJ NN')]\n",
      "('relaxed', 'VP', 'VBD') action verb ambiance relaxed and stylish [('ambiance', 'NP', 'NN'), ('relaxed', 'VP', 'VBD'), ('and', 'CC', 'CC'), ('stylish', 'JJ', 'JJ')]\n",
      "('have to try', 'VP', 'VBP TO VB') action verb you have to try it to believe it [('you', 'PRP', 'PRP'), ('have to try', 'VP', 'VBP TO VB'), ('it', 'PRP', 'PRP'), ('to believe it', 'PRP', 'TO VB PRP')]\n",
      "('is', 'VP', 'VBZ') linking verb the food is decent [('the food', 'NP', 'DT NN'), ('is', 'VP', 'VBZ'), ('decent', 'ADJP', 'JJ')]\n",
      "('intimidate', 'VP', 'VB') action verb a waiter intimidate me [('a waiter', 'NP', 'DT NN'), ('intimidate', 'VP', 'VB'), ('me', 'PRP', 'PRP')]\n",
      "('make', 'VP', 'VBP') action verb ie make [('ie', 'FW', 'FW'), ('make', 'VP', 'VBP')]\n",
      "('feel', 'VP', 'VBP') linking verb me feel bad asking for trivialities like water or the check [('me', 'PRP', 'PRP'), ('feel', 'VP', 'VBP'), ('bad asking for trivialities like water or the check', 'ADJP', 'JJ VBG IN NNS IN NN CC DT NN')]\n",
      "('walked', 'VP', 'VBN') action verb the last time i walked by it looked pretty empty hmmm [('the last time', 'NP', 'DT JJ NN'), ('i', 'FW', 'FW'), ('walked', 'VP', 'VBN'), ('by it', 'PP', 'IN PRP'), ('', 'PRP', ''), ('looked', 'VP', 'VBD'), ('pretty empty', 'ADJP', 'RB JJ'), ('hmmm', 'NN', 'NN')]\n",
      "('has got', 'VP', 'VBZ VBN') action verb this place has got to be the best japanese restaurant in the new york area [('this place', 'NP', 'DT NN'), ('has got', 'VP', 'VBZ VBN'), ('to', 'TO', 'TO'), ('be', 'VP', 'VB'), ('the best japanese restaurant', 'NP', 'DT JJS JJ NN'), ('in the new york area', 'PP', 'IN DT JJ NN NN')]\n",
      "('had', 'VP', 'VBD') action verb i had a great experience [('i', 'LS', 'LS'), ('had', 'VP', 'VBD'), ('a great experience', 'NP', 'DT JJ NN')]\n",
      "('is', 'VP', 'VBZ') linking verb food is great [('food', 'NP', 'NN'), ('is', 'VP', 'VBZ'), ('great', 'ADJP', 'JJ')]\n",
      "('is', 'VP', 'VBZ') linking verb service is top notch [('service', 'NP', 'NN'), ('is', 'VP', 'VBZ'), ('top notch', 'NP', 'JJ NN')]\n",
      "('have been going', 'VP', 'VBP VBN VBG') action verb i have been going back again and again [('i', 'LS', 'LS'), ('have been going', 'VP', 'VBP VBN VBG'), ('back again and again', 'ADVP', 'RB RB CC RB')]\n",
      "('melted', 'VP', 'VBD') action verb it melted in my little mouth and the perfect consistencynot too fishy creamy and slightly buttery [('it', 'PRP', 'PRP'), ('melted', 'VP', 'VBD'), ('in my little mouth and the perfect consistencynot too fishy creamy and slightly buttery', 'PP', 'IN PRP$ JJ NN CC DT JJ NN RB JJ JJ CC RB JJ')]\n",
      "('seemed', 'VP', 'VBD') action verb the sushi seemed pretty fresh and was adequately proportioned [('the sushi', 'NP', 'DT NN'), ('seemed', 'VP', 'VBD'), ('pretty fresh', 'ADJP', 'RB JJ'), ('and', 'CC', 'CC'), ('was', 'VP', 'VBD'), ('adequately', 'ADVP', 'RB'), ('proportioned', 'VP', 'VBN')]\n",
      "('was', 'VP', 'VBD') linking verb the rice to fish ration was also goodthey didnot [('the rice', 'NP', 'DT NN'), ('to fish ration', 'PP', 'TO NN NN'), ('was', 'VP', 'VBD'), ('also', 'ADVP', 'RB'), ('goodthey didnot', 'NP', 'JJ NN')]\n",
      "('try to overpack', 'VP', 'VB TO VB') action verb try to overpack the rice [('try to overpack', 'VP', 'VB TO VB'), ('the rice', 'NP', 'DT NN')]\n",
      "('took', 'VP', 'VBD') action verb we took advanatage of the half price sushi deal on saturday [('we', 'PRP', 'PRP'), ('took', 'VP', 'VBD'), ('advanatage', 'NP', 'NN'), ('of the half price sushi deal', 'PP', 'IN DT NN NN NN NN'), ('on saturday', 'PP', 'IN NNP')]\n",
      "('was', 'VP', 'VBD') linking verb so it was well worth it [('so it', 'PRP', 'IN PRP'), ('was', 'VP', 'VBD'), ('well', 'ADVP', 'RB'), ('worth it', 'PP', 'JJ PRP'), ('', 'PRP', '')]\n",
      "('could be', 'VP', 'MD VB') linking verb surprisingly nothing could be further from the truth [('surprisingly nothing', 'NP', 'RB NN'), ('could be', 'VP', 'MD VB'), ('further', 'ADVP', 'RB'), ('from the truth', 'PP', 'IN DT NN')]\n",
      "('attracted', 'VP', 'VBD') action verb in the evening this place attracted a well dressed with it ny crowd [('in the evening', 'PP', 'IN DT NN'), ('this place', 'NP', 'DT NN'), ('attracted', 'VP', 'VBD'), ('a well dressed with it', 'PRP', 'DT RB VBN IN PRP'), ('ny', 'NN', 'NN'), ('crowd', 'NN', 'NN')]\n",
      "('was', 'VP', 'VBD') linking verb the food was well prepared and the service impecable [('the food', 'NP', 'DT NN'), ('was', 'VP', 'VBD'), ('well prepared', 'ADJP', 'RB JJ'), ('and', 'CC', 'CC'), ('the service impecable', 'NP', 'DT NN NN')]\n",
      "('is', 'VP', 'VBZ') linking verb the prix fixe menu is worth [('the prix fixe menu', 'NP', 'DT NN NN NN'), ('is', 'VP', 'VBZ'), ('worth', 'ADJP', 'JJ')]\n",
      "('get', 'VP', 'VBP') linking verb every penny and you get more than enough both in quantity and quality [('every penny', 'NP', 'DT NN'), ('and you', 'PRP', 'CC PRP'), ('get', 'VP', 'VBP'), ('more than', 'ADVP', 'JJR IN'), ('enough', 'JJ', 'JJ'), ('both in quantity and quality', 'PP', 'CC IN NN CC NN')]\n",
      "('is', 'VP', 'VBZ') linking verb it is terrific [('it', 'PRP', 'PRP'), ('is', 'VP', 'VBZ'), ('terrific', 'ADJP', 'JJ')]\n",
      "('is', 'VP', 'VBZ') linking verb as is the value [('as', 'RB', 'RB'), ('is', 'VP', 'VBZ'), ('the value', 'NP', 'DT NN')]\n",
      "('refilled', 'VP', 'VBN') action verb NUM and there is much tasty food all of it fresh and continually refilled [('NUM and there is much tasty food all of it', 'PRP', 'NNP CC EX VBZ JJ JJ NN DT IN PRP'), ('fresh', 'ADJP', 'JJ'), ('and', 'CC', 'CC'), ('continually', 'ADVP', 'RB'), ('refilled', 'VP', 'VBN')]\n",
      "('am', 'VP', 'VBP') linking verb i am not a vegetarian [('i', 'LS', 'LS'), ('am', 'VP', 'VBP'), ('not', 'RB', 'RB'), ('a', 'DT', 'DT'), ('vegetarian', 'JJ', 'JJ')]\n",
      "('were', 'VP', 'VBD') linking verb but almost all the dishes were great [('but', 'CC', 'CC'), ('almost all the dishes', 'NP', 'RB PDT DT NNS'), ('were', 'VP', 'VBD'), ('great', 'ADJP', 'JJ')]\n",
      "('is', 'VP', 'VBZ') linking verb the food here is rather good but only [('the food', 'NP', 'DT NN'), ('here', 'ADVP', 'RB'), ('is', 'VP', 'VBZ'), ('rather good', 'ADJP', 'RB JJ'), ('but', 'CC', 'CC'), ('only', 'ADVP', 'RB')]\n",
      "('like to wait', 'VP', 'VBP TO VB') action verb if you like to wait for it [('if you', 'PRP', 'IN PRP'), ('like to wait', 'VP', 'VBP TO VB'), ('for it', 'PP', 'IN PRP'), ('', 'PRP', '')]\n",
      "('is', 'VP', 'VBZ') linking verb the kitchen however is almost always slow [('the kitchen', 'NP', 'DT NN'), ('however', 'ADVP', 'RB'), ('is', 'VP', 'VBZ'), ('almost', 'RB', 'RB'), ('always', 'RB', 'RB'), ('slow', 'VP', 'VB')]\n",
      "('is', 'VP', 'VBZ') linking verb the ambience is pretty and nice for conversation [('the ambience', 'NP', 'DT NN'), ('is', 'VP', 'VBZ'), ('pretty', 'ADVP', 'RB'), ('and', 'CC', 'CC'), ('nice for conversation', 'ADJP', 'JJ IN NN')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('have', 'VP', 'VBP') action verb you have yourself the beginning of a great evening [('you', 'PRP', 'PRP'), ('have', 'VP', 'VBP'), ('yourself', 'PRP', 'PRP'), ('the beginning', 'NP', 'DT NN'), ('of a great evening', 'PP', 'IN DT JJ NN')]\n",
      "('was', 'VP', 'VBD') linking verb the lava cake dessert was incredible [('the lava cake dessert', 'NP', 'DT NN NN NN'), ('was', 'VP', 'VBD'), ('incredible', 'ADJP', 'JJ')]\n",
      "('recommend', 'VP', 'VB') action verb i recommend it [('i', 'ADVP', 'LS'), ('recommend', 'VP', 'VB'), ('it', 'PRP', 'PRP')]\n",
      "('is', 'VP', 'VBZ') linking verb this tiny restaurant is as cozy [('this tiny restaurant', 'NP', 'DT JJ NN'), ('is', 'VP', 'VBZ'), ('as cozy', 'ADJP', 'IN JJ')]\n",
      "('gets', 'VP', 'VBZ') action verb as it gets with that certain parisian flair [('as it', 'PRP', 'IN PRP'), ('gets', 'VP', 'VBZ'), ('with that certain parisian flair', 'PP', 'IN DT JJ JJ NN')]\n",
      "('was', 'VP', 'VBD') linking verb the food was average to aboveaverage the french onion soup filling yet not overly impressive and the desserts not brilliant in any way [('the food', 'NP', 'DT NN'), ('was', 'VP', 'VBD'), ('average to aboveaverage the french onion soup filling yet not overly impressive and the desserts not brilliant in any way', 'ADJP', 'JJ TO VB DT JJ NN NN VBG RB RB RB JJ CC DT NNS RB JJ IN DT NN')]\n",
      "('was', 'VP', 'VBD') linking verb it was horrible [('it', 'PRP', 'PRP'), ('was', 'VP', 'VBD'), ('horrible', 'ADJP', 'JJ')]\n",
      "('was delivered', 'VP', 'VBD VBN') action verb the pizza was delivered cold and the cheese wasnot [('the pizza', 'NP', 'DT NN'), ('was delivered', 'VP', 'VBD VBN'), ('cold', 'JJ', 'JJ'), ('and', 'CC', 'CC'), ('the cheese wasnot', 'NP', 'DT NN NN')]\n",
      "('melted', 'VP', 'VBN') action verb even fully melted [('even fully', 'ADVP', 'RB RB'), ('melted', 'VP', 'VBN')]\n",
      "('looked', 'VP', 'VBD') action verb it looked like shredded cheese partly done still in strips [('it', 'PRP', 'PRP'), ('looked', 'VP', 'VBD'), ('like shredded cheese partly done still in strips', 'PP', 'IN JJ NN RB VBN RB IN NNS')]\n",
      "('has got', 'VP', 'VBZ VBN') action verb this has got to be one of the most overrated restaurants in brooklyn [('this', 'DT', 'DT'), ('has got', 'VP', 'VBZ VBN'), ('to', 'TO', 'TO'), ('be', 'VP', 'VB'), ('one', 'CD', 'CD'), ('of the most overrated restaurants in brooklyn', 'PP', 'IN DT RBS JJ NNS IN NN')]\n",
      "('is overpriced', 'VP', 'VBZ VBN') action verb the pizza is overpriced and soggy [('the pizza', 'NP', 'DT NN'), ('is overpriced', 'VP', 'VBZ VBN'), ('and', 'CC', 'CC'), ('soggy', 'ADJP', 'JJ')]\n",
      "('use', 'VP', 'VBP') action verb yes they use fancy ingredients but [('yes they', 'PRP', 'RB PRP'), ('use', 'VP', 'VBP'), ('fancy ingredients', 'NP', 'JJ NNS'), ('but', 'ADVP', 'CC')]\n",
      "('donot make', 'VP', 'VBP VB') action verb even fancy ingredients donot make for good pizza [('even fancy ingredients', 'NP', 'RB JJ NNS'), ('donot make', 'VP', 'VBP VB'), ('for good pizza', 'PP', 'IN JJ NN')]\n",
      "('knows', 'VP', 'VBZ') action verb unless someone knows how to get the crust right [('unless', 'IN', 'IN'), ('someone', 'NP', 'NN'), ('knows', 'VP', 'VBZ'), ('how', 'WRB', 'WRB'), ('to', 'TO', 'TO'), ('get', 'VP', 'VB'), ('the crust right', 'NP', 'DT NN NN')]\n",
      "('think', 'VP', 'VBP') action verb i think [('i', 'FW', 'FW'), ('think', 'VP', 'VBP')]\n",
      "('had', 'VP', 'VBD') action verb ive had some the best meals of my life at minnow [('ive', 'NP', 'NN'), ('had', 'VP', 'VBD'), ('some the best meals', 'NP', 'DT DT JJS NNS'), ('of my life', 'PP', 'IN PRP$ NN'), ('at minnow', 'PP', 'IN NN')]\n",
      "('is', 'VP', 'VBZ') linking verb the seafood is amazing [('the seafood', 'NP', 'DT NN'), ('is', 'VP', 'VBZ'), ('amazing', 'ADJP', 'JJ')]\n",
      "('offers', 'VP', 'VBZ') action verb there a good wine list and the everchanging menu always offers some great surprises [('there', 'RB', 'RB'), ('a good wine list', 'NP', 'DT JJ NN NN'), ('and', 'CC', 'CC'), ('the everchanging menu', 'NP', 'DT JJ NN'), ('always', 'ADVP', 'RB'), ('offers', 'VP', 'VBZ'), ('some great surprises', 'NP', 'DT JJ NNS')]\n",
      "('are', 'VP', 'VBP') linking verb the combination of superfresh ingredients in the dishes are unusual but really delicious [('the combination', 'NP', 'DT NN'), ('of superfresh ingredients in the dishes', 'PP', 'IN JJ NNS IN DT NNS'), ('are', 'VP', 'VBP'), ('unusual but really delicious', 'ADJP', 'JJ CC RB JJ')]\n",
      "('are', 'VP', 'VBP') linking verb which are huge [('which', 'WDT', 'WDT'), ('are', 'VP', 'VBP'), ('huge', 'ADJP', 'JJ')]\n",
      "('had', 'VP', 'VBD') action verb my wife had the fried shrimp and loved it [('my wife', 'NP', 'PRP$ NN'), ('had', 'VP', 'VBD'), ('the fried shrimp', 'NP', 'DT JJ NN'), ('and loved it', 'PRP', 'CC VBD PRP')]\n",
      "('is', 'VP', 'VBZ') linking verb this place is the most japanese [('this place', 'NP', 'DT NN'), ('is', 'VP', 'VBZ'), ('the', 'DT', 'DT'), ('most', 'RBS', 'RBS'), ('japanese', 'JJ', 'JJ')]\n",
      "('can', 'VP', 'MD') action verb it can ever get [('it', 'PRP', 'PRP'), ('can', 'VP', 'MD'), ('ever', 'ADVP', 'RB'), ('get', 'VP', 'VB')]\n",
      "('are', 'VP', 'VBP') linking verb the signs the specials menus food and even all the waitstaff are all totally japanese [('the signs', 'NP', 'DT NNS'), ('the specials menus food', 'NP', 'DT NNS NNS NN'), ('and', 'CC', 'CC'), ('even all', 'ADJP', 'RB DT'), ('the', 'DT', 'DT'), ('waitstaff', 'NN', 'NN'), ('are', 'VP', 'VBP'), ('all totally japanese', 'ADJP', 'DT RB JJ')]\n",
      "('is', 'VP', 'VBZ') linking verb this place is worth an onehour drive [('this place', 'NP', 'DT NN'), ('is', 'VP', 'VBZ'), ('worth an onehour drive', 'PP', 'IN DT JJ NN')]\n",
      "('am', 'VP', 'VBP') linking verb i am so coming [('i', 'FW', 'FW'), ('am', 'VP', 'VBP'), ('so', 'ADVP', 'RB'), ('coming', 'VP', 'VBG')]\n",
      "('can', 'VP', 'MD') action verb back here again as much as i can [('back here again as much', 'ADVP', 'RB RB RB RB JJ'), ('as', 'IN', 'IN'), ('i', 'FW', 'FW'), ('can', 'VP', 'MD')]\n",
      "('is', 'VP', 'VBZ') linking verb leon is an east village gem casual but hip with well prepared basic french bistro fare good specials a warm and lively atmosphere [('leon', 'NP', 'NN'), ('is', 'VP', 'VBZ'), ('an east village gem casual', 'NP', 'DT JJ NN NN JJ'), ('but', 'CC', 'CC'), ('hip with well prepared basic french bistro fare good specials', 'NP', 'NN IN RB JJ JJ JJ NN NN JJ NNS'), ('a warm and lively atmosphere', 'NP', 'DT JJ CC JJ NN')]\n"
     ]
    }
   ],
   "source": [
    "aspect_term = []\n",
    "opinion_term = []\n",
    "\n",
    "for r in res_single_df.head(100)['preprocessed_sentence']:\n",
    "    candidate_aspect_per_sentence, candidate_opinion_per_sentence = aspect_extraction(r);\n",
    "    aspect_term.append(candidate_aspect_per_sentence)\n",
    "    opinion_term.append(candidate_opinion_per_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the food'],\n",
       " ['thai fusion stuff', 'bit'],\n",
       " ['thai fusion stuff', 'bit'],\n",
       " ['every thing']]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_term[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['averagethe'], ['sweet'], ['sweet'], ['sweet']]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_term[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the kitchen', 'NP', 'DT NN'),\n",
       " ('however', 'ADVP', 'RB'),\n",
       " ('is', 'VP', 'VBZ'),\n",
       " ('almost', 'RB', 'RB'),\n",
       " ('always', 'RB', 'RB'),\n",
       " ('slow', 'VP', 'VB')]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_phrases('the kitchen however is almost always slow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'worth' in positive_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The food is very average', 'IC'),\n",
       " ('they serve is too sweet here', 'DC'),\n",
       " ('the Thai fusion stuff is a bit too sweet every thing', 'IC')]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_clauses('The food is very average...the Thai fusion stuff is a bit too sweet, every thing they serve is too sweet here.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('is', 'VP', 'VBZ') linking verb The food is very average [('The food', 'NP', 'DT NN'), ('is', 'VP', 'VBZ'), ('very average', 'ADJP', 'RB JJ')]\n",
      "('serve is', 'VP', 'VBP VBZ') action verb they serve is too sweet here [('they', 'PRP', 'PRP'), ('serve is', 'VP', 'VBP VBZ'), ('too sweet', 'ADJP', 'RB JJ'), ('here', 'ADVP', 'RB')]\n",
      "('is', 'VP', 'VBZ') linking verb the Thai fusion stuff is a bit too sweet every thing [('the Thai fusion stuff', 'NP', 'DT NNP NN NN'), ('is', 'VP', 'VBZ'), ('a bit', 'NP', 'DT NN'), ('too sweet', 'ADJP', 'RB JJ'), ('every thing', 'NP', 'DT NN')]\n",
      "[['The food'], [], ['the Thai fusion stuff', 'bit', 'thing']] [['average'], ['sweet'], ['sweet']]\n"
     ]
    }
   ],
   "source": [
    "candidate_aspect_per_sentence, candidate_opinion_per_sentence = aspect_extraction('The food is very average...the Thai fusion stuff is a bit too sweet, every thing they serve is too sweet here.');\n",
    "print(candidate_aspect_per_sentence, candidate_opinion_per_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bought', 'VP', 'VBD') action verb i bought my canon g3 about a month ago [('i', 'LS', 'LS'), ('bought', 'VP', 'VBD'), ('my canon g3', 'NP', 'PRP$ NN NN'), ('about a month ago', 'PP', 'IN DT NN RB')]\n",
      "('have to say', 'VP', 'VBP TO VB') action verb i have to say [('i', 'LS', 'LS'), ('have to say', 'VP', 'VBP TO VB')]\n",
      "('am', 'VP', 'VBP') linking verb i am very satisfied [('i', 'FW', 'FW'), ('am', 'VP', 'VBP'), ('very satisfied', 'ADJP', 'RB JJ')]\n",
      "[['my canon g3', 'g3'], []] [[], ['satisfied']]\n"
     ]
    }
   ],
   "source": [
    "candidate_aspect_per_sentence, candidate_opinion_per_sentence = aspect_extraction('i bought my canon g3 about a month ago and i have to say i am very satisfied');\n",
    "print(candidate_aspect_per_sentence, candidate_opinion_per_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
