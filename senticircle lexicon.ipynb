{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "positive_lexicon = []\n",
    "negative_lexicon = []\n",
    "\n",
    "def read_lexicon():\n",
    "    global positive_lexicon;\n",
    "    global negative_lexicon;\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('opinion-lexicon-English/') , 'positive-words.txt'), 'r') as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "         \n",
    "        positive_lexicon = file.readlines()\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('opinion-lexicon-English/') , 'negative-words.txt'), 'r', encoding = \"ISO-8859-1\") as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "        \n",
    "        negative_lexicon = file.readlines()\n",
    "        \n",
    "    positive_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), positive_lexicon))\n",
    "    negative_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), negative_lexicon))\n",
    "    \n",
    "        \n",
    "read_lexicon()\n",
    "op_set = positive_lexicon + negative_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate(category, tipe):\n",
    "    df = pd.read_csv('Results/Sentiwordnet/hasil_'+ tipe + category +'.csv')\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    p = 'positive'\n",
    "    n = 'negative'\n",
    "    for index in range(0, len(df)):\n",
    "        label = df['label'][index]\n",
    "        predict = df['predict'][index]\n",
    "        \n",
    "        if label == p and predict == p:\n",
    "            tp += 1\n",
    "        elif label == n and predict == n:\n",
    "            tn += 1\n",
    "        elif label == n and predict == p:\n",
    "            fp += 1\n",
    "        elif label == p and predict == n:\n",
    "            fn += 1\n",
    "    \n",
    "    precision = round(tp / (tp + fp), 2)\n",
    "    recall = round(tp / (tp + fn), 2)\n",
    "    f1 = round(2 * ((precision * recall) / (precision + recall)), 2)\n",
    "    accuracy = round((tp+tn)/(tp+tn+fp+fn), 2)\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    f = 2 * ((p * r) / (p + r))\n",
    "    \n",
    "    \n",
    "    print(tp, '\\t', tn, '\\t', fp, '\\t', fn, '\\t', '\\t', precision, '\\t', recall, '\\t', f1, '\\t', '\\t', accuracy)\n",
    "    return tp, tn, fp, fn, p, r, f, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    return sentence.lower()\n",
    "\n",
    "def calculate_f1(p, r):\n",
    "    return round(2*((p*r)/(p+r)),2)\n",
    "\n",
    "negation = [\n",
    "    \"afraid\",\n",
    "    \"can't\",\n",
    "    \"cannot\",\n",
    "    \"deny\",\n",
    "    \"mean\",\n",
    "    \"negate\",\n",
    "    \"negation\",\n",
    "    \"negative\",\n",
    "    \"neither\",\n",
    "    \"never\",\n",
    "    \"no\",\n",
    "    \"non\",\n",
    "    \"none\",\n",
    "    \"nor\",\n",
    "    \"not\",\n",
    "    \"nothing\",\n",
    "    \"refusal\",\n",
    "    \"refuse\",\n",
    "    \"reject\",\n",
    "    \"rejection\",\n",
    "#     \"don't\",\n",
    "#     \"shouldn't\",\n",
    "#     \"wouldn't\",\n",
    "#     \"didn't\",\n",
    "#     \"though\",\n",
    "#     \"although\",\n",
    "#     \"wasn't\",\n",
    "#     \"isn't\",\n",
    "#     \"but\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_hasil(tipe):\n",
    "    sf = pd.DataFrame(columns=['TP', 'TN', 'FP', 'FN', 'precision', 'recall', 'f1', 'accuracy'])\n",
    "    print('tp', '\\t', 'tn', '\\t', 'fp', '\\t', 'fn', '\\t', '\\t', 'prec', '\\t', 'rec', '\\t', 'f1', '\\t', '\\t', 'accuracy')\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    cat = ['AMBIENCE', 'FOOD', 'SERVICE', 'PRICES']\n",
    "    for c in cat:\n",
    "        a, b, c, d, e, f, g, h = calculate(c, tipe)\n",
    "        precision.append(e)\n",
    "        recall.append(f)\n",
    "        f1.append(g)\n",
    "        sf = sf.append({'TP':a, 'TN':b, 'FP':c, 'FN':d, 'precision':e, 'recall':f, 'f1':g, 'accuracy': h}, ignore_index=True)\n",
    "    sf.to_excel(\"Results/Calculation/sentiment-\"+ tipe +\".xlsx\")\n",
    "    print('', '\\t', '', '\\t', '', '\\t', '', '\\t', '\\t', round(np.mean(precision),2), '\\t', round(np.mean(recall),2), '\\t', calculate_f1(round(np.mean(precision),2), round(np.mean(recall),2)), '\\t', '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def predict_lexicon(opinions, positive_lexicon, negative_lexicon, sent):\n",
    "    endscore = 0\n",
    "    for opinion in opinions:\n",
    "        if opinion in positive_lexicon:\n",
    "            endscore += 1\n",
    "        elif opinion in negative_lexicon:\n",
    "            endscore -= 1\n",
    "                \n",
    "        \n",
    "        words = sent.split(' ')\n",
    "        word_around = []\n",
    "        for x in range(0, len(words)):\n",
    "            if words[x] in string.punctuation:\n",
    "                continue\n",
    "            try:\n",
    "                if (words[x+1] == opinion) or (words[x+2] == opinion) or (words[x+3] == opinion) or (words[x+4] == opinion):\n",
    "                    word_around.append(words[x])\n",
    "                elif (words[x-1] == opinion):\n",
    "                    word_around.append(words[x])\n",
    "            except:\n",
    "                pass\n",
    "        for neg in negation:\n",
    "            if neg in word_around:\n",
    "                endscore *= (-1)\n",
    "                break\n",
    "\n",
    "    if endscore > 0:\n",
    "        polarity = 'positive'\n",
    "    else:\n",
    "        polarity = 'negative'\n",
    "           \n",
    "    return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def run(category):\n",
    "    df = pd.read_csv('Results/'+ category +'.csv')\n",
    "    sf = pd.DataFrame(columns = ['id','review', 'opinion', 'label', 'predict'])\n",
    "    \n",
    "    of = pd.read_csv('Results/Opinion/' + category + '.csv')\n",
    "    positive_lexicon = []\n",
    "    negative_lexicon = []\n",
    "    for i in range(0, len(of)):\n",
    "        if of['sentimen'][i] == 'positive':\n",
    "            positive_lexicon.append(of['opini'][i])\n",
    "        else:\n",
    "            negative_lexicon.append(of['opini'][i])\n",
    "            \n",
    "    print(len(df))\n",
    "    count = 0\n",
    "    for index in range(0, len(df)):\n",
    "        opinion = []\n",
    "        if type(df['opinion'][index]) != float:\n",
    "            opinion = df['opinion'][index].split('|')\n",
    "            \n",
    "        \n",
    "            \n",
    "        prediction = predict_lexicon(opinion, positive_lexicon, negative_lexicon, preprocessing(df['review'][index]))\n",
    "        \n",
    "        sf = sf.append({'id': df['id'][index], \n",
    "            'review': df['review'][index],\n",
    "            'opinion': df['opinion'][index],\n",
    "            'label': df['label'][index],\n",
    "            'predict': prediction\n",
    "           }, ignore_index=True)\n",
    "        count += 1\n",
    "    print(count)\n",
    "    sf.to_csv(\"Results/Sentiwordnet/hasil_cir_\"+ category +\".csv\")\n",
    "    sf.to_excel(\"Results/Sentiwordnet/hasil_cir_\"+ category +\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "107\n",
      "177\n",
      "177\n",
      "122\n",
      "122\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "run('AMBIENCE')\n",
    "run('FOOD')\n",
    "run('SERVICE')\n",
    "run('PRICES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp \t tn \t fp \t fn \t \t prec \t rec \t f1 \t \t accuracy\n",
      "77 \t 10 \t 8 \t 16 \t \t 0.91 \t 0.83 \t 0.87 \t \t 0.78\n",
      "120 \t 25 \t 11 \t 21 \t \t 0.92 \t 0.85 \t 0.88 \t \t 0.82\n",
      "73 \t 27 \t 11 \t 9 \t \t 0.87 \t 0.89 \t 0.88 \t \t 0.83\n",
      "38 \t 32 \t 6 \t 6 \t \t 0.86 \t 0.86 \t 0.86 \t \t 0.85\n",
      " \t  \t  \t  \t \t 0.89 \t 0.86 \t 0.87 \t \t\n"
     ]
    }
   ],
   "source": [
    "print_hasil('cir_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp \t tn \t fp \t fn \t \t prec \t rec \t f1 \t \t accuracy\n",
      "72 \t 10 \t 8 \t 17 \t \t 0.9 \t 0.81 \t 0.85 \t \t 0.77\n",
      "118 \t 25 \t 11 \t 23 \t \t 0.91 \t 0.84 \t 0.87 \t \t 0.81\n",
      "73 \t 29 \t 11 \t 9 \t \t 0.87 \t 0.89 \t 0.88 \t \t 0.84\n",
      "32 \t 34 \t 3 \t 11 \t \t 0.91 \t 0.74 \t 0.82 \t \t 0.82\n",
      " \t  \t  \t  \t \t 0.9 \t 0.82 \t 0.86 \t \t\n"
     ]
    }
   ],
   "source": [
    "print_hasil('cir_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp \t tn \t fp \t fn \t \t prec \t rec \t f1 \t \t accuracy\n",
      "78 \t 10 \t 7 \t 15 \t \t 0.92 \t 0.84 \t 0.88 \t \t 0.8\n",
      "119 \t 25 \t 11 \t 22 \t \t 0.92 \t 0.84 \t 0.88 \t \t 0.81\n",
      "73 \t 28 \t 11 \t 9 \t \t 0.87 \t 0.89 \t 0.88 \t \t 0.83\n",
      "32 \t 34 \t 3 \t 11 \t \t 0.91 \t 0.74 \t 0.82 \t \t 0.82\n",
      " \t  \t  \t  \t \t 0.9 \t 0.83 \t 0.86 \t \t\n"
     ]
    }
   ],
   "source": [
    "print_hasil('cir_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
