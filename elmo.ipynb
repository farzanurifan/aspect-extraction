{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(8), Dimension(1024)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just a random sentence\n",
    "x = [\"Roasted ants are a popular snack in Columbia\"]\n",
    "\n",
    "# Extract ELMo features \n",
    "embeddings = elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(name, load = False):\n",
    "    # read data\n",
    "    train = pd.read_csv(\"train-\"+name+\".csv\")\n",
    "    test = pd.read_csv(\"test-\"+name+\".csv\")\n",
    "\n",
    "    if load:\n",
    "        train.shape, test.shape\n",
    "        train['label'].value_counts(normalize = True)\n",
    "        # remove URL's from train and test\n",
    "        train['clean_tweet'] = train['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "        test['clean_tweet'] = test['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "        # remove punctuation marks\n",
    "        punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "        train['clean_tweet'] = train['clean_tweet'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
    "        test['clean_tweet'] = test['clean_tweet'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
    "\n",
    "        # convert text to lowercase\n",
    "        train['clean_tweet'] = train['clean_tweet'].str.lower()\n",
    "        test['clean_tweet'] = test['clean_tweet'].str.lower()\n",
    "\n",
    "        # remove numbers\n",
    "        train['clean_tweet'] = train['clean_tweet'].str.replace(\"[0-9]\", \" \")\n",
    "        test['clean_tweet'] = test['clean_tweet'].str.replace(\"[0-9]\", \" \")\n",
    "\n",
    "        # remove whitespaces\n",
    "        train['clean_tweet'] = train['clean_tweet'].apply(lambda x:' '.join(x.split()))\n",
    "        test['clean_tweet'] = test['clean_tweet'].apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "        # import spaCy's language model\n",
    "        nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "        # function to lemmatize text\n",
    "        def lemmatization(texts):\n",
    "            output = []\n",
    "            for i in texts:\n",
    "                s = [token.lemma_ for token in nlp(i)]\n",
    "                output.append(' '.join(s))\n",
    "            return output\n",
    "        def elmo_vectors(x):\n",
    "            embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "            print('---')\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                sess.run(tf.tables_initializer())\n",
    "                # return average of ELMo features\n",
    "                return sess.run(tf.reduce_mean(embeddings,1))\n",
    "        list_train = [train[i:i+100] for i in range(0,train.shape[0],100)]\n",
    "        list_test = [test[i:i+100] for i in range(0,test.shape[0],100)]\n",
    "\n",
    "        # Extract ELMo embeddings\n",
    "        elmo_train = [elmo_vectors(x['clean_tweet']) for x in list_train]\n",
    "        elmo_test = [elmo_vectors(x['clean_tweet']) for x in list_test]\n",
    "\n",
    "        elmo_train_new = np.concatenate(elmo_train, axis = 0)\n",
    "        elmo_test_new = np.concatenate(elmo_test, axis = 0)\n",
    "\n",
    "        # save elmo_train_new\n",
    "        pickle_out = open(\"elmo_train_03032019.pickle\",\"wb\")\n",
    "        pickle.dump(elmo_train_new, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        # save elmo_test_new\n",
    "        pickle_out = open(\"elmo_test_03032019.pickle\",\"wb\")\n",
    "        pickle.dump(elmo_test_new, pickle_out)\n",
    "        pickle_out.close()\n",
    "    \n",
    "    # load elmo_train_new\n",
    "    pickle_in = open(\"elmo_train_03032019.pickle\", \"rb\")\n",
    "    elmo_train_new = pickle.load(pickle_in)\n",
    "\n",
    "    # load elmo_train_new\n",
    "    pickle_in = open(\"elmo_test_03032019.pickle\", \"rb\")\n",
    "    elmo_test_new = pickle.load(pickle_in)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    xtrain, xvalid, ytrain, yvalid = train_test_split(elmo_train_new, \n",
    "                                                      train['label'],  \n",
    "                                                      random_state=42, \n",
    "                                                      test_size=0.2)\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    lreg = LogisticRegression()\n",
    "    lreg.fit(xtrain, ytrain)\n",
    "    preds_valid = lreg.predict(xvalid)\n",
    "    f1_score(yvalid, preds_valid)\n",
    "    print(f1_score)\n",
    "#     return yvalid, preds_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.9126039e-02  5.2388992e-02  4.6263330e-02 ...  8.5774278e-03\n",
      "  -4.8353793e-03  6.7811199e-02]\n",
      " [-1.0902258e-01 -2.1525523e-02 -5.2172270e-02 ... -6.1512440e-02\n",
      "  -6.8826802e-02 -4.0342208e-02]\n",
      " [-7.3851429e-02  1.4869389e-02  3.8856074e-02 ... -1.6723890e-02\n",
      "  -8.2654923e-02  1.2227881e-04]\n",
      " ...\n",
      " [-5.7972725e-02 -7.6848440e-02 -1.4128958e-01 ...  4.3946747e-02\n",
      "  -6.2106684e-02  7.8684591e-02]\n",
      " [-1.6908251e-01 -4.5111772e-01 -2.1080220e-02 ... -8.8675328e-02\n",
      "   2.2013360e-01  2.4340060e-01]\n",
      " [-5.7666406e-02 -6.4698242e-02  8.1019267e-02 ...  5.5339698e-02\n",
      "  -3.3359792e-02  3.2166727e-02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function f1_score at 0x0000022D46681E18>\n"
     ]
    }
   ],
   "source": [
    "run('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def run_test(name):\n",
    "    train = pd.read_csv(\"train.csv\")\n",
    "    test = pd.read_csv(\"test.csv\")\n",
    "    \n",
    "    # load elmo_train_new\n",
    "    pickle_in = open(\"elmo_train_03032019.pickle\", \"rb\")\n",
    "    elmo_train_new = pickle.load(pickle_in)\n",
    "\n",
    "    # load elmo_train_new\n",
    "    pickle_in = open(\"elmo_test_03032019.pickle\", \"rb\")\n",
    "    elmo_test_new = pickle.load(pickle_in)\n",
    "    \n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    xtrain, xvalid, ytrain, yvalid = train_test_split(elmo_train_new, \n",
    "                                                      train['label'],  \n",
    "                                                      random_state=42, \n",
    "                                                      test_size=0.2)\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    lreg = KMeans(n_clusters=5)\n",
    "    lreg.fit(elmo_train_new)\n",
    "    preds_valid = lreg.predict(elmo_test_new)\n",
    "    return preds_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 4, 4, 2, 3, 2, 1, 0, 1, 1, 3, 3, 1, 4, 4, 4, 3, 4, 4, 1, 4,\n",
       "       1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 1, 3, 4, 4, 4, 4, 4, 4, 4, 4, 1,\n",
       "       4, 4, 4, 1, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 1, 3, 1, 4, 4, 4, 4, 1,\n",
       "       1, 4, 4, 1, 4, 4, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1,\n",
       "       4, 4, 0, 1, 1, 1, 1, 4, 4, 0, 4, 1, 4, 4, 1, 4, 4, 3, 0, 4, 0, 4,\n",
       "       4, 4, 1, 4, 4, 1, 4, 0, 1, 1, 3, 4, 4, 1, 0, 0, 1, 1, 4, 1, 4, 4,\n",
       "       4, 0, 1, 2, 4, 1, 1, 4, 4, 4, 1, 1, 1, 4, 0, 1, 1, 1, 4, 3, 1, 4,\n",
       "       4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 1, 4, 1, 4, 0, 4, 2, 3, 4, 1, 4, 4,\n",
       "       4, 4, 0, 3, 4, 1, 4, 1, 1, 4, 4, 4, 4, 0, 4, 3, 3, 4, 3, 4, 4, 4,\n",
       "       3, 3, 1, 1, 0, 4, 1, 3, 1, 1, 1, 3, 4, 4, 4, 1, 2, 4, 1, 3, 3, 4,\n",
       "       0, 0, 3, 0, 0, 4, 2, 0, 3, 0, 4, 4, 0, 0, 1, 4, 0, 4, 1, 4, 4, 4,\n",
       "       4, 2, 0, 4, 4, 0, 4, 1, 1, 4, 4, 4, 4, 4, 4, 1, 4, 1, 1, 3, 4, 1,\n",
       "       4, 1, 4, 1, 4, 4, 1, 4, 1, 0, 0, 1, 1, 1, 0, 4, 3, 4, 1, 4, 4, 1,\n",
       "       0, 4, 0, 3, 4, 4, 4, 1, 4, 1, 4, 1, 3, 0, 1, 4, 4, 3, 4, 4, 1, 1,\n",
       "       4, 1, 1, 1, 3, 3, 0, 3, 3, 1, 1, 4, 4, 4, 1, 1, 4, 0, 1, 3, 4, 4,\n",
       "       4, 4, 1, 4, 3, 1, 1, 4, 4, 4, 1, 0, 0, 4, 4, 3, 1, 1, 4, 4, 1, 2,\n",
       "       4, 2, 3, 3, 0, 4, 1, 0, 0, 4, 1, 3, 4, 1, 4, 4, 4, 3, 4, 1, 4, 4,\n",
       "       4, 4, 0, 4, 4, 0, 4, 1, 1, 0, 0, 1, 1, 4, 3, 2, 0, 4, 4, 1, 0, 1,\n",
       "       4, 4, 1, 1, 1, 1, 0, 3, 3, 4, 4, 4, 1, 1, 4, 4, 1, 4, 4, 4, 0, 0,\n",
       "       4, 4, 4, 4, 4, 4, 1, 3, 4, 4, 4, 4, 1, 4, 4, 1, 1, 4, 4, 1, 2, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 4, 4, 1, 4, 1, 0, 4,\n",
       "       0, 1, 0, 4, 3, 1, 1, 4, 1, 4, 1, 4, 1, 4, 4, 2, 1, 4, 1, 2, 0, 1,\n",
       "       4, 4, 4, 4, 4, 4, 4, 1, 4, 0, 1, 1, 4, 0, 0, 4, 4, 4, 4, 4, 3, 1,\n",
       "       4, 4, 4, 4, 0, 4, 4, 1, 1, 1, 0, 4, 4, 1, 4, 4, 4, 4, 4, 4, 1, 0,\n",
       "       4, 1, 4, 3, 0, 1, 4, 4, 1, 4, 4, 1, 4, 1, 4, 4, 1, 4, 4, 1, 4, 1,\n",
       "       3, 2, 4, 4, 1, 1, 1, 0, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 1, 4, 4, 3,\n",
       "       0, 4, 3, 4, 4, 1, 4, 1, 1, 4, 1, 1, 1, 4, 4, 4, 1, 4, 1, 2, 1, 4,\n",
       "       4, 4, 4, 4, 4, 4, 1, 1, 4, 3, 3, 4, 1, 0, 1, 1, 4, 4, 1, 2, 4, 4,\n",
       "       3, 3, 0, 4, 3, 1, 1, 4, 4, 3, 2, 1, 4, 0, 0, 1, 2, 3, 1, 4, 4, 1,\n",
       "       1, 4, 1, 1, 2, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_test('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-1f11dba82031>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'v'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# confusion_matrix(y, Y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "y, Y = run_test('v')\n",
    "print(classification_report(y, Y))\n",
    "# confusion_matrix(y, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_vectors(x):\n",
    "    embeddings = elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "    print('---')\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        # return average of ELMo features\n",
    "        return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "a = elmo_vectors(['i', 'love', 'you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "tokens_input = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"],\n",
    "                [\"dogs\", \"are\", \"in\", \"the\", \"fog\", \"\"]]\n",
    "tokens_length = [6, 5]\n",
    "embeddings = elmo(\n",
    "    inputs={\n",
    "        \"tokens\": tokens_input,\n",
    "        \"sequence_len\": tokens_length\n",
    "    },\n",
    "    signature=\"tokens\",\n",
    "    as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vektor(x):\n",
    "    elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "    embeddings = elmo(x,\n",
    "        signature=\"default\",\n",
    "        as_dict=True)[\"elmo\"]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        # return average of ELMo features\n",
    "        return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"A battery is a device consisting of one or more electrochemical cells with external connections provided to power electrical devices such as flashlights, smartphones, and electric cars. When a battery is supplying electric power, its positive terminal is the cathode and its negative terminal is the anode. The terminal marked negative is the source of electrons that will flow through an external electric circuit to the positive terminal. When a battery is connected to an external electric load, a redox reaction converts high-energy reactants to lower-energy products, and the free-energy difference is delivered to the external circuit as electrical energy. Historically the term battery specifically referred to a device composed of multiple cells, however the usage has evolved to include devices composed of a single cell.\"]\n",
    "x = vektor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [\"A display device is an output device for presentation of information in visual or tactile form (the latter used for example in tactile electronic displays for blind people). When the input information that is supplied has an electrical signal the display is called an electronic display.\"]\n",
    "y = vektor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [\"A central processing unit (CPU), also called a central processor or main processor, is the electronic circuitry within a computer that carries out the instructions of a computer program by performing the basic arithmetic, logic, controlling, and input/output (I/O) operations specified by the instructions. The computer industry has used the term central processing unit at least since the early 1960s. Traditionally, the term CPU refers to a processor, more specifically to its processing unit and control unit (CU), distinguishing these core elements of a computer from external components such as main memory and I/O circuitry.\"]\n",
    "z = vektor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "def cosine(x, y):\n",
    "    dataSetI = x\n",
    "    dataSetII = y\n",
    "    return 1 - spatial.distance.cosine(dataSetI, dataSetII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = ['power']\n",
    "w1 = vektor(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2 = ['screen']\n",
    "w2 = vektor(word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "def get_score(base, word):\n",
    "    k = []\n",
    "    for a in base:\n",
    "        k.append(cosine(a, word))\n",
    "    return np.mean(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load elmo_train_new\n",
    "pickle_in = open(\"elmo_test_03032019.pickle\", \"rb\")\n",
    "elmo_test_new = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03912604,  0.05238899,  0.04626333, ...,  0.00857743,\n",
       "       -0.00483538,  0.0678112 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_test_new[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
