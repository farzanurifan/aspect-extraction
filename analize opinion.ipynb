{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import re\n",
    "import pandas as pd\n",
    "import itertools, nltk, string \n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "nltk_words = set(nltk.corpus.stopwords.words('english'))\n",
    "stop_words = []\n",
    "for word in nltk_words:\n",
    "    stop_words.append(word.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "def preprocess(sentence):\n",
    "    res = sentence.lower()\n",
    "    res = res.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokenized_words = nltk.word_tokenize(res)\n",
    "    res = [word for word in tokenized_words if word not in stop_words]\n",
    "    res = [lemmatizer.lemmatize(r) for r in res]\n",
    "    res = [re.sub(r\"[^A-Za-z]+\", '', r) for r in res]\n",
    "    return res\n",
    "\n",
    "positive_lexicon = []\n",
    "negative_lexicon = []\n",
    "\n",
    "def read_lexicon():\n",
    "    global positive_lexicon;\n",
    "    global negative_lexicon;\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('opinion-lexicon-English/') , 'positive-words.txt'), 'r') as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "         \n",
    "        positive_lexicon = file.readlines()\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('opinion-lexicon-English/') , 'negative-words.txt'), 'r', encoding = \"ISO-8859-1\") as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "        \n",
    "        negative_lexicon = file.readlines()\n",
    "        \n",
    "    positive_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), positive_lexicon))\n",
    "    negative_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), negative_lexicon))    \n",
    "        \n",
    "read_lexicon()\n",
    "opinion_lexicon = positive_lexicon + negative_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Results/Opinion/PRICES.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run(name):\n",
    "    df = pd.read_csv('Results/Opinion/'+ name +'.csv')\n",
    "    sf = pd.DataFrame(columns = ['id','opinion', 'sentiment', 'type'])\n",
    "\n",
    "    for index in range(0, len(df)):\n",
    "        opini = df['opini'][index]\n",
    "        sentimen = df['sentimen'][index]\n",
    "        tipe = '-'\n",
    "\n",
    "        if opini == 'high':\n",
    "            print(opini, sentimen)\n",
    "        Flag = False\n",
    "        if sentimen == 'positive':\n",
    "            if opini not in positive_lexicon and opini in negative_lexicon:\n",
    "#                 print(opini, '+')\n",
    "                Flag = True\n",
    "            elif opini not in opinion_lexicon:\n",
    "#                 print(opini, '+ baru')\n",
    "                Flag = True\n",
    "                tipe = 'baru'\n",
    "\n",
    "        elif sentimen == 'negative':\n",
    "            if opini not in negative_lexicon and opini in positive_lexicon:\n",
    "#                 print(opini, '-')\n",
    "                Flag = True\n",
    "            elif opini not in opinion_lexicon:\n",
    "#                 print(opini, '- baru')\n",
    "                Flag = True\n",
    "                tipe = 'baru'\n",
    "\n",
    "        if Flag:\n",
    "            sf = sf.append({'id': index, \n",
    "                    'opinion': opini,\n",
    "                    'sentiment': sentimen,\n",
    "                    'type': tipe,\n",
    "                   }, ignore_index=True)\n",
    "\n",
    "    sf.to_csv('Results/Opinion/beda-' + name + '.csv')\n",
    "    sf.to_excel('Results/Opinion/beda-' + name + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high positive\n",
      "high negative\n"
     ]
    }
   ],
   "source": [
    "run('AMBIENCE')\n",
    "run('FOOD')\n",
    "run('SERVICE')\n",
    "run('PRICES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'high' in opinion_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
