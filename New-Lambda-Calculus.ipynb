{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to C:\\Users\\Farza\n",
      "[nltk_data]     Nurifan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk import Tree\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "import json\n",
    "import nltk\n",
    "from nltk.sem.logic import *\n",
    "import requests\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "nltk.download('sentiwordnet')\n",
    "\n",
    "\n",
    "read_expr = nltk.sem.Expression.fromstring\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "dependency_parser = nlp.annotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Babelfy WSD method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def babelfy(sentence):\n",
    "    response = []\n",
    "    token_word = nltk.word_tokenize(sentence)\n",
    "    url = 'https://babelfy.io/v1/disambiguate?text='+sentence+'&annRes=WN&lang=en&key=76787a80-1771-41d6-8879-2e5064008923'\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    res = r.json()\n",
    "    \n",
    "    for x in res:\n",
    "        tokenFragment = x['tokenFragment']\n",
    "        startTknFragment = tokenFragment['start']\n",
    "        endTknFragment = tokenFragment['end']\n",
    "        babelSynsetID = x['babelSynsetID'];\n",
    "        response.append((token_word[startTknFragment], babel_info(babelSynsetID)))\n",
    "    \n",
    "    return response\n",
    "\n",
    "def babel_info(synset_id):\n",
    "    url = 'https://babelnet.io/v5/getSynset?id='+synset_id+'&key=76787a80-1771-41d6-8879-2e5064008923'\n",
    "    r = requests.get(url)\n",
    "    res = r.json()\n",
    "    return '.'.join(res['mainSense'].split('#'))\n",
    "    \n",
    "\n",
    "def get_score(sentence):\n",
    "    resp = babelfy(sentence)\n",
    "    ss = []\n",
    "    for (w, sy) in resp:\n",
    "        swn_senti = swn.senti_synset(sy)\n",
    "        ss.append((w, sy, swn_senti.pos_score(), swn_senti.neg_score() ))\n",
    "        \n",
    "    return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensifier_adverb = ['absolutely', 'completely', 'extremely', 'highly', 'rather', 'really', 'very', 'so', 'too', 'totally', 'utterly', 'at all']\n",
    "negate_adverb = ['no', 'not', 'never', 'none', 'nobody']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(expression):\n",
    "    old = expression.replace(' ', '_').replace('>_(', '> (').replace(')_(', ') (').replace(')_)', ') )').replace(')_)', ') )').replace(' (', '(')\n",
    "    new = ''\n",
    "    flag = False\n",
    "    for x in range(0, len(old) - 1):        \n",
    "        if old[x] == '<':\n",
    "            flag = True\n",
    "        if old[x] == '>':\n",
    "            flag = False\n",
    "            \n",
    "        if flag == True:\n",
    "            if old[x] == '(':\n",
    "                new += '{'\n",
    "            elif old[x] == ')':\n",
    "                new += '}'\n",
    "            else:\n",
    "                new += old[x]\n",
    "        else:\n",
    "            new += old[x]\n",
    "    new += old[len(old)-1]\n",
    "    return new\n",
    "\n",
    "def pos_tag(sentence):\n",
    "    result = dependency_parser(sentence, properties={\"outputFormat\": \"json\", \"annotators\": \"pos\"})['sentences'][0]['tokens']\n",
    "    res = []\n",
    "    for pos in result:\n",
    "        res.append(pos['pos'])\n",
    "    return res\n",
    "\n",
    "\n",
    "def insert_pos_tag(exp, pos, nltk_pos):\n",
    "    count = 0\n",
    "    res = ''\n",
    "    for x in range(0, len(exp)):\n",
    "        if exp[x] == 'S' and exp[x+1]==' ' and exp[x+2] == 'P':\n",
    "            res += 'S '\n",
    "            res += pos[count] + ' ' + nltk_pos[count][1]\n",
    "            count += 1\n",
    "            x += 4\n",
    "        else:\n",
    "            res += exp[x]  \n",
    "    return res\n",
    "\n",
    "\n",
    "def direction(exp):\n",
    "    cont = False\n",
    "    for x in exp:\n",
    "        if x == '{':\n",
    "            cont = True\n",
    "        elif x == '}':\n",
    "            cont = False\n",
    "            continue\n",
    "        if cont == True:\n",
    "            continue\n",
    "        if x == '/':\n",
    "            return '/'\n",
    "        elif x == '\\\\':\n",
    "            return '\\\\'\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_type_raising(tree):\n",
    "    tree_string = str(tree)\n",
    "    \n",
    "    # check type raising\n",
    "    exp = tree_string.split('_')[1]\n",
    "    pattern_1 = r'(.*?)\\\\(.*?){(.*?)/(.*?)}'\n",
    "    pattern_2 = r'(.*?)/(.*?){(.*?)\\\\(.*?)}'\n",
    "    \n",
    "    match = False\n",
    "    if re.search(pattern_1, exp):\n",
    "        match = True\n",
    "    elif re.search(pattern_2, exp):\n",
    "        match = True\n",
    "        \n",
    "    sub = []\n",
    "    for subtree in tree:\n",
    "        sub.append(subtree)\n",
    "    if len(sub) == 1 and match:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def map_wnpos_to_pennpos(pos):\n",
    "    if(pos == 'n'):\n",
    "        return 'NN'\n",
    "    elif(pos == 'a'):\n",
    "        return 'JJ'\n",
    "    elif(pos == 'v'):\n",
    "        return 'VB'\n",
    "    elif(pos == 'r'):\n",
    "        return 'RB'\n",
    "    \n",
    "def find_word_in_swn(swn_score, word):\n",
    "    for (wordd, synset, pos_score, neg_score) in swn_score:\n",
    "        if(wordd == word):\n",
    "            return (wordd, synset, pos_score, neg_score)\n",
    "        \n",
    "def polarity_with_score(pos, neg):\n",
    "    if(pos > neg):\n",
    "        return ('P', round(pos * 10))\n",
    "    elif(pos == neg):\n",
    "        return ('Ne', round(neg*10))\n",
    "    else:\n",
    "        return ('N', 0)\n",
    "    \n",
    "def adverb_type(word):\n",
    "    if (word in intensifier_adverb):\n",
    "        return 'I'\n",
    "    elif(word in negate_adverb):\n",
    "        return 'Ne'\n",
    "    else:\n",
    "        return 'N'\n",
    "    \n",
    "def pos_majority_voting(corenlp, nltk, babelfy):\n",
    "    pos = {}\n",
    "    \n",
    "    if(corenlp in pos):\n",
    "        pos[corenlp] += 1\n",
    "    else:\n",
    "        pos[corenlp] = 0\n",
    "        \n",
    "    \n",
    "    if(nltk in pos):\n",
    "        pos[nltk] += 1\n",
    "    else:\n",
    "        pos[nltk] = 0\n",
    "    \n",
    "    \n",
    "    if(babelfy in pos):\n",
    "        pos[babelfy] += 1\n",
    "    else:\n",
    "        pos[babelfy] = 0\n",
    "        \n",
    "        \n",
    "    #find biggeest counter in pos \n",
    "    return sorted(pos.items(), key=lambda x: x[1], reverse=True)[0][0];\n",
    "\n",
    "    \n",
    "def lambda_calculus(tree, swn_score):\n",
    "    tree_string = str(tree)\n",
    "    \n",
    "    if tree_string[2] == 'L':\n",
    "        corenlp_pos = tree_string.split('_')[3]\n",
    "        nltk_pos = tree_string.split('_')[4]\n",
    "        word = tree_string.split('_')[6]\n",
    "        #                        #\n",
    "        # masukin rulenya disini #\n",
    "        #                        #\n",
    "        r_word = ['PRP', 'FW', 'NN', 'LS']\n",
    "        word_swn_score = find_word_in_swn(swn_score, word)\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        \n",
    "        babelfy_pos = None;\n",
    "        \n",
    "        if(word_swn_score):\n",
    "            word, synset, pos_score, neg_score = word_swn_score\n",
    "            splitted_syns = synset.split('.');\n",
    "            babelfy_pos = map_wnpos_to_pennpos(splitted_syns[1]);\n",
    "            \n",
    "        \n",
    "        polarity, score = polarity_with_score(pos_score, neg_score)\n",
    "        \n",
    "        pos = pos_majority_voting(corenlp_pos, nltk_pos, babelfy_pos)\n",
    "            \n",
    "        if pos == 'CC':\n",
    "            return read_expr(r'CC')\n",
    "        elif pos in r_word:\n",
    "            return read_expr(word + '_' + pos + '_' + polarity + '_' + str(score))\n",
    "        elif 'JJ' in pos:\n",
    "            return read_expr(word + '_' + 'JJ' + '_' + polarity + '_' + str(score))\n",
    "        elif 'VB' in pos:\n",
    "            if '{S[dcl]\\\\NP}/{S[adj]\\\\NP}' in tree_string.split('_')[1]:\n",
    "                return read_expr(r'\\x.x')\n",
    "            else:\n",
    "                return read_expr(r'\\X.' + word + '_' + 'VB' + '_' + polarity + '_' + str(score) +'(X)')\n",
    "        elif 'RB' in pos:\n",
    "            #Adverb has three types. I: Intensifier, Ne: Negation, N: no affection toward sentiment\n",
    "            return read_expr(word + '_' + 'RB' + '_' + adverb_type(word))\n",
    "        elif word == 'of':\n",
    "            return read_expr('of')\n",
    "        else:\n",
    "#             print(word, tree_string, '--')\n",
    "            return read_expr(r'\\x.x')\n",
    "    \n",
    "    # ini cuma masukin ke array \n",
    "    chunk = []\n",
    "    chunk3 = []\n",
    "    sub = []\n",
    "    \n",
    "    for subtree in tree:\n",
    "        if type(subtree) == nltk.tree.Tree:\n",
    "            sub.append(subtree)\n",
    "            \n",
    "            # chunk temp array\n",
    "            subtree_str_array = str(subtree).split('_')\n",
    "            if subtree_str_array[0][2] == 'L':\n",
    "                if subtree_str_array[3] == 'NN':\n",
    "                    chunk.append(subtree_str_array[6])\n",
    "                    if len(chunk3) == 0:\n",
    "                        chunk3.append(subtree_str_array[6])\n",
    "                    \n",
    "            if len(chunk3) == 1:\n",
    "                for sub in subtree:\n",
    "                    # chunk temp array\n",
    "                    subtree_str_array3 = str(sub).split('_')\n",
    "                    if subtree_str_array3[0][2] == 'L':\n",
    "                        if subtree_str_array3[3] == 'NN':\n",
    "                            chunk3.append(subtree_str_array3[6])\n",
    "    \n",
    "    \n",
    "    # chunk noun phrase\n",
    "    if len(chunk) == 2:\n",
    "        chunk_str = '+'.join(chunk)\n",
    "        return read_expr(r'(' + chunk_str + '_NN_Ne_0)')\n",
    "    \n",
    "    if len(chunk3) == 3:\n",
    "        chunk_str = '+'.join(chunk3)\n",
    "        return read_expr(r'(' + chunk_str + '_NN_Ne_0)')\n",
    "    \n",
    "    # error anak 1\n",
    "    if len(sub) == 1:            \n",
    "        return lambda_calculus(sub[0], swn_score)\n",
    "                        \n",
    "    # urutan operasi lambda calculusnya    \n",
    "    first = sub[0]\n",
    "    second = sub[1]\n",
    "    \n",
    "    if is_type_raising(first):\n",
    "        if direction(str(first).split('_')[1]) == '/':\n",
    "            x = read_expr(r'\\F x.F(x, ' + str(lambda_calculus(first, swn_score)) + ')')\n",
    "            y = lambda_calculus(second, swn_score)\n",
    "            return ApplicationExpression(x, y).simplify()\n",
    "    \n",
    "    if is_type_raising(second):\n",
    "        if direction(str(second).split('_')[1]) == '/':\n",
    "            x = lambda_calculus(first, swn_score)\n",
    "            y = read_expr(r'\\F x.F(x, ' + str(lambda_calculus(second, swn_score)) + ')')\n",
    "            return ApplicationExpression(x, y).simplify()\n",
    "    \n",
    "        \n",
    "    length_1 = len(str(sub[0]).split('_')[1].replace('\\\\', '/').split('/'))\n",
    "    length_2 = len(str(sub[1]).split('_')[1].replace('\\\\', '/').split('/'))\n",
    "    if length_2 > length_1:\n",
    "        first = sub[1]\n",
    "        second = sub[0]\n",
    "    # rekursi\n",
    "    return deduction(lambda_calculus(first, swn_score), lambda_calculus(second, swn_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduction(a, b):\n",
    "    str_a = str(a)\n",
    "    str_b = str(b)\n",
    "    print('old a ' + str_a)\n",
    "    print('old b ' + str_b)\n",
    "    \n",
    "    if str_a == 'of':\n",
    "        a = read_expr(r'\\x.x')\n",
    "        b = read_expr(r'\\x.x')\n",
    "    \n",
    "    #change identity function for adjective\n",
    "    is_adj_exist_in_a = re.search(r'JJ.*', str_a)\n",
    "    is_adj_exist_in_b = re.search(r'JJ.*', str_b)\n",
    "    \n",
    "    is_adverb_exist_in_a = re.search(r'RB.*', str_a)\n",
    "    is_adverb_exist_in_b = re.search(r'RB.*', str_b)\n",
    "    \n",
    "    \n",
    "    is_noun_exist_in_b = re.search(r'\\w*?\\+?\\w*?\\+?\\w*_NN_\\w*', str_b)\n",
    "    is_verb_exist_in_b = re.search(r'VB_\\w*_\\d*', str_b)\n",
    "    \n",
    "    \n",
    "    if is_adverb_exist_in_a and (is_noun_exist_in_b and (not is_verb_exist_in_b)):\n",
    "        print(is_adverb_exist_in_a)\n",
    "        print(is_noun_exist_in_b)\n",
    "        print(is_verb_exist_in_b)\n",
    "        a = read_expr(r'\\x.x')\n",
    "        b = read_expr(r'\\x.x')\n",
    "\n",
    "#     elif( is_adj_exist_in_a and is_noun_exist_in_b):\n",
    "# #         adjective_score = str_a.split('_')[3]\n",
    "# #         sentiment_polarity = str_a.split('_')[2]\n",
    "#         pattern = '(\\w*_JJ_\\w_\\d)'\n",
    "#         adjective_score = re.findall(pattern, str_a)[0].split('_')[3]\n",
    "#         sentiment_polarity = re.findall(pattern, str_a)[0].split('_')[2]\n",
    "#         print(adjective_score, sentiment_polarity)\n",
    "#         #get noun\n",
    "#         noun_str_b = str_b[ is_noun_exist_in_b.start() : is_noun_exist_in_b.end() ]\n",
    "#         #change sentiment and polarity\n",
    "#         def mapFunction(data):\n",
    "#             idx, x = data\n",
    "#             if(idx == 2):\n",
    "#                 return sentiment_polarity\n",
    "#             elif(idx == 3):\n",
    "#                 return adjective_score\n",
    "#             else:\n",
    "#                 return x\n",
    "            \n",
    "#         noun_update_str_b = '_'.join( list(map(mapFunction, enumerate(noun_str_b.split('_')))) )\n",
    "#         #change str_b for noun filtered with x\n",
    "#         list_str_b = list(str_b)\n",
    "#         list_str_b[is_noun_exist_in_b.start() : is_noun_exist_in_b.end()] = 'x'\n",
    "#         str_b = \"\".join(list_str_b)\n",
    "#         print(str_b, noun_update_str_b, is_noun_exist_in_b)\n",
    "#         str_b = str(ApplicationExpression(read_expr(r\"\\x.\" + str_b), read_expr(noun_update_str_b)).simplify())\n",
    "        \n",
    "#         a = read_expr(r'\\x.x')\n",
    "#         b = read_expr(str_b)\n",
    "    \n",
    "    #change identity function for adverb.\n",
    "    elif( is_adverb_exist_in_a and is_adj_exist_in_b or is_adverb_exist_in_a and is_verb_exist_in_b ):\n",
    "        #adverb modify adjective\n",
    "        #example very_RB_I excellent_JJ_P_10 = excellent_JJ_P_20\n",
    "        #I Intensifier must *2\n",
    "        #N Negate must *-1\n",
    "        adverb_type = str_a.split('_')[2]\n",
    "        if(adverb_type == 'N'):\n",
    "            a = read_expr(r'\\x.x')\n",
    "        elif(adverb_type == 'Ne'):\n",
    "            #for negation adverb just change polairty\n",
    "            def mapFunction(data):\n",
    "                idx, x = data\n",
    "                if(idx == 2):\n",
    "                    if(x == 'P'):\n",
    "                        return 'Ne'\n",
    "                    elif(x == 'Ne'):\n",
    "                        return 'P'\n",
    "                    else:\n",
    "                        return x\n",
    "                else:\n",
    "                    return x\n",
    "\n",
    "            str_b = '_'.join( list(map(mapFunction, enumerate(str_b.split('_')))) )\n",
    "            a = read_expr(r'\\x.x')\n",
    "            b = read_expr(str_b)\n",
    "            \n",
    "        elif(adverb_type == 'I'):\n",
    "            #for intensifier adverb. scale adjective value \n",
    "            vb_score = re.findall('VB_\\w*_\\d*', str_b)[0].split('_')[2]\n",
    "            def mapFunction(data):\n",
    "                if(data == vb_score):\n",
    "                    return str(int(vb_score) * 2);\n",
    "                else:\n",
    "                    return data;\n",
    "            list_str_b = list(str_b)\n",
    "            str_b = ''.join( list(map(mapFunction, list_str_b)))\n",
    "            print(str_b)\n",
    "            a = read_expr(r'\\x.x')\n",
    "            b = read_expr(str_b)\n",
    "        \n",
    "    elif( is_adverb_exist_in_a and is_adverb_exist_in_b):\n",
    "        #adverb modify other adverb\n",
    "        #kondisi yang jarang bertemu\n",
    "        pass\n",
    "    \n",
    "    if(str_a == 'CC'):\n",
    "#         print('m')\n",
    "        pass\n",
    "    if(str_b == 'CC'):\n",
    "        a = read_expr(str_b)\n",
    "        b = read_expr(str_a)\n",
    "    if (re.search(r'CC\\(', str_a)) and (re.search(r',', str_a)) and is_noun_exist_in_b:\n",
    "        a = read_expr(r'\\x.x')\n",
    "        b = read_expr(replacer(str_a, str_b))\n",
    "        \n",
    "    r_word = ['PRP', 'FW', 'NN', 'LS', 'JJ']\n",
    "    \n",
    "    if '(' not in str_a and '(' not in str_b:\n",
    "            x = False\n",
    "            y = False\n",
    "            for r in r_word:\n",
    "                if r in str_a:\n",
    "                    x = True\n",
    "                if r in str_b:\n",
    "                    y = True\n",
    "                    \n",
    "            if x and y:\n",
    "                a = read_expr(r'\\x.x')\n",
    "                b = read_expr('seq(' + str_a + ',' + str_b + ')')\n",
    "                \n",
    "    str_a = str(a)\n",
    "    str_b = str(b)\n",
    "    print('new a ' + str_a)\n",
    "    print('new b ' + str_b)\n",
    "    print('hasil ' + str(ApplicationExpression(a, b).simplify()))\n",
    "    return ApplicationExpression(a, b).simplify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(a, b):\n",
    "#     print(a, b)\n",
    "    pattern = '(\\w*_NN_)'\n",
    "    mereplace = re.findall(pattern, b)\n",
    "    res = ''\n",
    "    for mreplace in mereplace:\n",
    "        pattern = '(\\w*_JJ_)'\n",
    "        hasil = re.findall(pattern, a)\n",
    "        if hasil:\n",
    "            res = a.replace(hasil[0], mreplace)\n",
    "        if len(hasil) > 1:\n",
    "            for index in range(1, len(hasil)):\n",
    "                res = res.replace(hasil[index], mreplace)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glue_process(sent):\n",
    "    url = \"http://localhost:5000/ccgParsing\"\n",
    "    data = {\"sent\": sent}\n",
    "    r = requests.post(url, data=data)\n",
    "\n",
    "    res = r.json()\n",
    "    \n",
    "    from_res = res['tree']\n",
    "    \n",
    "    text = nltk.word_tokenize(sent)\n",
    "    nltk_pos = nltk.pos_tag(text)\n",
    "    \n",
    "    pos_tagged = insert_pos_tag(from_res, pos_tag(data['sent']), nltk_pos)\n",
    "\n",
    "    hasil = parser(pos_tagged)\n",
    "\n",
    "    tree = Tree.fromstring(hasil)\n",
    "    swn_score = get_score(sent)\n",
    "    \n",
    "#     print(tree)\n",
    "    return lambda_calculus(tree, swn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glue_process('the breakfast that the restaurant served daily was excellent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# glue_process('i bought my canon g3 about a month ago and i have to say i am very satisfied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old a delicious_JJ_P_8\n",
      "old b CC\n",
      "new a CC\n",
      "new b delicious_JJ_P_8\n",
      "hasil CC(delicious_JJ_P_8)\n",
      "old a CC(delicious_JJ_P_8)\n",
      "old b hot_JJ_Ne_0\n",
      "new a CC(delicious_JJ_P_8)\n",
      "new b hot_JJ_Ne_0\n",
      "hasil CC(delicious_JJ_P_8,hot_JJ_Ne_0)\n",
      "old a \\x.x\n",
      "old b CC(delicious_JJ_P_8,hot_JJ_Ne_0)\n",
      "new a \\x.x\n",
      "new b CC(delicious_JJ_P_8,hot_JJ_Ne_0)\n",
      "hasil CC(delicious_JJ_P_8,hot_JJ_Ne_0)\n",
      "old a of\n",
      "old b squid+eyeball+stew_NN_N_0\n",
      "new a \\x.x\n",
      "new b \\x.x\n",
      "hasil \\x.x\n",
      "old a \\x.x\n",
      "old b bowl_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b bowl_NN_Ne_0\n",
      "hasil bowl_NN_Ne_0\n",
      "old a \\x.x\n",
      "old b bowl_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b bowl_NN_Ne_0\n",
      "hasil bowl_NN_Ne_0\n",
      "old a CC(delicious_JJ_P_8,hot_JJ_Ne_0)\n",
      "old b bowl_NN_Ne_0\n",
      "CC(delicious_JJ_P_8,hot_JJ_Ne_0) bowl_NN_Ne_0 -- ['bowl_NN_']\n",
      "new a \\x.x\n",
      "new b CC(bowl_NN_P_8,bowl_NN_Ne_0)\n",
      "hasil CC(bowl_NN_P_8,bowl_NN_Ne_0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ApplicationExpression CC(bowl_NN_P_8,bowl_NN_Ne_0)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_process(\"The bowl of squid eyeball stew is hot and delicious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bowl_NN_P_8', 'bowl_NN_N_0']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = '(\\w*?\\+?\\w*_NN_[P|N]_\\d)'\n",
    "re.findall(pattern, 'CC(bowl_NN_P_8,bowl_NN_N_0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def semua(collection):\n",
    "    df = pd.DataFrame(columns=['sentence', 'lambda', 'raw_aspect', 'aspect', 'sentiment'])\n",
    "    for data in collection:\n",
    "        hasil = glue_process(data)\n",
    "        \n",
    "        pattern = '(\\w*?\\+?\\w*_NN_[P|N]_\\d)'\n",
    "        aspek = re.findall(pattern, str(hasil))\n",
    "        aspect = []\n",
    "        sentiment = []\n",
    "        temp = ''\n",
    "        for asp in aspek:\n",
    "            temp = asp.split('_')\n",
    "            aspect.append(temp[0].replace('+', ' '))\n",
    "            sentiment.append(1 if temp[2] == 'P' else 0)\n",
    "            \n",
    "        df = df.append({'sentence': data, 'lambda': hasil,'raw_aspect': aspek, 'aspect': aspect, 'sentiment': sentiment}, ignore_index=True)\n",
    "    df.to_csv('hasil_ccg.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old a \\x.x\n",
      "old b purchase_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b purchase_NN_Ne_0\n",
      "hasil purchase_NN_Ne_0\n",
      "old a \\x.x\n",
      "old b purchase_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b purchase_NN_Ne_0\n",
      "hasil purchase_NN_Ne_0\n",
      "old a \\X.satisfied_VB_P_5(X)\n",
      "old b purchase_NN_Ne_0\n",
      "new a \\X.satisfied_VB_P_5(X)\n",
      "new b purchase_NN_Ne_0\n",
      "hasil satisfied_VB_P_5(purchase_NN_Ne_0)\n",
      "old a extremely_RB_I\n",
      "old b satisfied_VB_P_5(purchase_NN_Ne_0)\n",
      "satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "new a \\x.x\n",
      "new b satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "hasil satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "old a \\x.x\n",
      "old b satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "new a \\x.x\n",
      "new b satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "hasil satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "old a satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "old b CC\n",
      "new a CC\n",
      "new b satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "hasil CC(satisfied_VB_P_10(purchase_NN_Ne_0))\n",
      "old a \\x.x\n",
      "old b canon+powershot+g3_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b canon+powershot+g3_NN_Ne_0\n",
      "hasil canon+powershot+g3_NN_Ne_0\n",
      "old a \\X.purchased_VB_Ne_0(X)\n",
      "old b canon+powershot+g3_NN_Ne_0\n",
      "new a \\X.purchased_VB_Ne_0(X)\n",
      "new b canon+powershot+g3_NN_Ne_0\n",
      "hasil purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0)\n",
      "old a recently_RB_N\n",
      "old b purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0)\n",
      "new a \\x.x\n",
      "new b purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0)\n",
      "hasil purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0)\n",
      "old a CC(satisfied_VB_P_10(purchase_NN_Ne_0))\n",
      "old b purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0)\n",
      "new a CC(satisfied_VB_P_10(purchase_NN_Ne_0))\n",
      "new b purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0)\n",
      "hasil CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0))\n",
      "old a CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0))\n",
      "old b i_LS_Ne_0\n",
      "new a CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0))\n",
      "new b i_LS_Ne_0\n",
      "hasil CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0),i_LS_Ne_0)\n",
      "old a CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0),i_LS_Ne_0)\n",
      "old b \\x.x\n",
      "new a CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0),i_LS_Ne_0)\n",
      "new b \\x.x\n",
      "hasil CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_Ne_0),i_LS_Ne_0,\\x.x)\n",
      "old a past_JJ_N_0\n",
      "old b week_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b seq(past_JJ_N_0,week_NN_Ne_0)\n",
      "hasil seq(past_JJ_N_0,week_NN_Ne_0)\n",
      "old a \\x.x\n",
      "old b seq(past_JJ_N_0,week_NN_Ne_0)\n",
      "new a \\x.x\n",
      "new b seq(past_JJ_N_0,week_NN_Ne_0)\n",
      "hasil seq(past_JJ_N_0,week_NN_Ne_0)\n",
      "old a elderly_JJ_P_5\n",
      "old b group_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b seq(elderly_JJ_P_5,group_NN_Ne_0)\n",
      "hasil seq(elderly_JJ_P_5,group_NN_Ne_0)\n",
      "old a \\X.vacationing_VB_P_1(X)\n",
      "old b seq(elderly_JJ_P_5,group_NN_Ne_0)\n",
      "new a \\X.vacationing_VB_P_1(X)\n",
      "new b seq(elderly_JJ_P_5,group_NN_Ne_0)\n",
      "hasil vacationing_VB_P_1(seq(elderly_JJ_P_5,group_NN_Ne_0))\n",
      "old a \\x.x\n",
      "old b vacationing_VB_P_1(seq(elderly_JJ_P_5,group_NN_Ne_0))\n",
      "new a \\x.x\n",
      "new b vacationing_VB_P_1(seq(elderly_JJ_P_5,group_NN_Ne_0))\n",
      "hasil vacationing_VB_P_1(seq(elderly_JJ_P_5,group_NN_Ne_0))\n",
      "old a of\n",
      "old b vacationing_VB_P_1(seq(elderly_JJ_P_5,group_NN_Ne_0))\n",
      "new a \\x.x\n",
      "new b \\x.x\n",
      "hasil \\x.x\n",
      "old a \\x.x\n",
      "old b picture_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b picture_NN_Ne_0\n",
      "hasil picture_NN_Ne_0\n",
      "old a \\x.x\n",
      "old b picture_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b picture_NN_Ne_0\n",
      "hasil picture_NN_Ne_0\n",
      "old a \\X.take_VB_Ne_0(X)\n",
      "old b picture_NN_Ne_0\n",
      "new a \\X.take_VB_Ne_0(X)\n",
      "new b picture_NN_Ne_0\n",
      "hasil take_VB_Ne_0(picture_NN_Ne_0)\n",
      "old a \\x.x\n",
      "old b take_VB_Ne_0(picture_NN_Ne_0)\n",
      "new a \\x.x\n",
      "new b take_VB_Ne_0(picture_NN_Ne_0)\n",
      "hasil take_VB_Ne_0(picture_NN_Ne_0)\n",
      "old a \\X.asked_VB_Ne_0(X)\n",
      "old b take_VB_Ne_0(picture_NN_Ne_0)\n",
      "new a \\X.asked_VB_Ne_0(X)\n",
      "new b take_VB_Ne_0(picture_NN_Ne_0)\n",
      "hasil asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0))\n",
      "old a \\X.was_VB_Ne_0(X)\n",
      "old b asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0))\n",
      "new a \\X.was_VB_Ne_0(X)\n",
      "new b asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0))\n",
      "hasil was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)))\n",
      "old a seq(past_JJ_N_0,week_NN_Ne_0)\n",
      "old b \\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0)\n",
      "new a seq(past_JJ_N_0,week_NN_Ne_0)\n",
      "new b \\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0)\n",
      "hasil seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0))\n",
      "old a recent_JJ_Ne_0\n",
      "old b trip_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b seq(recent_JJ_Ne_0,trip_NN_Ne_0)\n",
      "hasil seq(recent_JJ_Ne_0,trip_NN_Ne_0)\n",
      "old a \\x.x\n",
      "old b seq(recent_JJ_Ne_0,trip_NN_Ne_0)\n",
      "new a \\x.x\n",
      "new b seq(recent_JJ_Ne_0,trip_NN_Ne_0)\n",
      "hasil seq(recent_JJ_Ne_0,trip_NN_Ne_0)\n",
      "old a seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0))\n",
      "old b seq(recent_JJ_Ne_0,trip_NN_Ne_0)\n",
      "new a seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0))\n",
      "new b seq(recent_JJ_Ne_0,trip_NN_Ne_0)\n",
      "hasil seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0))\n",
      "old a \\x.x\n",
      "old b seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0))\n",
      "new a \\x.x\n",
      "new b seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0))\n",
      "hasil seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0))\n",
      "old a seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0))\n",
      "old b fact_NN_Ne_0\n",
      "new a seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0))\n",
      "new b fact_NN_Ne_0\n",
      "hasil seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0)\n",
      "old a \\x.x\n",
      "old b seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0)\n",
      "new a \\x.x\n",
      "new b seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0)\n",
      "hasil seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0)\n",
      "old a \\x.x\n",
      "old b \\X.use_VB_Ne_0(X)\n",
      "new a \\x.x\n",
      "new b \\X.use_VB_Ne_0(X)\n",
      "hasil \\X.use_VB_Ne_0(X)\n",
      "old a easy_JJ_P_6\n",
      "old b \\X.use_VB_Ne_0(X)\n",
      "new a easy_JJ_P_6\n",
      "new b \\X.use_VB_Ne_0(X)\n",
      "hasil easy_JJ_P_6(\\X.use_VB_Ne_0(X))\n",
      "old a very_RB_I\n",
      "old b easy_JJ_P_6(\\X.use_VB_Ne_0(X))\n",
      "easy_JJ_P_6(\\X.use_VB_Ne_0(X))\n",
      "new a \\x.x\n",
      "new b easy_JJ_P_6(\\X.use_VB_Ne_0(X))\n",
      "hasil easy_JJ_P_6(\\X.use_VB_Ne_0(X))\n",
      "old a \\x.x\n",
      "old b easy_JJ_P_6(\\X.use_VB_Ne_0(X))\n",
      "new a \\x.x\n",
      "new b easy_JJ_P_6(\\X.use_VB_Ne_0(X))\n",
      "hasil easy_JJ_P_6(\\X.use_VB_Ne_0(X))\n",
      "old a easy_JJ_P_6(\\X.use_VB_Ne_0(X))\n",
      "old b \\x.x\n",
      "new a easy_JJ_P_6(\\X.use_VB_Ne_0(X))\n",
      "new b \\x.x\n",
      "hasil easy_JJ_P_6(\\X.use_VB_Ne_0(X),\\x.x)\n",
      "old a seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0)\n",
      "old b easy_JJ_P_6(\\X.use_VB_Ne_0(X),\\x.x)\n",
      "new a seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0)\n",
      "new b easy_JJ_P_6(\\X.use_VB_Ne_0(X),\\x.x)\n",
      "hasil seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0,easy_JJ_P_6(\\X.use_VB_Ne_0(X),\\x.x))\n",
      "old a \\x.x\n",
      "old b camera_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b camera_NN_Ne_0\n",
      "hasil camera_NN_Ne_0\n",
      "old a seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0,easy_JJ_P_6(\\X.use_VB_Ne_0(X),\\x.x))\n",
      "old b camera_NN_Ne_0\n",
      "new a seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0,easy_JJ_P_6(\\X.use_VB_Ne_0(X),\\x.x))\n",
      "new b camera_NN_Ne_0\n",
      "hasil seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0,easy_JJ_P_6(\\X.use_VB_Ne_0(X),\\x.x),camera_NN_Ne_0)\n",
      "old a seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0,easy_JJ_P_6(\\X.use_VB_Ne_0(X),\\x.x),camera_NN_Ne_0)\n",
      "old b \\x.x\n",
      "new a seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0,easy_JJ_P_6(\\X.use_VB_Ne_0(X),\\x.x),camera_NN_Ne_0)\n",
      "new b \\x.x\n",
      "hasil seq(past_JJ_N_0,week_NN_Ne_0,\\x.was_VB_Ne_0(asked_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0)),x,i_FW_Ne_0),seq(recent_JJ_Ne_0,trip_NN_Ne_0),fact_NN_Ne_0,easy_JJ_P_6(\\X.use_VB_Ne_0(X),\\x.x),camera_NN_Ne_0,\\x.x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old a \\x.x\n",
      "old b camera_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b camera_NN_Ne_0\n",
      "hasil camera_NN_Ne_0\n",
      "old a \\x.x\n",
      "old b camera_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b camera_NN_Ne_0\n",
      "hasil camera_NN_Ne_0\n",
      "old a \\x.x\n",
      "old b picture_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b picture_NN_Ne_0\n",
      "hasil picture_NN_Ne_0\n",
      "old a \\X.took_VB_Ne_0(X)\n",
      "old b picture_NN_Ne_0\n",
      "new a \\X.took_VB_Ne_0(X)\n",
      "new b picture_NN_Ne_0\n",
      "hasil took_VB_Ne_0(picture_NN_Ne_0)\n",
      "old a camera_NN_Ne_0\n",
      "old b took_VB_Ne_0(picture_NN_Ne_0)\n",
      "new a camera_NN_Ne_0\n",
      "new b took_VB_Ne_0(picture_NN_Ne_0)\n",
      "hasil camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0))\n",
      "old a camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0))\n",
      "old b i_FW_Ne_0\n",
      "new a camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0))\n",
      "new b i_FW_Ne_0\n",
      "hasil camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0),i_FW_Ne_0)\n",
      "old a \\x.x\n",
      "old b camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0),i_FW_Ne_0)\n",
      "new a \\x.x\n",
      "new b camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0),i_FW_Ne_0)\n",
      "hasil camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0),i_FW_Ne_0)\n",
      "old a of\n",
      "old b us_PRP_Ne_0\n",
      "new a \\x.x\n",
      "new b \\x.x\n",
      "hasil \\x.x\n",
      "old a \\x.x\n",
      "old b picture_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b picture_NN_Ne_0\n",
      "hasil picture_NN_Ne_0\n",
      "old a \\x.x\n",
      "old b picture_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b picture_NN_Ne_0\n",
      "hasil picture_NN_Ne_0\n",
      "old a \\X.take_VB_Ne_0(X)\n",
      "old b picture_NN_Ne_0\n",
      "new a \\X.take_VB_Ne_0(X)\n",
      "new b picture_NN_Ne_0\n",
      "hasil take_VB_Ne_0(picture_NN_Ne_0)\n",
      "old a \\x.x\n",
      "old b take_VB_Ne_0(picture_NN_Ne_0)\n",
      "new a \\x.x\n",
      "new b take_VB_Ne_0(picture_NN_Ne_0)\n",
      "hasil take_VB_Ne_0(picture_NN_Ne_0)\n",
      "old a \\X.offered_VB_Ne_0(X)\n",
      "old b take_VB_Ne_0(picture_NN_Ne_0)\n",
      "new a \\X.offered_VB_Ne_0(X)\n",
      "new b take_VB_Ne_0(picture_NN_Ne_0)\n",
      "hasil offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0))\n",
      "old a offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0))\n",
      "old b they_PRP_Ne_0\n",
      "new a offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0))\n",
      "new b they_PRP_Ne_0\n",
      "hasil offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0),they_PRP_Ne_0)\n",
      "old a \\x.x\n",
      "old b offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0),they_PRP_Ne_0)\n",
      "new a \\x.x\n",
      "new b offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0),they_PRP_Ne_0)\n",
      "hasil offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0),they_PRP_Ne_0)\n",
      "old a camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0),i_FW_Ne_0)\n",
      "old b offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0),they_PRP_Ne_0)\n",
      "new a camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0),i_FW_Ne_0)\n",
      "new b offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0),they_PRP_Ne_0)\n",
      "hasil camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0),i_FW_Ne_0,offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0),they_PRP_Ne_0))\n",
      "old a camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0),i_FW_Ne_0,offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0),they_PRP_Ne_0))\n",
      "old b \\x.x\n",
      "new a camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0),i_FW_Ne_0,offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0),they_PRP_Ne_0))\n",
      "new b \\x.x\n",
      "hasil camera_NN_Ne_0(took_VB_Ne_0(picture_NN_Ne_0),i_FW_Ne_0,offered_VB_Ne_0(take_VB_Ne_0(picture_NN_Ne_0),they_PRP_Ne_0),\\x.x)\n",
      "old a \\X.told_VB_Ne_0(X)\n",
      "old b them_PRP_Ne_0\n",
      "new a \\X.told_VB_Ne_0(X)\n",
      "new b them_PRP_Ne_0\n",
      "hasil told_VB_Ne_0(them_PRP_Ne_0)\n",
      "old a \\x.x\n",
      "old b box_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b box_NN_Ne_0\n",
      "hasil box_NN_Ne_0\n",
      "old a \\x.x\n",
      "old b box_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b box_NN_Ne_0\n",
      "hasil box_NN_Ne_0\n",
      "old a \\X.press_VB_Ne_0(X)\n",
      "old b CC\n",
      "new a CC\n",
      "new b \\X.press_VB_Ne_0(X)\n",
      "hasil CC(\\X.press_VB_Ne_0(X))\n",
      "old a green_JJ_N_0\n",
      "old b \\X.turn_VB_Ne_0(X)\n",
      "new a green_JJ_N_0\n",
      "new b \\X.turn_VB_Ne_0(X)\n",
      "hasil green_JJ_N_0(\\X.turn_VB_Ne_0(X))\n",
      "old a CC(\\X.press_VB_Ne_0(X))\n",
      "old b green_JJ_N_0(\\X.turn_VB_Ne_0(X))\n",
      "new a CC(\\X.press_VB_Ne_0(X))\n",
      "new b green_JJ_N_0(\\X.turn_VB_Ne_0(X))\n",
      "hasil CC(\\X.press_VB_Ne_0(X),green_JJ_N_0(\\X.turn_VB_Ne_0(X)))\n",
      "old a \\x.x\n",
      "old b way_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b way_NN_Ne_0\n",
      "hasil way_NN_Ne_0\n",
      "old a of\n",
      "old b way_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b \\x.x\n",
      "hasil \\x.x\n",
      "old a \\x.x\n",
      "old b rest_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b rest_NN_Ne_0\n",
      "hasil rest_NN_Ne_0\n",
      "old a \\x.x\n",
      "old b rest_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b rest_NN_Ne_0\n",
      "hasil rest_NN_Ne_0\n",
      "old a CC(\\X.press_VB_Ne_0(X),green_JJ_N_0(\\X.turn_VB_Ne_0(X)))\n",
      "old b rest_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))\n",
      "hasil CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))\n",
      "old a \\x.x\n",
      "old b CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))\n",
      "new a \\x.x\n",
      "new b CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))\n",
      "hasil CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))\n",
      "old a box_NN_Ne_0\n",
      "old b CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))\n",
      "new a box_NN_Ne_0\n",
      "new b CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))\n",
      "hasil box_NN_Ne_0(CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X))))\n",
      "old a \\X.wait_VB_Ne_0(X)\n",
      "old b box_NN_Ne_0(CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X))))\n",
      "new a \\X.wait_VB_Ne_0(X)\n",
      "new b box_NN_Ne_0(CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X))))\n",
      "hasil wait_VB_Ne_0(box_NN_Ne_0(CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))))\n",
      "old a wait_VB_Ne_0(box_NN_Ne_0(CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))))\n",
      "old b \\x.x\n",
      "new a wait_VB_Ne_0(box_NN_Ne_0(CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))))\n",
      "new b \\x.x\n",
      "hasil wait_VB_Ne_0(box_NN_Ne_0(CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))),\\x.x)\n",
      "old a press_NN_Ne_0\n",
      "old b halfway_RB_N\n",
      "new a press_NN_Ne_0\n",
      "new b halfway_RB_N\n",
      "hasil press_NN_Ne_0(halfway_RB_N)\n",
      "old a wait_VB_Ne_0(box_NN_Ne_0(CC(\\X.press_VB_Ne_0(X),rest_NN_N_0(\\X.turn_VB_Ne_0(X)))),\\x.x)\n",
      "old b press_NN_Ne_0(halfway_RB_N)\n"
     ]
    },
    {
     "ename": "LogicalExpressionException",
     "evalue": "End of input found.  Expression expected.\n\n^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\sem\\logic.py\u001b[0m in \u001b[0;36mtoken\u001b[1;34m(self, location)\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m                 \u001b[0mtok\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_currentIndex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_currentIndex\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExpectedMoreTokensException\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\sem\\logic.py\u001b[0m in \u001b[0;36mprocess_next_expression\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             \u001b[0mtok\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mExpectedMoreTokensException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\sem\\logic.py\u001b[0m in \u001b[0;36mtoken\u001b[1;34m(self, location)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExpectedMoreTokensException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_currentIndex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExpectedMoreTokensException\u001b[0m: End of input found.  More tokens expected.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExpectedMoreTokensException\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\sem\\logic.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, data, signature)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_next_expression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minRange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\sem\\logic.py\u001b[0m in \u001b[0;36mprocess_next_expression\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m    288\u001b[0m             raise ExpectedMoreTokensException(\n\u001b[1;32m--> 289\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_currentIndex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Expression expected.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             )\n",
      "\u001b[1;31mExpectedMoreTokensException\u001b[0m: End of input found.  Expression expected.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLogicalExpressionException\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-c62abe96de9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msemua\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-117-28445a9808e6>\u001b[0m in \u001b[0;36msemua\u001b[1;34m(collection)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lambda'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'raw_aspect'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'aspect'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollection\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mhasil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglue_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'(\\w*?\\+?\\w*_NN_[P|N]_\\d)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-112-f89a7f3a1f22>\u001b[0m in \u001b[0;36mglue_process\u001b[1;34m(sent)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#     print(tree)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-122-960c2d9b3603>\u001b[0m in \u001b[0;36mlambda_calculus\u001b[1;34m(tree, swn_score)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0msecond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;31m# rekursi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-122-960c2d9b3603>\u001b[0m in \u001b[0;36mlambda_calculus\u001b[1;34m(tree, swn_score)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0msecond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;31m# rekursi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-122-960c2d9b3603>\u001b[0m in \u001b[0;36mlambda_calculus\u001b[1;34m(tree, swn_score)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0msecond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;31m# rekursi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-122-960c2d9b3603>\u001b[0m in \u001b[0;36mlambda_calculus\u001b[1;34m(tree, swn_score)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0msecond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;31m# rekursi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-122-960c2d9b3603>\u001b[0m in \u001b[0;36mlambda_calculus\u001b[1;34m(tree, swn_score)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0msecond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;31m# rekursi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-122-960c2d9b3603>\u001b[0m in \u001b[0;36mlambda_calculus\u001b[1;34m(tree, swn_score)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0msecond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;31m# rekursi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_calculus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswn_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-124-dc954ed80fee>\u001b[0m in \u001b[0;36mdeduction\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'CC\\('\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_noun_exist_in_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_expr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\x.x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_expr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplacer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[0mr_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'PRP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FW'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'LS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'JJ'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\sem\\logic.py\u001b[0m in \u001b[0;36mfromstring\u001b[1;34m(cls, s, type_check, signature)\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_type_checking_logic_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logic_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0madditional\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\sem\\logic.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, data, signature)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLogicalExpressionException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s\\n%s\\n%s^'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mLogicalExpressionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLogicalExpressionException\u001b[0m: End of input found.  Expression expected.\n\n^"
     ]
    }
   ],
   "source": [
    "# input file\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "# preprocess\n",
    "sentences = df['review']\n",
    "labels = df[\"target\"]\n",
    "\n",
    "semua(sentences[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old a \\x.x\n",
      "old b purchase_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b purchase_NN_Ne_0\n",
      "hasil purchase_NN_Ne_0\n",
      "old a \\x.x\n",
      "old b purchase_NN_Ne_0\n",
      "new a \\x.x\n",
      "new b purchase_NN_Ne_0\n",
      "hasil purchase_NN_Ne_0\n",
      "old a \\X.satisfied_VB_P_5(X)\n",
      "old b purchase_NN_Ne_0\n",
      "new a \\X.satisfied_VB_P_5(X)\n",
      "new b purchase_NN_Ne_0\n",
      "hasil satisfied_VB_P_5(purchase_NN_Ne_0)\n",
      "old a extremely_RB_I\n",
      "old b satisfied_VB_P_5(purchase_NN_Ne_0)\n",
      "satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "new a \\x.x\n",
      "new b satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "hasil satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "old a \\x.x\n",
      "old b satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "new a \\x.x\n",
      "new b satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "hasil satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "old a satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "old b CC\n",
      "new a CC\n",
      "new b satisfied_VB_P_10(purchase_NN_Ne_0)\n",
      "hasil CC(satisfied_VB_P_10(purchase_NN_Ne_0))\n",
      "old a \\x.x\n",
      "old b canon+powershot+g3_NN_N_0\n",
      "new a \\x.x\n",
      "new b canon+powershot+g3_NN_N_0\n",
      "hasil canon+powershot+g3_NN_N_0\n",
      "old a \\X.purchased_VB_Ne_0(X)\n",
      "old b canon+powershot+g3_NN_N_0\n",
      "new a \\X.purchased_VB_Ne_0(X)\n",
      "new b canon+powershot+g3_NN_N_0\n",
      "hasil purchased_VB_Ne_0(canon+powershot+g3_NN_N_0)\n",
      "old a recently_RB_N\n",
      "old b purchased_VB_Ne_0(canon+powershot+g3_NN_N_0)\n",
      "new a \\x.x\n",
      "new b purchased_VB_Ne_0(canon+powershot+g3_NN_N_0)\n",
      "hasil purchased_VB_Ne_0(canon+powershot+g3_NN_N_0)\n",
      "old a CC(satisfied_VB_P_10(purchase_NN_Ne_0))\n",
      "old b purchased_VB_Ne_0(canon+powershot+g3_NN_N_0)\n",
      "new a CC(satisfied_VB_P_10(purchase_NN_Ne_0))\n",
      "new b purchased_VB_Ne_0(canon+powershot+g3_NN_N_0)\n",
      "hasil CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_N_0))\n",
      "old a CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_N_0))\n",
      "old b i_LS_Ne_0\n",
      "new a CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_N_0))\n",
      "new b i_LS_Ne_0\n",
      "hasil CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_N_0),i_LS_Ne_0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ApplicationExpression CC(satisfied_VB_P_10(purchase_NN_Ne_0),purchased_VB_Ne_0(canon+powershot+g3_NN_N_0),i_LS_Ne_0)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_process('i recently purchased the canon powershot g3 and am extremely satisfied with the purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(10, 17), match='VB_Ne_0'>\n"
     ]
    }
   ],
   "source": [
    "p = re.search(r'VB_\\w*_\\d*', 'purchased_VB_Ne_0(canon+powershot+g3_NN_N_0)')\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
