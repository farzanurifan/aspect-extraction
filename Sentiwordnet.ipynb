{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 4.85966157913208 secs.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from pywsd.lesk import simple_lesk\n",
    "from pywsd.lesk import cosine_lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import requests\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "dependency_parser = nlp.annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "breakdown = swn.senti_synset('good.n.01')\n",
    "print(breakdown.pos_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('love.n.01'),\n",
       " Synset('love.n.02'),\n",
       " Synset('beloved.n.01'),\n",
       " Synset('love.n.04'),\n",
       " Synset('love.n.05'),\n",
       " Synset('sexual_love.n.02'),\n",
       " Synset('love.v.01'),\n",
       " Synset('love.v.02'),\n",
       " Synset('love.v.03'),\n",
       " Synset('sleep_together.v.01')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_lexicon = []\n",
    "negative_lexicon = []\n",
    "\n",
    "def read_lexicon():\n",
    "    global positive_lexicon;\n",
    "    global negative_lexicon;\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('opinion-lexicon-English/') , 'positive-words.txt'), 'r') as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "         \n",
    "        positive_lexicon = file.readlines()\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('opinion-lexicon-English/') , 'negative-words.txt'), 'r', encoding = \"ISO-8859-1\") as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "        \n",
    "        negative_lexicon = file.readlines()\n",
    "        \n",
    "    positive_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), positive_lexicon))\n",
    "    negative_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), negative_lexicon))\n",
    "    \n",
    "        \n",
    "read_lexicon()\n",
    "op_set = positive_lexicon + negative_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import re\n",
    "import pandas as pd\n",
    "import itertools, nltk, string \n",
    "\n",
    "def read_file(file):\n",
    "    f = open(file, 'r')\n",
    "\n",
    "    pattern_title = '\\[t\\]'\n",
    "    pattern_sentence = '(?<=##).+'\n",
    "    pattern_aspect = '.+(?=##)'\n",
    "\n",
    "    review = []\n",
    "    for a in f:\n",
    "        if re.search('##', a):\n",
    "            sentence = re.findall(pattern_sentence, a)[0]\n",
    "            aspect = re.findall(pattern_aspect, a)\n",
    "            if len(aspect) > 0:\n",
    "                aspect = aspect[0]\n",
    "            else:\n",
    "                aspect = ''\n",
    "            review.append((sentence, aspect))\n",
    "\n",
    "    df = pd.DataFrame(columns=['review','target'])\n",
    "    for r in review:\n",
    "        df = df.append({'review': r[0], 'target': r[1]}, ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag(sentence):\n",
    "    result = dependency_parser(sentence, properties={\"outputFormat\": \"json\", \"annotators\": \"pos\"})['sentences'][0]['tokens']\n",
    "    res = []\n",
    "    for pos in result:\n",
    "        res.append((pos['word'], pos['pos']))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(sentence, key, tagged_sentence):\n",
    "    flag = True\n",
    "    \n",
    "    tagged = ('','')\n",
    "    for p in tagged_sentence:\n",
    "        if p[0] == key:\n",
    "            tagged = p\n",
    "    if tagged == ('', ''):\n",
    "        flag = False\n",
    "\n",
    "    ambiguous = tagged[0]\n",
    "    tag = tagged[1]\n",
    "    pos = ''\n",
    "\n",
    "    if 'NN' in tag:\n",
    "        pos = 'n'\n",
    "    elif 'NNS' in tag:\n",
    "        pos = 'nns'\n",
    "    elif 'VB' in tag:\n",
    "        pos = 'v'\n",
    "    elif 'VBG' in tag:\n",
    "        pos = 'v'\n",
    "    elif 'JJ' in tag:\n",
    "        pos = 'a'\n",
    "    elif 'RB' in tag:\n",
    "        pos = 'r'\n",
    "    else:\n",
    "        flag = False\n",
    "\n",
    "    endscore = 0\n",
    "    if flag:\n",
    "        answer = cosine_lesk(sentence, ambiguous, pos)\n",
    "        if answer:\n",
    "            score = swn.senti_synset(answer.name())\n",
    "\n",
    "            if score.pos_score() > score.neg_score():\n",
    "                endscore = score.pos_score()\n",
    "            else:\n",
    "                endscore = score.neg_score() * (-1)\n",
    "    return endscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_score(sentence):\n",
    "    scores = []\n",
    "    tagged_sentence = pos_tag(sentence)\n",
    "    for word in sentence.split(' '):\n",
    "        if word in op_set:\n",
    "            score = get_score(sentence, word, tagged_sentence)\n",
    "            scores.append(score)\n",
    "    if len(scores):\n",
    "        return np.mean(scores)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_program(review, target, filename):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    index = 0\n",
    "    for sentence in review:\n",
    "        aspects = target[index].split(',')\n",
    "        label = 0\n",
    "        if aspects[0] != '':\n",
    "            for aspect in aspects:\n",
    "                try:\n",
    "                    tanda = aspect.split('[')[1][0]\n",
    "                    angka = aspect.split('[')[1][1]\n",
    "                    if tanda == '+':\n",
    "                        label += int(angka)\n",
    "                    else:\n",
    "                        label -= int(angka)\n",
    "                except:\n",
    "                    print(aspect)\n",
    "        \n",
    "        score = get_sentence_score(sentence)\n",
    "        \n",
    "        if label > 0:\n",
    "            labels.append(1)\n",
    "        elif label < 0:\n",
    "            labels.append(2)\n",
    "        else:            \n",
    "            labels.append(0)\n",
    "            \n",
    "        if score > 0:\n",
    "            scores.append(1)\n",
    "        elif score < 0:\n",
    "            scores.append(2)\n",
    "        else:            \n",
    "            scores.append(0)\n",
    "            \n",
    "        index += 1\n",
    "    \n",
    "    data = { 'review':review, 'label': labels, 'prediction': scores}\n",
    "    out = pd.DataFrame(data)\n",
    "    out.to_csv(filename)\n",
    "    \n",
    "    return labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_file('dataset/bing_liu/Nikon coolpix 4300.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, pred = main_program(df['review'], df['target'], 'sentiwordnet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actu = pd.Series(label, name='Actual')\n",
    "y_pred = pd.Series(pred, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>75</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1   2\n",
       "Actual                \n",
       "0          112  54  21\n",
       "1           34  75  20\n",
       "2           14   6  10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "cm = ConfusionMatrix(label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted    0    1   2  __all__\n",
      "Actual                          \n",
      "0          112   54  21      187\n",
      "1           34   75  20      129\n",
      "2           14    6  10       30\n",
      "__all__    160  135  51      346\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.569364161849711\n",
      "95% CI: (0.5153378774354668, 0.6221930440346766)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 4.250370715909964e-05\n",
      "Kappa: 0.27236030542970446\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                       0         1          2\n",
      "Population                                  346       346        346\n",
      "P: Condition positive                       187       129         30\n",
      "N: Condition negative                       159       217        316\n",
      "Test outcome positive                       160       135         51\n",
      "Test outcome negative                       186       211        295\n",
      "TP: True Positive                           112        75         10\n",
      "TN: True Negative                           111       157        275\n",
      "FP: False Positive                           48        60         41\n",
      "FN: False Negative                           75        54         20\n",
      "TPR: (Sensitivity, hit rate, recall)    0.59893  0.581395   0.333333\n",
      "TNR=SPC: (Specificity)                 0.698113  0.723502   0.870253\n",
      "PPV: Pos Pred Value (Precision)             0.7  0.555556   0.196078\n",
      "NPV: Neg Pred Value                    0.596774  0.744076   0.932203\n",
      "FPR: False-out                         0.301887  0.276498   0.129747\n",
      "FDR: False Discovery Rate                   0.3  0.444444   0.803922\n",
      "FNR: Miss Rate                          0.40107  0.418605   0.666667\n",
      "ACC: Accuracy                          0.644509   0.67052   0.823699\n",
      "F1 score                               0.645533  0.568182   0.246914\n",
      "MCC: Matthews correlation coefficient  0.296909  0.302253   0.161606\n",
      "Informedness                           0.297044  0.304898   0.203586\n",
      "Markedness                             0.296774  0.299631   0.128282\n",
      "Prevalence                             0.540462  0.372832  0.0867052\n",
      "LR+: Positive likelihood ratio          1.98396   2.10271    2.56911\n",
      "LR-: Negative likelihood ratio         0.574505  0.578581   0.766061\n",
      "DOR: Diagnostic odds ratio              3.45333   3.63426    3.35366\n",
      "FOR: False omission rate               0.403226  0.255924  0.0677966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\stats.py:60: FutureWarning: supplying multiple axes to axis is deprecated and will be removed in a future version.\n",
      "  num = df[df > 1].dropna(axis=[0, 1], thresh=1).applymap(lambda n: choose(n, 2)).sum().sum() - np.float64(nis2 * njs2) / n2\n"
     ]
    }
   ],
   "source": [
    "cm.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
