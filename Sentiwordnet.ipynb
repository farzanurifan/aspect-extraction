{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from pywsd.lesk import simple_lesk\n",
    "from pywsd.lesk import cosine_lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import requests\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "dependency_parser = nlp.annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "breakdown = swn.senti_synset('good.n.01')\n",
    "print(breakdown.pos_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('love.n.01'),\n",
       " Synset('love.n.02'),\n",
       " Synset('beloved.n.01'),\n",
       " Synset('love.n.04'),\n",
       " Synset('love.n.05'),\n",
       " Synset('sexual_love.n.02'),\n",
       " Synset('love.v.01'),\n",
       " Synset('love.v.02'),\n",
       " Synset('love.v.03'),\n",
       " Synset('sleep_together.v.01')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_lexicon = []\n",
    "negative_lexicon = []\n",
    "\n",
    "def read_lexicon():\n",
    "    global positive_lexicon;\n",
    "    global negative_lexicon;\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('opinion-lexicon-English/') , 'positive-words.txt'), 'r') as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "         \n",
    "        positive_lexicon = file.readlines()\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('opinion-lexicon-English/') , 'negative-words.txt'), 'r', encoding = \"ISO-8859-1\") as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "        \n",
    "        negative_lexicon = file.readlines()\n",
    "        \n",
    "    positive_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), positive_lexicon))\n",
    "    negative_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), negative_lexicon))\n",
    "    \n",
    "        \n",
    "read_lexicon()\n",
    "op_set = positive_lexicon + negative_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import re\n",
    "import pandas as pd\n",
    "import itertools, nltk, string \n",
    "\n",
    "def read_file(file):\n",
    "    f = open(file, 'r')\n",
    "\n",
    "    pattern_title = '\\[t\\]'\n",
    "    pattern_sentence = '(?<=##).+'\n",
    "    pattern_aspect = '.+(?=##)'\n",
    "\n",
    "    review = []\n",
    "    for a in f:\n",
    "        if re.search('##', a):\n",
    "            sentence = re.findall(pattern_sentence, a)[0]\n",
    "            aspect = re.findall(pattern_aspect, a)\n",
    "            if len(aspect) > 0:\n",
    "                aspect = aspect[0]\n",
    "            else:\n",
    "                aspect = ''\n",
    "            review.append((sentence, aspect))\n",
    "\n",
    "    df = pd.DataFrame(columns=['review','target'])\n",
    "    for r in review:\n",
    "        df = df.append({'review': r[0], 'target': r[1]}, ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag(sentence):\n",
    "    result = dependency_parser(sentence, properties={\"outputFormat\": \"json\", \"annotators\": \"pos\"})['sentences'][0]['tokens']\n",
    "    res = []\n",
    "    for pos in result:\n",
    "        res.append((pos['word'], pos['pos']))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(sentence, key, tagged_sentence):\n",
    "    flag = True\n",
    "    \n",
    "    tagged = ('','')\n",
    "    for p in tagged_sentence:\n",
    "        if p[0] == key:\n",
    "            tagged = p\n",
    "    if tagged == ('', ''):\n",
    "        flag = False\n",
    "\n",
    "    ambiguous = tagged[0]\n",
    "    tag = tagged[1]\n",
    "    pos = ''\n",
    "\n",
    "    if 'NN' in tag:\n",
    "        pos = 'n'\n",
    "    elif 'NNS' in tag:\n",
    "        pos = 'nns'\n",
    "    elif 'VB' in tag:\n",
    "        pos = 'v'\n",
    "    elif 'VBG' in tag:\n",
    "        pos = 'v'\n",
    "    elif 'JJ' in tag:\n",
    "        pos = 'a'\n",
    "    elif 'RB' in tag:\n",
    "        pos = 'r'\n",
    "    else:\n",
    "        flag = False\n",
    "\n",
    "    endscore = 0\n",
    "    if flag:\n",
    "        answer = cosine_lesk(sentence, ambiguous, pos)\n",
    "        if answer:\n",
    "            score = swn.senti_synset(answer.name())\n",
    "\n",
    "            if score.pos_score() > score.neg_score():\n",
    "                endscore = score.pos_score()\n",
    "            else:\n",
    "                endscore = score.neg_score() * (-1)\n",
    "    return endscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_score(sentence):\n",
    "    scores = []\n",
    "    tagged_sentence = pos_tag(sentence)\n",
    "    for word in sentence.split(' '):\n",
    "#         if word in op_set:\n",
    "        score = get_score(sentence, word, tagged_sentence)\n",
    "        scores.append(score)\n",
    "    if len(scores):\n",
    "        return np.mean(scores)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_program(review, target, filename):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    index = 0\n",
    "    for sentence in review:\n",
    "        aspects = target[index].split(',')\n",
    "        label = 0\n",
    "        if aspects[0] != '':\n",
    "            for aspect in aspects:\n",
    "                try:\n",
    "                    tanda = aspect.split('[')[1][0]\n",
    "                    angka = aspect.split('[')[1][1]\n",
    "                    if tanda == '+':\n",
    "                        label += int(angka)\n",
    "                    else:\n",
    "                        label -= int(angka)\n",
    "                except:\n",
    "                    pass\n",
    "#                     print(aspect)\n",
    "\n",
    "            score = get_sentence_score(sentence)\n",
    "\n",
    "            if label > 0:\n",
    "                labels.append(1)\n",
    "            elif label <= 0:\n",
    "                labels.append(2)\n",
    "    #         else:            \n",
    "    #             labels.append(0)\n",
    "\n",
    "            if score > 0:\n",
    "                scores.append(1)\n",
    "            elif score <= 0:\n",
    "                if(score == 0):\n",
    "                    print(aspects, sentence)\n",
    "                scores.append(2)\n",
    "    #         else:            \n",
    "    #             scores.append(0)\n",
    "            \n",
    "        index += 1\n",
    "    \n",
    "#     data = { 'review':review, 'label': labels, 'prediction': scores}\n",
    "#     out = pd.DataFrame(data)\n",
    "#     out.to_csv(filename)\n",
    "    \n",
    "    return labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_file('dataset/bing_liu/Nikon coolpix 4300.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transfer[-2]'] 1 . pictures wo n't transfer to pc directly from the camera using the included transfer cable . \n",
      "['auto mode[-2]'] . this camera keeps on autofocussing in auto mode with a buzzing sound which can 't be stopped . \n",
      "['image[-2]'] . even the slightest of the shakes totally distorts your image \n",
      "['indoor image[-2]'] . images taken indoor were n't so clear . \n",
      "['lens cap[-3]'] . lens cap is a really annoying \n",
      "['movie[-2]'] . the movie clips taken will always have some ' noise ' in it - you can 't avoid that . \n",
      "['indoor picture[-1]'] 1 . pictures taken in an indoor setting are a little dull and rarely hazy if you tend to take photographs from a distance . \n",
      "['delay[-2][u]'] 2 . it takes a while for the camera to actually capture the photograph from the time you click the button and i have seen people becoming a little impatient waiting for the flash to glow . \n",
      "['picture[-2]'] 3 . the pictures come out hazy if your hands shake even for a moment during the entire process of taking a picture . \n",
      "['sunset feature[+3]'] sunset feature takes incredible pics in the morning , and the evening ! \n",
      "['camera[+3]'] great camera , great investment ! \n",
      "['software[+3]', ' online service[+2]'] the software that comes with it is amazing and the online service that comes free is really very neat. clean clear and well focused on over 95 % of all photos taken by a beginner . \n",
      "['photo[+2]'] just point and shoot and the photos were great . \n",
      "['camera[+2]'] if you have to buy a camera on a buget, this has got to be the one . \n",
      "['macro[+2]'] i particularly like the way it aids me in taking my macro shots . \n",
      "['optical zoom[-1]'] it has a 3x optical zoom , which is average for these cameras . \n",
      "['picture[+3]'] the picturers are amazing . \n",
      "['camera[+2]'] great camera . \n",
      "['picture[+2]'] it takes great pictures . \n",
      "['camera[+3]'] i got this camera about a month ago and i can 't put it down . \n",
      "['camera[+2]'] but this camera is great ! \n",
      "['8mb card[-2]'] i only have one complaint , and that is the 8mb card included . \n",
      "['feature[+2]'] 1 it has all the features an amatuer photo-enthusiast would want . \n",
      "['price[+2]'] 10 great price for all the features . \n",
      "['firewire[-1]'] 1 no direct firewire to the camera . \n"
     ]
    }
   ],
   "source": [
    "label, pred = main_program(df['review'], df['target'], 'sentiwordnet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actu = pd.Series(label, name='Actual')\n",
    "y_pred = pd.Series(pred, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   1   2\n",
       "Actual           \n",
       "1          94  35\n",
       "2           8  23"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "cm = ConfusionMatrix(label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population: 0\n",
      "P: 0\n",
      "N: 0\n",
      "PositiveTest: 0\n",
      "NegativeTest: 0\n",
      "TP: 0\n",
      "TN: 0\n",
      "FP: 0\n",
      "FN: 0\n",
      "TPR: nan\n",
      "TNR: nan\n",
      "PPV: nan\n",
      "NPV: nan\n",
      "FPR: nan\n",
      "FDR: nan\n",
      "FNR: nan\n",
      "ACC: nan\n",
      "F1_score: nan\n",
      "MCC: nan\n",
      "informedness: nan\n",
      "markedness: nan\n",
      "prevalence: nan\n",
      "LRP: nan\n",
      "LRN: nan\n",
      "DOR: nan\n",
      "FOR: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:191: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TP) / self.P)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:213: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TN) / self.N)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:236: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TP) / self.PositiveTest)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:259: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TN) / self.NegativeTest)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:181: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FP) / self.N)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:267: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FP) / self.PositiveTest)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:276: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FN) / self.P)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:284: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TP + self.TN) / self.population)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:293: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(2 * np.float64(self.TP) / (2 * self.TP + self.FP + self.FN))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:302: RuntimeWarning: invalid value encountered in true_divide\n",
      "  * (self.TN + self.FP) * (self.TN + self.FN)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:323: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.P) / self.population)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas_ml\\confusion_matrix\\bcm.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FN) / self.NegativeTest)\n"
     ]
    }
   ],
   "source": [
    "cm.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great -0.0\n",
      "camera -0.0\n",
      ", 0\n",
      "great -0.0\n",
      "investment -0.0\n",
      "! 0\n",
      " 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_score('great camera , great investment ! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
