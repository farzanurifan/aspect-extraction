{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(name, load = False):\n",
    "    # read data\n",
    "    train = pd.read_csv(\"Results/\"+name+\".csv\")\n",
    "\n",
    "    if not load:\n",
    "        train.shape\n",
    "        train['label'].value_counts(normalize = True)\n",
    "        # remove URL's from train and test\n",
    "        train['clean_tweet'] = train['review'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "        # remove punctuation marks\n",
    "        punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "        train['clean_tweet'] = train['clean_tweet'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
    "\n",
    "        # convert text to lowercase\n",
    "        train['clean_tweet'] = train['clean_tweet'].str.lower()\n",
    "\n",
    "        # remove numbers\n",
    "        train['clean_tweet'] = train['clean_tweet'].str.replace(\"[0-9]\", \" \")\n",
    "\n",
    "        # remove whitespaces\n",
    "        train['clean_tweet'] = train['clean_tweet'].apply(lambda x:' '.join(x.split()))\n",
    "\n",
    "        # import spaCy's language model\n",
    "        nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "        # function to lemmatize text\n",
    "        def lemmatization(texts):\n",
    "            output = []\n",
    "            for i in texts:\n",
    "                s = [token.lemma_ for token in nlp(i)]\n",
    "                output.append(' '.join(s))\n",
    "            return output\n",
    "        def elmo_vectors(x):\n",
    "            embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "            print('---')\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                sess.run(tf.tables_initializer())\n",
    "                # return average of ELMo features\n",
    "                return sess.run(tf.reduce_mean(embeddings,1))\n",
    "        list_train = [train[i:i+100] for i in range(0,train.shape[0],100)]\n",
    "\n",
    "        # Extract ELMo embeddings\n",
    "        elmo_train = [elmo_vectors(x['clean_tweet']) for x in list_train]\n",
    "        elmo_train_new = np.concatenate(elmo_train, axis = 0)\n",
    "\n",
    "        # save elmo_train_new\n",
    "        pickle_out = open(\"elmo_train_\"+ name +\".pickle\",\"wb\")\n",
    "        pickle.dump(elmo_train_new, pickle_out)\n",
    "        pickle_out.close()\n",
    "    \n",
    "    # load elmo_train_new\n",
    "    print(\"elmo_train_\"+ name +\".pickle\")\n",
    "    pickle_in = open(\"elmo_train_\"+ name +\".pickle\", \"rb\")\n",
    "    elmo_train_new = pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    xtrain, xvalid, ytrain, yvalid = train_test_split(elmo_train_new, \n",
    "                                                      train['label'],  \n",
    "                                                      random_state=42, \n",
    "                                                      test_size=0.2)\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn import svm\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    lreg = LogisticRegression()\n",
    "#     lreg = GaussianNB()\n",
    "#     lreg = svm.LinearSVC()\n",
    "    lreg.fit(xtrain, ytrain)\n",
    "    preds_valid = lreg.predict(xvalid)\n",
    "    return yvalid, preds_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "---\n",
      "elmo_train_FOOD.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "    positive       0.85      1.00      0.92        29\n",
      "\n",
      "   micro avg       0.86      0.86      0.86        36\n",
      "   macro avg       0.93      0.64      0.68        36\n",
      "weighted avg       0.88      0.86      0.83        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y, Y = run('FOOD', False)\n",
    "print(classification_report(y, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "---\n",
      "elmo_train_AMBIENCE.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.20      0.33         5\n",
      "    positive       0.81      1.00      0.89        17\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        22\n",
      "   macro avg       0.90      0.60      0.61        22\n",
      "weighted avg       0.85      0.82      0.77        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y, Y = run('AMBIENCE', False)\n",
    "print(classification_report(y, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "---\n",
      "elmo_train_SERVICE.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.40      0.57        10\n",
      "    positive       0.71      1.00      0.83        15\n",
      "\n",
      "   micro avg       0.76      0.76      0.76        25\n",
      "   macro avg       0.86      0.70      0.70        25\n",
      "weighted avg       0.83      0.76      0.73        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y, Y = run('SERVICE', False)\n",
    "print(classification_report(y, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "elmo_train_PRICES.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      1.00      0.80         6\n",
      "    positive       1.00      0.70      0.82        10\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        16\n",
      "   macro avg       0.83      0.85      0.81        16\n",
      "weighted avg       0.88      0.81      0.81        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y, Y = run('PRICES', False)\n",
    "print(classification_report(y, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
