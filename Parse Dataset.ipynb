{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "f = open('dataset/bing_liu/Nikon coolpix 4300.txt', 'r')\n",
    "\n",
    "pattern_title = '\\[t\\]'\n",
    "pattern_sentence = '(?<=##).+'\n",
    "pattern_aspect = '.+(?=##)'\n",
    "pattern_aspect_anomali = '\\[(u|p|s|cc|cs)\\]'\n",
    "\n",
    "sentences = []\n",
    "review = []\n",
    "count = 0\n",
    "for a in f:\n",
    "    if re.search('##', a):\n",
    "        sentence = re.findall(pattern_sentence, a)[0]\n",
    "        aspect = re.findall(pattern_aspect, a)\n",
    "#         anomali = re.findall(pattern_aspect_anomali, a)\n",
    "#         if anomali:\n",
    "#             print(sentence, aspect)\n",
    "#         else:\n",
    "        if len(aspect) > 0:\n",
    "            aspect = aspect[0]\n",
    "        else:\n",
    "            aspect = ''\n",
    "        sentences.append((sentence, aspect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['review','aspect'])\n",
    "for r in sentences:\n",
    "    df = df.append({'review': r[0], 'aspect': r[1]}, ignore_index=True)\n",
    "df.to_csv(\"nikon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"SentiCircle/nokia.txt\",\"w+\")\n",
    "for i in sentences:\n",
    "     f.write(i + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et \n",
    "def parse_laptop(filename, isMultipleCategories=False):\n",
    "    df_cols = [\"reviewID\", \"sentenceID\", \"review\", \"category\", \"polarity\"]\n",
    "    out_df = pd.DataFrame(columns = df_cols)\n",
    "\n",
    "    xtree_train = et.parse(filename)\n",
    "    xroot_train = xtree_train.getroot()\n",
    "\n",
    "    for node in xroot_train: \n",
    "        rid = node.attrib.get('rid')\n",
    "        sentences = node.find('sentences') if node is not None else None\n",
    "        for sentence in sentences:\n",
    "            sid = sentence.attrib.get('id')\n",
    "            text = sentence.find('text').text if sentence is not None else None\n",
    "            opinions = sentence.find('Opinions') if sentence is not None else []\n",
    "            if opinions is not None:\n",
    "                categories = []\n",
    "                polarities = []\n",
    "                for opinion in opinions:\n",
    "                    categories.append(opinion.attrib.get('category'))\n",
    "                    polarities.append(opinion.attrib.get('polarity'))\n",
    "                if not isMultipleCategories:\n",
    "                    out_df = out_df.append(pd.Series([rid, sid, text, categories[0], polarities[0]], \n",
    "                                        index = df_cols), \n",
    "                            ignore_index = True)\n",
    "                else:\n",
    "                    out_df = out_df.append(pd.Series([rid, sid, text, ','.join(categories), ','.join(polarities)], \n",
    "                                        index = df_cols), \n",
    "                            ignore_index = True)\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_laptop_single = parse_laptop(\"dataset/ABSA16/ABSA16_Laptops_Train_SB1_v2.xml\")\n",
    "res_df_laptop_multiple = parse_laptop(\"dataset/ABSA16/ABSA16_Laptops_Train_SB1_v2.xml\", True)\n",
    "\n",
    "res_df_laptop_single.to_csv('dataset/laptop-single-train.csv', index=False)\n",
    "res_df_laptop_multiple.to_csv('dataset/laptop-multiple-train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_laptop_single = parse_laptop(\"dataset/ABSA15_RestaurantsTrain/ABSA-15_Restaurants_Train_Final.xml\")\n",
    "res_df_laptop_multiple = parse_laptop(\"dataset/ABSA15_RestaurantsTrain/ABSA-15_Restaurants_Train_Final.xml\", True)\n",
    "\n",
    "res_df_laptop_single.to_csv('dataset/restaurant-single-test.csv', index=False)\n",
    "res_df_laptop_multiple.to_csv('dataset/restaurant-multiple-test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
