{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk import Tree\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "import json\n",
    "import nltk\n",
    "from nltk.sem.logic import *\n",
    "import requests\n",
    "\n",
    "read_expr = nltk.sem.Expression.fromstring\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "dependency_parser = nlp.annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(expression):\n",
    "    old = expression.replace(' ', '_').replace('>_(', '> (').replace(')_(', ') (').replace(')_)', ') )').replace(')_)', ') )').replace(' (', '(')\n",
    "    new = ''\n",
    "    flag = False\n",
    "    for x in range(0, len(old) - 1):        \n",
    "        if old[x] == '<':\n",
    "            flag = True\n",
    "        if old[x] == '>':\n",
    "            flag = False\n",
    "            \n",
    "        if flag == True:\n",
    "            if old[x] == '(':\n",
    "                new += '{'\n",
    "            elif old[x] == ')':\n",
    "                new += '}'\n",
    "            else:\n",
    "                new += old[x]\n",
    "        else:\n",
    "            new += old[x]\n",
    "    new += old[len(old)-1]\n",
    "    return new\n",
    "\n",
    "def pos_tag(sentence):\n",
    "    result = dependency_parser(sentence, properties={\"outputFormat\": \"json\", \"annotators\": \"pos\"})['sentences'][0]['tokens']\n",
    "    res = []\n",
    "    for pos in result:\n",
    "        res.append(pos['pos'])\n",
    "    return res\n",
    "\n",
    "\n",
    "def insert_pos_tag(exp, pos):\n",
    "    count = 0\n",
    "    res = ''\n",
    "    for x in range(0, len(exp)):\n",
    "        if exp[x] == 'S' and exp[x+1]==' ' and exp[x+2] == 'P':\n",
    "            res += 'S '\n",
    "            res += pos[count]\n",
    "            count += 1\n",
    "            x += 4\n",
    "        else:\n",
    "            res += exp[x]\n",
    "    return res\n",
    "\n",
    "\n",
    "def direction(exp):\n",
    "    cont = False\n",
    "    for x in exp:\n",
    "        if x == '{':\n",
    "            cont = True\n",
    "        elif x == '}':\n",
    "            cont = False\n",
    "            continue\n",
    "        if cont == True:\n",
    "            continue\n",
    "        if x == '/':\n",
    "            return '/'\n",
    "        elif x == '\\\\':\n",
    "            return '\\\\'\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_type_raising(tree):\n",
    "    tree_string = str(tree)\n",
    "    \n",
    "    # check type raising\n",
    "    exp = tree_string.split('_')[1]\n",
    "    pattern_1 = r'(.*?)\\\\(.*?){(.*?)/(.*?)}'\n",
    "    pattern_2 = r'(.*?)/(.*?){(.*?)\\\\(.*?)}'\n",
    "    \n",
    "    match = False\n",
    "    if re.search(pattern_1, exp):\n",
    "        match = True\n",
    "    elif re.search(pattern_2, exp):\n",
    "        match = True\n",
    "        \n",
    "    sub = []\n",
    "    for subtree in tree:\n",
    "        sub.append(subtree)\n",
    "    if len(sub) == 1 and match:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def score(tree):\n",
    "    tree_string = str(tree)\n",
    "#     print(tree_string)\n",
    "    if tree_string[2] == 'L':\n",
    "        pos = tree_string.split('_')[3]\n",
    "        word = tree_string.split('_')[5]\n",
    "        \n",
    "        #                        #\n",
    "        # masukin rulenya disini #\n",
    "        #                        #\n",
    "        if 'JJ' in pos:\n",
    "            return '10_'\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "identity = lambda x: x   \n",
    "\n",
    "def lambda_calculus(tree):\n",
    "    tree_string = str(tree)\n",
    "    \n",
    "    if tree_string[2] == 'L':\n",
    "        pos = tree_string.split('_')[3]\n",
    "        word = tree_string.split('_')[5]\n",
    "        #                        #\n",
    "        # masukin rulenya disini #\n",
    "        #                        #\n",
    "        r_word = ['PRP', 'FW', 'NN', 'LS']\n",
    "        if pos == 'CC':\n",
    "            return read_expr(r'CC')\n",
    "        elif pos in r_word:\n",
    "            return read_expr(word + '_' + pos + '_' + 'N' + '_' + '0')\n",
    "        elif 'JJ' in pos:\n",
    "            return read_expr(word + '_' + 'JJ' + '_' + 'P' + '_' + '2')\n",
    "        elif 'VB' in pos:\n",
    "            if '{S[dcl]\\\\NP}/{S[adj]\\\\NP}' in tree_string.split('_')[1]:\n",
    "                return read_expr(r'\\x.x')\n",
    "            else:\n",
    "                return read_expr(r'\\X.' + word + '(X)')\n",
    "        else:\n",
    "            return read_expr(r'\\x.x')\n",
    "    \n",
    "    # ini cuma masukin ke array \n",
    "    chunk = []\n",
    "    sub = []\n",
    "    \n",
    "    for subtree in tree:\n",
    "        if type(subtree) == nltk.tree.Tree:\n",
    "            sub.append(subtree)\n",
    "            \n",
    "            # chunk temp array\n",
    "            subtree_str_array = str(subtree).split('_')\n",
    "            if subtree_str_array[0][2] == 'L':\n",
    "                if subtree_str_array[3] == 'NN':\n",
    "                    chunk.append(subtree_str_array[5])\n",
    "    \n",
    "    \n",
    "    # chunk noun phrase\n",
    "    if len(chunk) == 2:\n",
    "        chunk_str = '+'.join(chunk)\n",
    "        return read_expr(r'(' + chunk_str + ')')\n",
    "    \n",
    "    # error anak 1\n",
    "    if len(sub) == 1:            \n",
    "        return lambda_calculus(sub[0])\n",
    "                        \n",
    "    # urutan operasi lambda calculusnya    \n",
    "    first = sub[0]\n",
    "    second = sub[1]\n",
    "    \n",
    "    if is_type_raising(first):\n",
    "        if direction(str(first).split('_')[1]) == '/':\n",
    "            x = read_expr(r'\\F x.F(x, ' + str(lambda_calculus(first)) + ')')\n",
    "            y = lambda_calculus(second)\n",
    "            return ApplicationExpression(x, y).simplify()\n",
    "    \n",
    "    if is_type_raising(second):\n",
    "        if direction(str(second).split('_')[1]) == '/':\n",
    "            x = lambda_calculus(first)\n",
    "            y = read_expr(r'\\F x.F(x, ' + str(lambda_calculus(second)) + ')')\n",
    "            return ApplicationExpression(x, y).simplify()\n",
    "    \n",
    "        \n",
    "    length_1 = len(str(sub[0]).split('_')[1].replace('\\\\', '/').split('/'))\n",
    "    length_2 = len(str(sub[1]).split('_')[1].replace('\\\\', '/').split('/'))\n",
    "    if length_2 > length_1:\n",
    "        first = sub[1]\n",
    "        second = sub[0]\n",
    "    # rekursi\n",
    "    return deduction(lambda_calculus(first), lambda_calculus(second))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glue_process(sent):\n",
    "    url = \"http://localhost:5000/ccgParsing\"\n",
    "    data = {\"sent\": sent}\n",
    "    r = requests.post(url, data=data)\n",
    "\n",
    "    res = r.json()\n",
    "    \n",
    "    from_res = res['tree']\n",
    "    pos_tagged = insert_pos_tag(from_res, pos_tag(data['sent']))\n",
    "\n",
    "    hasil = parser(pos_tagged)\n",
    "\n",
    "    tree = Tree.fromstring(hasil)\n",
    "    return lambda_calculus(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduction(a, b):\n",
    "    str_a = str(a)\n",
    "    str_b = str(b)\n",
    "    \n",
    "    #change identity function for adjective\n",
    "    if(re.search(r'JJ.*', str_a) and re.search(r'NN.*', str_b)):\n",
    "        adjective_score = str_a.split('_')[3]\n",
    "        def mapFunction(data):\n",
    "            idx, x = data\n",
    "            return adjective_score if idx == 3 else x\n",
    "        \n",
    "        str_b = '_'.join( list(map(mapFunction, enumerate(str_b.split('_')))) )\n",
    "        a = read_expr(r'\\x.x')\n",
    "        b = read_expr(str_b)\n",
    "    elif(re.search(r'JJ.*', str_a)):\n",
    "        a = read_expr(r'\\x.x')\n",
    "        a = read_expr(str_a)\n",
    "    #change identity function for adverb\n",
    "\n",
    "    if(str_a == 'CC'):\n",
    "        print('m')\n",
    "        pass\n",
    "    if(re.search(r'CC\\(', str_a)):\n",
    "        a = read_expr(r'\\x.x')\n",
    "        b = read_expr(replacer(str_a, str_b))\n",
    "        \n",
    "    str_a = str(a)\n",
    "    str_b = str(b)\n",
    "    print('a ' + str_a)\n",
    "    print('b ' + str_b)\n",
    "    print('hasil ' + str(ApplicationExpression(a, b).simplify()))\n",
    "    return ApplicationExpression(a, b).simplify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(a, b):\n",
    "    pattern = '(.*?_JJ_.*?_)'\n",
    "    end_pos = len(re.findall(pattern, a)[0]) + 1\n",
    "    start_pos = 0\n",
    "    for x in range(0, end_pos):\n",
    "        if a[x] == '(' or a[x] == ',':\n",
    "            start_pos = x + 1\n",
    "    temp = ''\n",
    "    for x in range(start_pos, end_pos):\n",
    "        temp += a[x]\n",
    "    print(a,b, temp)\n",
    "    res = str(a).replace(str(temp), str(b))\n",
    "    print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glue_process('the breakfast that the restaurant served daily was excellent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a \\x.x\n",
      "b satisfied_JJ_P_2\n",
      "hasil satisfied_JJ_P_2\n",
      "a \\x.x\n",
      "b satisfied_JJ_P_2\n",
      "hasil satisfied_JJ_P_2\n",
      "a satisfied_JJ_P_2\n",
      "b i_FW_N_0\n",
      "hasil satisfied_JJ_P_2(i_FW_N_0)\n",
      "a \\X.say(X)\n",
      "b satisfied_JJ_P_2(i_FW_N_0)\n",
      "hasil say(satisfied_JJ_P_2(i_FW_N_0))\n",
      "a \\x.x\n",
      "b say(satisfied_JJ_P_2(i_FW_N_0))\n",
      "hasil say(satisfied_JJ_P_2(i_FW_N_0))\n",
      "a \\X.have(X)\n",
      "b say(satisfied_JJ_P_2(i_FW_N_0))\n",
      "hasil have(say(satisfied_JJ_P_2(i_FW_N_0)))\n",
      "a have(say(satisfied_JJ_P_2(i_FW_N_0)))\n",
      "b i_FW_N_0\n",
      "hasil have(say(satisfied_JJ_P_2(i_FW_N_0)),i_FW_N_0)\n",
      "m\n",
      "a CC\n",
      "b have(say(satisfied_JJ_P_2(i_FW_N_0)),i_FW_N_0)\n",
      "hasil CC(have(say(satisfied_JJ_P_2(i_FW_N_0)),i_FW_N_0))\n",
      "a \\x.x\n",
      "b canon+g3\n",
      "hasil canon+g3\n",
      "a \\X.bought(X)\n",
      "b canon+g3\n",
      "hasil bought(canon+g3)\n",
      "a bought(canon+g3)\n",
      "b i_LS_N_0\n",
      "hasil bought(canon+g3,i_LS_N_0)\n",
      "CC(have(say(satisfied_JJ_P_2(i_FW_N_0)),i_FW_N_0)) bought(canon+g3,i_LS_N_0) satisfied_JJ_P_2\n",
      "CC(have(say(bought(canon+g3,i_LS_N_0)(i_FW_N_0)),i_FW_N_0))\n",
      "a \\x.x\n",
      "b CC(have(say(bought(canon+g3,i_LS_N_0,i_FW_N_0)),i_FW_N_0))\n",
      "hasil CC(have(say(bought(canon+g3,i_LS_N_0,i_FW_N_0)),i_FW_N_0))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ApplicationExpression CC(have(say(bought(canon+g3,i_LS_N_0,i_FW_N_0)),i_FW_N_0))>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_process('i bought my canon g3 and i have to say i am very satisfied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = lambda a: lambda b: a + '(' + b + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have(seat)'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb('have')('seat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rr = i_a('restaurant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambek:\n",
    "    def __init__(self, word, score, pos):\n",
    "        ## private varibale or property in Python\n",
    "        self.__word = word\n",
    "        self.__score = score\n",
    "        self.__pos = pos\n",
    "        \n",
    "    def get_word(self):\n",
    "        return self.__word\n",
    "    \n",
    "    def get_score(self):\n",
    "        return self.__score\n",
    "    \n",
    "    def set_score(self, score):\n",
    "        self.__score = score\n",
    "    \n",
    "    def get_pos(self):\n",
    "        return self.__pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakfast = Lambek('breakfast', 0, 'NN')\n",
    "restaurant = Lambek('restaurant', 0, 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii = i_a(breakfast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rr = i_a(restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "served = Lambek('served', 0, 'VB')\n",
    "daily = Lambek('daily', 1, 'RB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = change_identity(daily)(served)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "served.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'served(daily)'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb('served')('daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_function(l):\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_i = lambda x: x\n",
    "c_i('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import isfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isfunction(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ApplicationExpression.variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\\\x', 'P(x)']\n"
     ]
    }
   ],
   "source": [
    "v = read_expr(r'\\x.P(x)')\n",
    "#v = read_expr(r'\\x.x')\n",
    "print(str(v).split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = map(lambda x: adjective_score if i == 3 else x, [1,2,3,4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "for i,w in enumerate(['1', '2', '3']):\n",
    "    print(i, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC(have(say(bought(canon+g3,i_LS_N_0)(i_FW_N_0)),i_FW_N_0))'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'CC(have(say(satisfied_JJ_P_2(i_FW_N_0)),i_FW_N_0))'\n",
    "b = 'bought(canon+g3,i_LS_N_0)'\n",
    "c = 'satisfied_JJ_P_2'\n",
    "\n",
    "a.replace(c,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
