{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "positive_lexicon = []\n",
    "negative_lexicon = []\n",
    "\n",
    "def read_lexicon():\n",
    "    global positive_lexicon;\n",
    "    global negative_lexicon;\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('../opinion-lexicon-English/') , 'positive-words.txt'), 'r') as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "         \n",
    "        positive_lexicon = file.readlines()\n",
    "    \n",
    "    with open(os.path.join(os.path.abspath('../opinion-lexicon-English/') , 'negative-words.txt'), 'r', encoding = \"ISO-8859-1\") as file:\n",
    "        line = file.readline();\n",
    "        while \";\" in line:\n",
    "            line = file.readline();\n",
    "        \n",
    "        negative_lexicon = file.readlines()\n",
    "        \n",
    "    positive_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), positive_lexicon))\n",
    "    negative_lexicon = list(map(lambda word: word.rstrip(\"\\n\\r\"), negative_lexicon))\n",
    "    \n",
    "        \n",
    "read_lexicon()\n",
    "op_set = positive_lexicon + negative_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sf = pd.DataFrame(columns=['reviewID', 'sentenceID', 'review', 'target', 'category', 'polarity'])\n",
    "df = pd.read_csv('../dataset/res16_nan_all.csv')\n",
    "categories = {}\n",
    "count = 0\n",
    "f_count, a_count, s_count, p_count = 0, 0, 0, 0\n",
    "for index in range(0, len(df)):\n",
    "    category = df['category'][index].split(',')\n",
    "    ncat = []\n",
    "    sent_temp = []\n",
    "    target = df['target'][index]\n",
    "    \n",
    "    is_food, is_service, is_ambience, is_price = False, False, False, False\n",
    "    for c in category:\n",
    "        if c == \"FOOD\":\n",
    "            is_food = True\n",
    "        elif c == \"PRICES\":\n",
    "            is_price = True\n",
    "        elif c == \"AMBIENCE\":\n",
    "            is_ambience = True\n",
    "        elif c == \"SERVICE\":\n",
    "            is_service = True\n",
    "        if c not in sent_temp:\n",
    "            try:\n",
    "                categories[c] += 1\n",
    "            except:\n",
    "                categories[c] = 1\n",
    "        sent_temp.append(c)\n",
    "        \n",
    "    if is_price:\n",
    "        sf = sf.append({'reviewID': df['reviewID'][index],\n",
    "                            'sentenceID': df['sentenceID'][index],\n",
    "                            'review': df['review'][index],\n",
    "                            'target': df['target'][index],\n",
    "                            'category': df['category'][index],\n",
    "                            'polarity': df['polarity'][index]}, ignore_index=True)\n",
    "\n",
    "        if is_food:\n",
    "            f_count += 1\n",
    "        if is_ambience:\n",
    "            a_count += 1\n",
    "        if is_service:\n",
    "            s_count += 1\n",
    "        if is_price:\n",
    "            p_count += 1\n",
    "            \n",
    "for index in range(0, len(df)):\n",
    "    category = df['category'][index].split(',')\n",
    "    ncat = []\n",
    "    sent_temp = []\n",
    "    target = df['target'][index]\n",
    "    sentence =  df['review'][index].lower().replace('  ', ' ').strip()\n",
    "    tokenized = sentence.split(' ')\n",
    "    \n",
    "    is_food, is_service, is_ambience, is_price = False, False, False, False\n",
    "    for c in category:\n",
    "        if c == \"FOOD\":\n",
    "            is_food = True\n",
    "        elif c == \"PRICES\":\n",
    "            is_price = True\n",
    "        elif c == \"AMBIENCE\":\n",
    "            is_ambience = True\n",
    "        elif c == \"SERVICE\":\n",
    "            is_service = True\n",
    "        if c not in sent_temp:\n",
    "            try:\n",
    "                categories[c] += 1\n",
    "            except:\n",
    "                categories[c] = 1\n",
    "        sent_temp.append(c)\n",
    "    \n",
    "#     is_dp = False\n",
    "#     print(sentence)\n",
    "#     for token in tokenized:\n",
    "#         if token in op_set:\n",
    "#             is_dp = rule(sentence, token)\n",
    "#             break\n",
    "            \n",
    "    if not is_price: #and is_dp:\n",
    "        if f_count > 129 and is_food:\n",
    "            continue\n",
    "        if a_count > 129 and is_ambience:\n",
    "            continue\n",
    "        if s_count > 129 and is_service:\n",
    "            continue\n",
    "\n",
    "        sf = sf.append({'reviewID': df['reviewID'][index],\n",
    "                            'sentenceID': df['sentenceID'][index],\n",
    "                            'review': df['review'][index],\n",
    "                            'target': df['target'][index],\n",
    "                            'category': df['category'][index],\n",
    "                            'polarity': df['polarity'][index]}, ignore_index=True)\n",
    "\n",
    "        if (is_food and is_service) and is_ambience:\n",
    "            f_count += 1\n",
    "            s_count += 1\n",
    "            a_count += 1\n",
    "        elif (is_food and is_service) and not is_ambience:\n",
    "            f_count += 1\n",
    "            s_count += 1\n",
    "        elif (is_food and is_ambience) and not is_service:\n",
    "            f_count += 1\n",
    "            a_count += 1\n",
    "        elif (is_service and is_ambience) and not is_food:\n",
    "            s_count += 1\n",
    "            a_count += 1\n",
    "        elif (is_food) and not (is_price):\n",
    "            f_count += 1\n",
    "        elif (is_ambience) and not (is_price):\n",
    "            a_count += 1\n",
    "        elif (is_service) and not (is_price):\n",
    "            s_count += 1            \n",
    "\n",
    "sf.to_csv(\"dataset/res16_baru.csv\")\n",
    "sf.to_excel(\"dataset/res16_baru.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dataset/res16_baru.csv')\n",
    "categories = {}\n",
    "count = 0\n",
    "for index, cat in enumerate(df['category']):\n",
    "    count+=1\n",
    "    category = cat.split(',')\n",
    "    ncat = []\n",
    "    sent_temp = []\n",
    "    target = df['target'][index]\n",
    "    for c in category:\n",
    "        x = c#.split('#')[0]\n",
    "        if x not in sent_temp:\n",
    "            try:\n",
    "                categories[x] += 1\n",
    "            except:\n",
    "                categories[x] = 1\n",
    "        sent_temp.append(x)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMBIENCE': 130, 'FOOD': 130, 'PRICES': 130, 'SERVICE': 130}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMBIENCE': 130, 'FOOD': 130, 'PRICES': 130, 'SERVICE': 130}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://localhost:9000/semgrex\"\n",
    "\n",
    "conj_DP = ['conj']\n",
    "dep_DP = ['amod', 'prep', 'nsubj', 'csubj', 'xsubj', 'dobj', 'iobj']\n",
    "\n",
    "def req_semgrex(params, text):\n",
    "    r = requests.post(url, data = text, params=params)\n",
    "    return r.json()\n",
    "\n",
    "def rule(text, key):\n",
    "    for dep in dep_DP:\n",
    "        r = req_semgrex({\"pattern\": \"{word:\"+ key +\"} <\"+ dep +\" {}\"}, text)\n",
    "        print('-')\n",
    "        length = r['sentences'][0]['length']\n",
    "        if length:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule('good food', 'food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "\n",
    "parser = CoreNLPDependencyParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule(sentence, key):\n",
    "    parse = next(parser.raw_parse(sentence))\n",
    "    for (w1, dep, w2) in list(parse.triples()):\n",
    "        word1 = w1[0]\n",
    "        word2 = w2[0]\n",
    "        if word1 == key or word2 == key:\n",
    "            if dep in dep_DP:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
