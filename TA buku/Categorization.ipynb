{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model '../../model_wiki'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f61aa83b3fdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mglove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../glove.6B.300d.w2vformat.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mw2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../../model_wiki\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model '../../model_wiki'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove = KeyedVectors.load_word2vec_format('../../glove.6B.300d.w2vformat.txt')\n",
    "w2v = KeyedVectors.load_word2vec_format('../../GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# nlp = spacy.load(\"../../model_wiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def cosine(x, y):\n",
    "    dataSetI = x\n",
    "    dataSetII = y\n",
    "    return 1 - spatial.distance.cosine(dataSetI, dataSetII)\n",
    "\n",
    "import string\n",
    "def rem_punct(word):\n",
    "    return word.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_category(category, tipe):\n",
    "    pickle_in = open(\"../elmo_category/\"+ tipe + '/' + category +\".pickle\", \"rb\")\n",
    "    return pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def similarity(category, word):\n",
    "    res = []\n",
    "    for cat in category:\n",
    "        res.append(cosine(cat, word))\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_result(word):\n",
    "    c1 = similarity(ambience, word)\n",
    "    c2 = similarity(food, word)\n",
    "    c3 = similarity(service, word)\n",
    "    c4 = similarity(value, word)\n",
    "    return c1, c2, c3, c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_str(a, b, c, d):\n",
    "    if a > b and a > c and a > d:\n",
    "        return 1\n",
    "    elif b > a and b > c and b > d:\n",
    "        return 2\n",
    "    elif c > b and c > a and c > d:\n",
    "        return 3\n",
    "    elif d > b and d > c and d > a:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "\n",
    "def similarity(category, word):\n",
    "    res = []\n",
    "    for cat in category:\n",
    "        res.append(cosine(cat, word))\n",
    "    return np.mean(res)\n",
    "\n",
    "def sim_result(word):\n",
    "    c1 = similarity(ambience, word)\n",
    "    c2 = similarity(food, word)\n",
    "    c3 = similarity(service, word)\n",
    "    c4 = similarity(value, word)\n",
    "    return c1, c2, c3, c4\n",
    "\n",
    "def cat_str(a, b, c, d):\n",
    "    if a > b and a > c and a > d:\n",
    "        return 1\n",
    "    elif b > a and b > c and b > d:\n",
    "        return 2\n",
    "    elif c > b and c > a and c > d:\n",
    "        return 3\n",
    "    elif d > b and d > c and d > a:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "def str_cat(num):\n",
    "    pred =''\n",
    "    if num == 1:\n",
    "        pred = 'AMBIENCE'\n",
    "    elif num == 2:\n",
    "        pred = 'FOOD'\n",
    "    elif num == 3:\n",
    "        pred = 'SERVICE'\n",
    "    elif num == 4:\n",
    "        pred = 'PRICES'\n",
    "    return pred\n",
    "\n",
    "def run(tipe, tipe_keluar, where, sim):\n",
    "    ambience = load_category('ambience', sim)\n",
    "    food = load_category('food', sim)\n",
    "    service = load_category('service', sim)\n",
    "    value = load_category('price', sim)\n",
    "    \n",
    "    df = pd.read_csv('output.csv')\n",
    "    sf = pd.DataFrame(columns=['id', 'review', 'target', 'label', 'predict', 'term', 'polarity'])\n",
    "    for index in tqdm_notebook(range(len(df))):\n",
    "        pred= ''\n",
    "        pred_mult=[]\n",
    "        if type(df['term'][index]) != float:\n",
    "            terms = df['term'][index].lower().split('|')\n",
    "            target = df['target'][index]\n",
    "            id_file = df['id'][index]\n",
    "            label = df['category'][index]\n",
    "            review = df['review'][index]\n",
    "            polarity = df['polarity'][index]\n",
    "\n",
    "            tokenized = df['review'][index].lower().replace('  ', ' ').strip().split(' ')\n",
    "\n",
    "            for term in terms:\n",
    "                term_t = ''\n",
    "                if term == '':\n",
    "                    continue\n",
    "                else:\n",
    "                    term_t = term.split('!')[0]\n",
    "                i = 0\n",
    "                for token in tokenized:\n",
    "                    if term_t in token:\n",
    "                        if sim == 'fasttext':\n",
    "                            a, b, c, d = sim_result(nlp(rem_punct(token)).vector)\n",
    "                        elif sim == 'w2v':\n",
    "                            try:\n",
    "                                a, b, c, d = sim_result(w2v[rem_punct(token)])\n",
    "                            except:\n",
    "                                a, b, c, d = 0, 0, 0, 0\n",
    "                        elif sim == 'glove':\n",
    "                            try:\n",
    "                                a, b, c, d = sim_result(glove[rem_punct(token)])\n",
    "                            except:\n",
    "                                a, b, c, d = 0, 0, 0, 0\n",
    "\n",
    "                        x = cat_str(a, b, c, d)\n",
    "                        pred_mult.append(str_cat(x))\n",
    "                        break\n",
    "                    i += 1\n",
    "        else:\n",
    "            terms = ''\n",
    "            target = df['target'][index]\n",
    "            id_file = df['id'][index]\n",
    "            label = df['category'][index]\n",
    "            polarity = df['polarity'][index]\n",
    "            review = df['review'][index]\n",
    "            \n",
    "        sf = sf.append({'id': id_file,\n",
    "                        'review': review,\n",
    "                        'target': target,\n",
    "                        'label': label,\n",
    "                        'predict': '|'.join(pred_mult),\n",
    "                        'term': '|'.join(terms),\n",
    "                        'polarity': polarity\n",
    "                       }, ignore_index=True)\n",
    "\n",
    "        sf.to_csv(\"Results/Categorization/output-w2v.csv\")\n",
    "        sf.to_excel(\"Results/Categorization/output-w2v.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run('dp', '-fasttext', 'ATE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run('dp-partial', '-w2v', 'add_noun/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a9ffb132b3476aa6c958d131e45af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=358), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run('dp-partial-ner', '-w2v', 'Filter/', 'w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
