{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "nltk_words = set(nltk.corpus.stopwords.words('english'))\n",
    "stop_words = []\n",
    "for word in nltk_words:\n",
    "    stop_words.append(word.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "def preprocess(sentence):\n",
    "    res = sentence.lower()\n",
    "    res = res.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokenized_words = nltk.word_tokenize(res)\n",
    "    res = [word for word in tokenized_words if word not in stop_words]\n",
    "    res = [lemmatizer.lemmatize(r) for r in res]\n",
    "    res = [re.sub(r\"[^A-Za-z]+\", '', r) for r in res]\n",
    "    res = [r for r in res if len(r) > 3]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviewID</th>\n",
       "      <th>sentenceID</th>\n",
       "      <th>review</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>entity</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>type_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RL#3</td>\n",
       "      <td>RL#3:1</td>\n",
       "      <td>I am not necessarily fanatical about this plac...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>positive</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>i am not necessarily fanatical about this plac...</td>\n",
       "      <td>compound_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id reviewID sentenceID                                             review  \\\n",
       "0   0     RL#3     RL#3:1  I am not necessarily fanatical about this plac...   \n",
       "1   2     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "2   3     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "3   4     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "4   5     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "\n",
       "       category  polarity entity  \\\n",
       "0  VALUE#PRICES  positive  VALUE   \n",
       "1  VALUE#PRICES  negative  VALUE   \n",
       "2  VALUE#PRICES  negative  VALUE   \n",
       "3  VALUE#PRICES  negative  VALUE   \n",
       "4  VALUE#PRICES  negative  VALUE   \n",
       "\n",
       "                               preprocessed_sentence      type_sentence  \n",
       "0  i am not necessarily fanatical about this plac...  compound_sentence  \n",
       "1  the high prices you 're going to pay is for th...   complex_sentence  \n",
       "2  the high prices you 're going to pay is for th...   complex_sentence  \n",
       "3  the high prices you 're going to pay is for th...   complex_sentence  \n",
       "4  the high prices you 're going to pay is for th...   complex_sentence  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('res_mul_all.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for sentence in df['review']:\n",
    "    tokens = preprocess(sentence)\n",
    "    text_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 20, id2word=dictionary, random_state = 42)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely', 'always', 'amazing', 'appropriate', 'atmosphere', 'away', 'bagel', 'beautiful', 'best', 'bland', 'cant', 'casual', 'caviar', 'cozy', 'decor', 'delicious', 'dish', 'enjoy', 'even', 'ever', 'excellent', 'family', 'filet', 'fish', 'flavorful', 'food', 'fresh', 'friendly', 'garden', 'going', 'good', 'great', 'high', 'lamb', 'like', 'lobster', 'made', 'meal', 'moderate', 'never', 'nice', 'outside', 'pasta', 'pizza', 'place', 'plentiful', 'portion', 'price', 'reasonably', 'recommend', 'relaxed', 'restaurant', 'rice', 'roll', 'rude', 'salad', 'sandwich', 'selection', 'service', 'spicy', 'staff', 'sushi', 'tempura', 'terrible', 'time', 'treated', 'value', 'view', 'waiter', 'want', 'well', 'wonderful', 'world', 'worth', 'would']\n"
     ]
    }
   ],
   "source": [
    "all_topics = []\n",
    "for topic in topics:\n",
    "    for pair in topic[1].split(' + '):\n",
    "        word = pair.split('*')[1].replace(\"\\\"\", '')\n",
    "        all_topics.append(word)\n",
    "print(sorted(list(dict.fromkeys(all_topics))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely', 'always', 'amazing', 'appropriate', 'atmosphere', 'away', 'bagel', 'beautiful', 'best', 'bland', 'cant', 'casual', 'caviar', 'cozy', 'decor', 'delicious', 'dish', 'enjoy', 'even', 'ever', 'excellent', 'family', 'filet', 'fish', 'flavorful', 'food', 'fresh', 'friendly', 'garden', 'going', 'good', 'great', 'high', 'lamb', 'like', 'lobster', 'made', 'meal', 'moderate', 'never', 'nice', 'outside', 'pasta', 'pizza', 'place', 'plentiful', 'portion', 'price', 'reasonably', 'recommend', 'relaxed', 'restaurant', 'rice', 'roll', 'rude', 'salad', 'sandwich', 'selection', 'service', 'spicy', 'staff', 'sushi', 'tempura', 'terrible', 'time', 'treated', 'value', 'view', 'waiter', 'want', 'well', 'wonderful', 'world', 'worth', 'would']\n"
     ]
    }
   ],
   "source": [
    "all_topics = []\n",
    "for topic in topics:\n",
    "    for pair in topic[1].split(' + '):\n",
    "        word = pair.split('*')[1].replace(\"\\\"\", '')\n",
    "        all_topics.append(word)\n",
    "print(sorted(list(dict.fromkeys(all_topics))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def aspect_topic(all_topics):\n",
    "    sf = pd.DataFrame(columns=['id','review','category','term'])\n",
    "    count = 0\n",
    "    index = 0\n",
    "    res = []\n",
    "    for sentence in df['review']:\n",
    "        lowercased = sentence.lower()\n",
    "        term = []\n",
    "        category = []\n",
    "        for cat in df['category'][index].split(','):\n",
    "            category.append(cat.split('#')[0])\n",
    "        id_name = df['id'][index]\n",
    "        for topic in all_topics:\n",
    "            if topic in lowercased:\n",
    "                term.append(topic)\n",
    "#         print(term)\n",
    "        if len(term) == 0:\n",
    "            print(sentence)\n",
    "            count += 1\n",
    "        sf = sf.append({'id': id_name, 'review': sentence.strip().lower().replace('  ', ' '), 'category': '|'.join(category), 'term': '|'.join(term)}, ignore_index=True)\n",
    "        index += 1\n",
    "    print(count)\n",
    "    sf.to_csv(\"lda.csv\")\n",
    "    sf.to_excel(\"lda.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hostess is rude to the point of being offensive.\n",
      "First went here to enjoy their garden terrace.\n",
      "Took my mom for Mother's Day, and the maitre d' was pretty rude.\n",
      "The tuna and wasabe potatoes are bad.\n",
      "Their tuna tartar appetizer is to die for.\n",
      "The dining room is quietly elegant with no music to shout over -- how refreshing!\n",
      "The menu is very limited - i think we counted 4 or 5 entrees.\n",
      "Delivery is fast too.\n",
      "Thius is a must for anyone who loves Shabu-Shabu.\n",
      "Taxan horrible!\n",
      "I had the worst ravioli ever.\n",
      "Whether it's the parmesean porcini souffle or the lamb glazed with balsamic vinegar, you will surely be transported to Northern Italy with one bite.\n",
      "I had their eggs benedict for brunch, which were the worst in my entire life, I tried removing the hollondaise sauce completely that was how failed it was.\n",
      "And the Tom Kha soup was pathetic.\n",
      "We had the lobster sandwich and it was fantastic.\n",
      "Mizu is home to creative and unique rolls not to found anywhere else.\n",
      "I ordered the smoked salmon and roe appetizer and it was off flavor.\n",
      "I expected quite a bit more from such an expensive menu.\n",
      "Their calzones are horrific, bad, vomit-inducing, YUCK.\n",
      "The dosas are skimpy, unattractive and drip with grease, and personally I'd drink popcorn topping before I'd eat another one of these.\n",
      "Unique apppetizers.\n",
      "The location is perfect.\n",
      "if you're daring, try the balsamic vinegar over icecream, it's wonderful!\n",
      "The lamb was tender so full of flavor, the dessert was divine!!\n",
      "Dessert is a joke...dont bother\n",
      "Cozy romantic atomosphere with only around 15 tables at most.\n",
      "Delicate spices, onions, eggs and a kick-ass roti.\n",
      "Toons has recently been redone, so it's now a very attractive space.\n",
      "We recently decided to try this location, and to our delight, they have outdoor seating, perfect since I had my yorkie with me.\n",
      "Indoor was very cozy and cute.\n",
      "Yakitori (bbq meats) is tasty too.\n",
      "Personal pans are the perfect size for those hungry nights.\n",
      "There is a downside if you're ordering in -- the delivery guys have MAJOR attitude.\n",
      " Perfect location for those traveling in/out of the city by auto or bus\n",
      " The 8th Ave location was very convenient and while busy, wasn't packed\n",
      "The location in the heart of Manhattan adjacent to the Port Authority makes this an easy spot to grab a bite to eat\n",
      "Location is convienient to businesses, hotels and theaters\n",
      "  Boucherie is our new favorite neighborhood spot.\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "aspect_topic(list(dict.fromkeys(all_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I had the duck breast special on my last visit and it was not incredible.\n",
      "Once you step into Cosette, you're miraculously in a small, off-the-beaten path Parisian bistro.\n",
      "My wife had the fried shrimp which are huge and loved it.\n",
      "There was a small wait, but shorter than I expected.\n",
      "The tuna and wasabe potatoes are bad.\n",
      "Ingredients are organic which is a real plus for me.\n",
      "Their tuna tartar appetizer is to die for.\n",
      "The menu is very limited - i think we counted 4 or 5 entrees.\n",
      "We ordered the special, grilled branzino, that was so infused with bone, it was difficult to eat.\n",
      "Delivery is fast too.\n",
      "Thius is a must for anyone who loves Shabu-Shabu.\n",
      "Taxan horrible!\n",
      "I had their eggs benedict for brunch, which were the worst in my entire life, I tried removing the hollondaise sauce completely that was how failed it was.\n",
      "The seats are uncomfortable if you are sitting against the wall on wooden benches.\n",
      "(The asparagus, truffle oil, parmesan bruschetta is a winner!)\n",
      "And the Tom Kha soup was pathetic.\n",
      "I ordered the smoked salmon and roe appetizer and it was off flavor.\n",
      "I expected quite a bit more from such an expensive menu.\n",
      "Their calzones are horrific, bad, vomit-inducing, YUCK.\n",
      "The dosas are skimpy, unattractive and drip with grease, and personally I'd drink popcorn topping before I'd eat another one of these.\n",
      "Unique apppetizers.\n",
      "the turkey burgers are scary!\n",
      "The location is perfect.\n",
      "I LOVE their Thai\n",
      "Dessert is a joke...dont bother\n",
      "Delicate spices, onions, eggs and a kick-ass roti.\n",
      "Toons has recently been redone, so it's now a very attractive space.\n",
      "We recently decided to try this location, and to our delight, they have outdoor seating, perfect since I had my yorkie with me.\n",
      "I fell in love with the egg noodles in the beef broth with shrimp dumplings and slices of BBQ roast pork.\n",
      "Yakitori (bbq meats) is tasty too.\n",
      "The only problem is that the manager is a complete incompetent.\n",
      "Personal pans are the perfect size for those hungry nights.\n",
      "There is a downside if you're ordering in -- the delivery guys have MAJOR attitude.\n",
      " Perfect location for those traveling in/out of the city by auto or bus\n",
      " The 8th Ave location was very convenient and while busy, wasn't packed\n",
      "The location in the heart of Manhattan adjacent to the Port Authority makes this an easy spot to grab a bite to eat\n",
      "Location is convienient to businesses, hotels and theaters\n",
      "  Boucherie is our new favorite neighborhood spot.\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "aspect_topic(list(dict.fromkeys(all_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
