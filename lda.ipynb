{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "nltk_words = set(nltk.corpus.stopwords.words('english'))\n",
    "stop_words = []\n",
    "for word in nltk_words:\n",
    "    stop_words.append(word.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "def preprocess(sentence):\n",
    "    res = sentence.lower()\n",
    "    res = res.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokenized_words = nltk.word_tokenize(res)\n",
    "    res = [word for word in tokenized_words if word not in stop_words]\n",
    "    res = [lemmatizer.lemmatize(r) for r in res]\n",
    "    res = [re.sub(r\"[^A-Za-z]+\", '', r) for r in res]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviewID</th>\n",
       "      <th>sentenceID</th>\n",
       "      <th>review</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>entity</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>type_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RL#3</td>\n",
       "      <td>RL#3:1</td>\n",
       "      <td>I am not necessarily fanatical about this plac...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>positive</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>i am not necessarily fanatical about this plac...</td>\n",
       "      <td>compound_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id reviewID sentenceID                                             review  \\\n",
       "0   0     RL#3     RL#3:1  I am not necessarily fanatical about this plac...   \n",
       "1   2     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "2   3     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "3   4     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "4   5     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "\n",
       "       category  polarity entity  \\\n",
       "0  VALUE#PRICES  positive  VALUE   \n",
       "1  VALUE#PRICES  negative  VALUE   \n",
       "2  VALUE#PRICES  negative  VALUE   \n",
       "3  VALUE#PRICES  negative  VALUE   \n",
       "4  VALUE#PRICES  negative  VALUE   \n",
       "\n",
       "                               preprocessed_sentence      type_sentence  \n",
       "0  i am not necessarily fanatical about this plac...  compound_sentence  \n",
       "1  the high prices you 're going to pay is for th...   complex_sentence  \n",
       "2  the high prices you 're going to pay is for th...   complex_sentence  \n",
       "3  the high prices you 're going to pay is for th...   complex_sentence  \n",
       "4  the high prices you 're going to pay is for th...   complex_sentence  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('res_mul_all.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for sentence in df['review']:\n",
    "    tokens = preprocess(sentence)\n",
    "    text_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 30, id2word=dictionary, random_state = 42)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, '0.054*\"food\" + 0.027*\"high\" + 0.027*\"price\" + 0.018*\"pay\" + 0.018*\"get\" + 0.018*\"always\" + 0.018*\"really\" + 0.018*\"going\" + 0.018*\"terrible\" + 0.018*\"portion\"')\n",
      "\n",
      "(29, '0.030*\"relaxed\" + 0.024*\"friendly\" + 0.024*\"atmosphere\" + 0.024*\"service\" + 0.024*\"casual\" + 0.018*\"fast\" + 0.018*\"great\" + 0.012*\"new\" + 0.012*\"duck\" + 0.012*\"world\"')\n",
      "\n",
      "(7, '0.027*\"place\" + 0.020*\"food\" + 0.014*\"fish\" + 0.014*\"price\" + 0.014*\"cream\" + 0.014*\"really\" + 0.014*\"reasonably\" + 0.014*\"like\" + 0.014*\"mahi\" + 0.014*\"flavorful\"')\n",
      "\n",
      "(1, '0.028*\"food\" + 0.019*\"best\" + 0.017*\"try\" + 0.017*\"service\" + 0.011*\"pleasant\" + 0.011*\"bad\" + 0.011*\"decor\" + 0.011*\"atmosphere\" + 0.011*\"nice\" + 0.011*\"staff\"')\n",
      "\n",
      "(13, '0.068*\"food\" + 0.049*\"price\" + 0.032*\"high\" + 0.023*\"bad\" + 0.019*\"staff\" + 0.014*\"bagel\" + 0.014*\"great\" + 0.009*\"going\" + 0.009*\"always\" + 0.009*\"way\"')\n",
      "\n",
      "(2, '0.034*\"like\" + 0.020*\"food\" + 0.014*\"cool\" + 0.014*\"sea\" + 0.014*\"better\" + 0.014*\"sushi\" + 0.014*\"served\" + 0.014*\"taste\" + 0.014*\"would\" + 0.009*\"french\"')\n",
      "\n",
      "(4, '0.030*\"food\" + 0.022*\"attentive\" + 0.022*\"price\" + 0.022*\"atmosphere\" + 0.022*\"bad\" + 0.015*\"tasty\" + 0.015*\"high\" + 0.015*\"goat\" + 0.015*\"good\" + 0.015*\"place\"')\n",
      "\n",
      "(17, '0.048*\"atmosphere\" + 0.046*\"food\" + 0.029*\"casual\" + 0.029*\"price\" + 0.029*\"relaxed\" + 0.019*\"flavorful\" + 0.019*\"plentiful\" + 0.019*\"reasonably\" + 0.017*\"service\" + 0.016*\"pizza\"')\n",
      "\n",
      "(3, '0.062*\"food\" + 0.026*\"view\" + 0.026*\"service\" + 0.021*\"price\" + 0.016*\"pay\" + 0.016*\"relaxed\" + 0.016*\"bad\" + 0.016*\"good\" + 0.016*\"casual\" + 0.016*\"high\"')\n",
      "\n",
      "(26, '0.024*\"place\" + 0.018*\"time\" + 0.018*\"always\" + 0.018*\"food\" + 0.018*\"great\" + 0.012*\"u\" + 0.012*\"price\" + 0.012*\"one\" + 0.012*\"service\" + 0.011*\"little\"')\n",
      "\n",
      "(16, '0.082*\"food\" + 0.023*\"good\" + 0.023*\"great\" + 0.019*\"service\" + 0.017*\"price\" + 0.015*\"sushi\" + 0.015*\"bad\" + 0.015*\"bland\" + 0.015*\"get\" + 0.011*\"small\"')\n",
      "\n",
      "(25, '0.122*\"great\" + 0.049*\"place\" + 0.046*\"value\" + 0.035*\"service\" + 0.033*\"food\" + 0.026*\"price\" + 0.013*\"plentiful\" + 0.013*\"reasonably\" + 0.013*\"flavorful\" + 0.010*\"dinner\"')\n",
      "\n",
      "(23, '0.047*\"great\" + 0.028*\"service\" + 0.019*\"decor\" + 0.019*\"good\" + 0.019*\"place\" + 0.019*\"food\" + 0.010*\"size\" + 0.010*\"personal\" + 0.010*\"hostess\" + 0.010*\"wine\"')\n",
      "\n",
      "(20, '0.037*\"good\" + 0.027*\"food\" + 0.021*\"great\" + 0.016*\"drink\" + 0.016*\"u\" + 0.016*\"place\" + 0.016*\"service\" + 0.011*\"lunch\" + 0.011*\"pizza\" + 0.011*\"dish\"')\n",
      "\n",
      "(24, '0.049*\"great\" + 0.034*\"food\" + 0.024*\"place\" + 0.019*\"good\" + 0.015*\"nice\" + 0.015*\"price\" + 0.010*\"id\" + 0.010*\"though\" + 0.010*\"decor\" + 0.010*\"dish\"')\n",
      "\n",
      "(15, '0.034*\"price\" + 0.030*\"service\" + 0.020*\"pizza\" + 0.020*\"great\" + 0.014*\"rice\" + 0.014*\"even\" + 0.014*\"salty\" + 0.014*\"terrific\" + 0.014*\"food\" + 0.010*\"impeccable\"')\n",
      "\n",
      "(22, '0.075*\"great\" + 0.048*\"food\" + 0.031*\"place\" + 0.027*\"value\" + 0.024*\"service\" + 0.017*\"\" + 0.017*\"menu\" + 0.014*\"good\" + 0.014*\"limited\" + 0.011*\"sushi\"')\n",
      "\n",
      "(5, '0.022*\"service\" + 0.017*\"atmosphere\" + 0.017*\"food\" + 0.013*\"ever\" + 0.013*\"worst\" + 0.013*\"get\" + 0.013*\"place\" + 0.011*\"menu\" + 0.009*\"would\" + 0.009*\"selection\"')\n",
      "\n",
      "(18, '0.061*\"food\" + 0.039*\"price\" + 0.035*\"atmosphere\" + 0.028*\"relaxed\" + 0.028*\"casual\" + 0.024*\"good\" + 0.024*\"high\" + 0.016*\"view\" + 0.016*\"going\" + 0.016*\"pay\"')\n",
      "\n",
      "(27, '0.045*\"food\" + 0.031*\"price\" + 0.018*\"reasonably\" + 0.018*\"plentiful\" + 0.018*\"atmosphere\" + 0.018*\"flavorful\" + 0.013*\"\" + 0.013*\"like\" + 0.013*\"staff\" + 0.013*\"amazing\"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in topics:\n",
    "    print(a)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = []\n",
    "for topic in topics:\n",
    "    for pair in topic[1].split(' + '):\n",
    "        word = pair.split('*')[1].replace(\"\\\"\", '')\n",
    "        all_topics.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def aspect_topic(all_topics):\n",
    "    sf = pd.DataFrame(columns=['id','review','category','term'])\n",
    "    count = 0\n",
    "    index = 0\n",
    "    res = []\n",
    "    for sentence in df['review']:\n",
    "        lowercased = sentence.lower()\n",
    "        term = []\n",
    "        category = []\n",
    "        for cat in df['category'][index].split(','):\n",
    "            category.append(cat.split('#')[0])\n",
    "        id_name = df['id'][index]\n",
    "        for topic in all_topics:\n",
    "            if topic in lowercased:\n",
    "                term.append(topic)\n",
    "#         print(term)\n",
    "        if len(term) == 0:\n",
    "            print(sentence)\n",
    "            count += 1\n",
    "        sf = sf.append({'id': id_name, 'review': sentence.strip().lower().replace('  ', ' '), 'category': '|'.join(category), 'term': '|'.join(term)}, ignore_index=True)\n",
    "        index += 1\n",
    "    print(count)\n",
    "    sf.to_csv(\"lda.csv\")\n",
    "    sf.to_excel(\"lda.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "aspect_topic(list(dict.fromkeys(all_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(dict.fromkeys(all_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
