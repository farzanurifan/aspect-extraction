{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import time\n",
    "import shelve\n",
    "\n",
    "import chainer\n",
    "from chainer import cuda\n",
    "from chainer import serializers\n",
    "import chainer.optimizers as O\n",
    "import numpy as np\n",
    "\n",
    "from lda2vec import utils\n",
    "from lda2vec import prepare_topics, print_top_words_per_topic, topic_coherence\n",
    "from lda2vec import LDA2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_id = int(os.getenv('CUDA_GPU', 0))\n",
    "# cuda.get_device(gpu_id).use()\n",
    "# print(\"Using GPU:\" + str(gpu_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = os.getenv('data_dir', '../data/')\n",
    "fn_vocab = 'res/vocab.pkl'\n",
    "fn_corpus = 'res/corpus.pkl'\n",
    "fn_flatnd = 'res/flattened.npy'\n",
    "fn_docids = 'res/doc_ids.npy'\n",
    "fn_vectors = 'res/vectors.npy'\n",
    "vocab = pickle.load(open(fn_vocab, 'rb'))\n",
    "corpus = pickle.load(open(fn_corpus, 'rb'))\n",
    "flattened = np.load(fn_flatnd)\n",
    "doc_ids = np.load(fn_docids)\n",
    "vectors = np.load(fn_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "# Number of documents\n",
    "n_docs = doc_ids.max() + 1\n",
    "# Number of unique words in the vocabulary\n",
    "n_vocab = flattened.max() + 1\n",
    "# 'Strength' of the dircihlet prior; 200.0 seems to work well\n",
    "clambda = 200.0\n",
    "# Number of topics to fit\n",
    "n_topics = int(os.getenv('n_topics', 20))\n",
    "batchsize = 4096\n",
    "# Power for neg sampling\n",
    "power = float(os.getenv('power', 0.75))\n",
    "# Intialize with pretrained word vectors\n",
    "pretrained = bool(int(os.getenv('pretrained', True)))\n",
    "# Sampling temperature\n",
    "temperature = float(os.getenv('temperature', 1.0))\n",
    "# Number of dimensions in a single word vector\n",
    "n_units = int(os.getenv('n_units', 300))\n",
    "# Get the string representation for every compact key\n",
    "words = corpus.word_list(vocab)[:n_vocab]\n",
    "# How many tokens are in each document\n",
    "doc_idx, lengths = np.unique(doc_ids, return_counts=True)\n",
    "doc_lengths = np.zeros(doc_ids.max() + 1, dtype='int32')\n",
    "doc_lengths[doc_idx] = lengths\n",
    "# Count all token frequencies\n",
    "tok_idx, freq = np.unique(flattened, return_counts=True)\n",
    "term_frequency = np.zeros(n_vocab, dtype='int32')\n",
    "term_frequency[tok_idx] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in sorted(locals().keys()):\n",
    "#     val = locals()[key]\n",
    "#     if len(str(val)) < 100 and '<' not in str(val):\n",
    "#         print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LDA2Vec(n_documents=n_docs, n_document_topics=n_topics,\n",
    "                n_units=n_units, n_vocab=n_vocab, counts=term_frequency,\n",
    "                n_samples=20, power=power, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists('lda2vec.hdf5'):\n",
    "#     print(\"Reloading from saved\")\n",
    "#     serializers.load_hdf5(\"lda2vec.hdf5\", model)\n",
    "\n",
    "# if pretrained:\n",
    "#     model.sampler.W.data[:, :] = vectors[:n_vocab, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to_gpu()\n",
    "optimizer = O.Adam()\n",
    "optimizer.setup(model)\n",
    "clip = chainer.optimizer.GradientClipping(5.0)\n",
    "optimizer.add_hook(clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "epoch = 0\n",
    "fraction = batchsize * 1.0 / flattened.shape[0]\n",
    "progress = shelve.open('res/progress.shelve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in topic 0 make out_of_vocabulary never overpriced service place ambience decor rude would\n",
      "Top words in topic 1 pizza would best out_of_vocabulary delicious dish atmosphere sushi friendly good\n",
      "Top words in topic 2 worth make feel dinner like best though <SKIP> service restaurant\n",
      "Top words in topic 3 menu good reasonable though well food feel always make sushi\n",
      "Top words in topic 4 menu fresh wine service back place thing dinner friendly sushi\n",
      "Top words in topic 5 really worth dinner place out_of_vocabulary romantic back overpriced like out_of_vocabulary\n",
      "Top words in topic 6 ambience make place always friendly excellent atmosphere menu overpriced nice\n",
      "Top words in topic 7 great romantic always back place out_of_vocabulary fresh best nice make\n",
      "Top words in topic 8 romantic always delicious dinner nice wait would out_of_vocabulary menu special\n",
      "Top words in topic 9 excellent always thing fresh feel wine back restaurant food never\n",
      "Top words in topic 10 price dinner sushi nice good friendly overpriced wait feel like\n",
      "Top words in topic 11 wine rude place delicious out_of_vocabulary best nice feel great friendly\n",
      "Top words in topic 12 staff friendly food wine place overpriced always service fresh well\n",
      "Top words in topic 13 dinner reasonable menu would meal nice out_of_vocabulary place feel excellent\n",
      "Top words in topic 14 dinner staff price would worth fresh always thing atmosphere well\n",
      "Top words in topic 15 really fresh well delicious nice dish meal great atmosphere back\n",
      "Top words in topic 16 time overpriced dish well rude ambience restaurant menu wine price\n",
      "Top words in topic 17 out_of_vocabulary back place dish food great price make feel thing\n",
      "Top words in topic 18 dinner time staff delicious meal <SKIP> wait menu atmosphere best\n",
      "Top words in topic 19 romantic time pizza like restaurant would good feel friendly out_of_vocabulary\n",
      "0\n",
      "after partial fitting: 50145.61\n",
      "J:00000 E:00000 L:5.015e+04 P:-2.630e+04 R:8.634e+03\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    data = prepare_topics(cuda.to_cpu(model.mixture.weights.W.data).copy(),\n",
    "                          cuda.to_cpu(model.mixture.factors.W.data).copy(),\n",
    "                          cuda.to_cpu(model.sampler.W.data).copy(),\n",
    "                          words)\n",
    "    top_words = print_top_words_per_topic(data)\n",
    "    if j % 100 == 0 and j > 100:\n",
    "        coherence = topic_coherence(top_words)\n",
    "        for j in range(n_topics):\n",
    "            print(j, coherence[(j, 'cv')])\n",
    "        kw = dict(top_words=top_words, coherence=coherence, epoch=epoch)\n",
    "        progress[str(epoch)] = pickle.dumps(kw)\n",
    "    data['doc_lengths'] = doc_lengths\n",
    "    data['term_frequency'] = term_frequency\n",
    "    np.savez('res/topics.pyldavis', **data)\n",
    "    print(epoch)\n",
    "    for d, f in utils.chunks(batchsize, doc_ids, flattened):\n",
    "        t0 = time.time()\n",
    "        model.cleargrads()\n",
    "        #optimizer.use_cleargrads(use=False)\n",
    "        l = model.fit_partial(d.copy(), f.copy())\n",
    "        print(\"after partial fitting:\", l)\n",
    "        prior = model.prior()\n",
    "        loss = prior * fraction\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        msg = (\"J:{j:05d} E:{epoch:05d} L:{loss:1.3e} \"\n",
    "               \"P:{prior:1.3e} R:{rate:1.3e}\")\n",
    "        prior.to_cpu()\n",
    "        loss.to_cpu()\n",
    "        t1 = time.time()\n",
    "        dt = t1 - t0\n",
    "        rate = batchsize / dt\n",
    "        logs = dict(loss=float(l), epoch=epoch, j=j,\n",
    "                    prior=float(prior.data), rate=rate)\n",
    "        print(msg.format(**logs))\n",
    "        j += 1\n",
    "    serializers.save_hdf5(\"res/lda2vec.hdf5\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SKIP>', 'always', 'ambience', 'atmosphere', 'back', 'best', 'decor', 'delicious', 'dinner', 'dish', 'excellent', 'feel', 'food', 'fresh', 'friendly', 'good', 'great', 'like', 'make', 'meal', 'menu', 'never', 'nice', 'out_of_vocabulary', 'overpriced', 'pizza', 'place', 'price', 'really', 'reasonable', 'restaurant', 'romantic', 'rude', 'service', 'special', 'staff', 'sushi', 'thing', 'though', 'time', 'wait', 'well', 'wine', 'worth', 'would']\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "all_topics = []\n",
    "for row in top_words:\n",
    "    for word in row:\n",
    "        all_topics.append(word)\n",
    "print(sorted(list(dict.fromkeys(all_topics))))\n",
    "print(len(sorted(list(dict.fromkeys(all_topics)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewID</th>\n",
       "      <th>sentenceID</th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:1</td>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>staff</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1004293</td>\n",
       "      <td>1004293:3</td>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>food,portions</td>\n",
       "      <td>FOOD,FOOD</td>\n",
       "      <td>negative,negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1014458</td>\n",
       "      <td>1014458:0</td>\n",
       "      <td>I have eaten at Saul, many times, the food is ...</td>\n",
       "      <td>food</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1014458</td>\n",
       "      <td>1014458:2</td>\n",
       "      <td>The duck confit is always amazing and the foie...</td>\n",
       "      <td>foie gras terrine with figs,duck confit</td>\n",
       "      <td>FOOD,FOOD</td>\n",
       "      <td>positive,positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1014458</td>\n",
       "      <td>1014458:3</td>\n",
       "      <td>The wine list is interesting and has many good...</td>\n",
       "      <td>wine list,wine list</td>\n",
       "      <td>FOOD,PRICES</td>\n",
       "      <td>positive,positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 reviewID sentenceID  \\\n",
       "0           0  1004293  1004293:1   \n",
       "1           1  1004293  1004293:3   \n",
       "2           2  1014458  1014458:0   \n",
       "3           3  1014458  1014458:2   \n",
       "4           4  1014458  1014458:3   \n",
       "\n",
       "                                              review  \\\n",
       "0  We, there were four of us, arrived at noon - t...   \n",
       "1  The food was lousy - too sweet or too salty an...   \n",
       "2  I have eaten at Saul, many times, the food is ...   \n",
       "3  The duck confit is always amazing and the foie...   \n",
       "4  The wine list is interesting and has many good...   \n",
       "\n",
       "                                    target     category           polarity  \n",
       "0                                    staff      SERVICE           negative  \n",
       "1                            food,portions    FOOD,FOOD  negative,negative  \n",
       "2                                     food         FOOD           positive  \n",
       "3  foie gras terrine with figs,duck confit    FOOD,FOOD  positive,positive  \n",
       "4                      wine list,wine list  FOOD,PRICES  positive,positive  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dataset/res16_baru.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def aspect_topic(tipe, all_topics):\n",
    "    sf = pd.DataFrame(columns=['id','review','target', 'category','term','polarity'])\n",
    "    count = 0\n",
    "    index = 0\n",
    "    res = []\n",
    "    for sentence in df['review']:\n",
    "        lowercased = sentence.lower()\n",
    "        term = []\n",
    "        category = []\n",
    "        polarity = df['polarity'][index]\n",
    "        category = df['category'][index]\n",
    "        id_name = df['sentenceID'][index]\n",
    "        target = df['target'][index]\n",
    "        for topic in all_topics:\n",
    "            tokens = lowercased.split(' ')\n",
    "            for token in tokens:\n",
    "                if topic in token:\n",
    "                    term.append(topic)\n",
    "#         print(term)\n",
    "        if len(term) == 0:\n",
    "            print(lowercased)\n",
    "            count += 1\n",
    "        sf = sf.append({'id': id_name,\n",
    "                        'review': sentence.strip().lower().replace('  ', ' '),\n",
    "                        'target': target,\n",
    "                        'category': category,\n",
    "                        'term': '|'.join(term),\n",
    "                        'polarity': polarity}, ignore_index=True)\n",
    "        index += 1\n",
    "    print(count)\n",
    "    sf.to_csv(\"../Results/Aspect Terms Extraction/\"+ tipe +\".csv\")\n",
    "    sf.to_excel(\"../Results/Aspect Terms Extraction/\"+ tipe +\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "their sake list was extensive, but we were looking for purple haze, which wasn't listed but made for us upon request!\n",
      "ambiance- relaxed and stylish.\n",
      "if you've ever been along the river in weehawken you have an idea of the top of view the chart house has to offer.\n",
      "the lava cake dessert was incredible and i recommend it.\n",
      "once you step into cosette, you're miraculously in a small, off-the-beaten path parisian bistro.\n",
      "my wife had the fried shrimp which are huge and loved it.\n",
      "a large is $20, and toppings are about $3 each.\n",
      "located at the end of a magnificent block.\n",
      "get the tuna of gari.\n",
      "try the crunchy tuna, it is to die for.\n",
      "first went here to enjoy their garden terrace.\n",
      "the bagel was huge.\n",
      "the workers there also absolutely load the bagel with cream cheese (gets a little messy).\n",
      "hats off to the chef.\n",
      "salads were fantastic.\n",
      "ingredients are organic which is a real plus for me.\n",
      "i started out with a bombay beer which was big enough for two.\n",
      "fish was overdone.\n",
      "someone else recommended the dessert - we also left that.\n",
      "their tuna tartar appetizer is to die for.\n",
      "delivery is fast too.\n",
      "zero ambiance to boot.\n",
      "the seats are uncomfortable if you are sitting against the wall on wooden benches.\n",
      "a gentleman, maybe the manager, came to our table, and without so much as a smile or greeting asked for our order.\n",
      "i asked for an open faced cheese sandwich and the manager basically told me to take my business elsewhere!\n",
      "the location is perfect.\n",
      "terrible, terrible management - deserves to be shut-down.\n",
      "still, any quibbles about the bill were off-set by the pour-your-own measures of liquers which were courtesey of the house...\n",
      "the drinks are amazing and half off till 8pm.\n",
      "toons has recently been redone, so it's now a very attractive space.\n",
      "we recently decided to try this location, and to our delight, they have outdoor seating, perfect since i had my yorkie with me.\n",
      "indoor was very cozy and cute.\n",
      "whoever the jazz duo was, they were on point.\n",
      "and $11 for a plate of bland guacamole?\n",
      "we were offered water for the table but were not told the voss bottles of water were $8 a piece.\n",
      "oh, and there's hookah.\n",
      "oh speaking of bathroom , the mens bathroom was disgusting.\n",
      "we were drawn into the belly dancing show that captivated the crowd.\n",
      "mazing interior.\n",
      "what you are paying for is the environment and the name.\n",
      "the environment is very upscale and you will see a lot of rich guys with trophy wives or just highly paid escorts.\n",
      "however, our $14 drinks were were horrible!\n",
      "too bad i had paid an extra $2 for the stone bowl.\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "aspect_topic(\"lda2vec\",list(dict.fromkeys(all_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
