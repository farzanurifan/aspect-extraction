{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import time\n",
    "import shelve\n",
    "\n",
    "import chainer\n",
    "from chainer import cuda\n",
    "from chainer import serializers\n",
    "import chainer.optimizers as O\n",
    "import numpy as np\n",
    "\n",
    "from lda2vec import utils\n",
    "from lda2vec import prepare_topics, print_top_words_per_topic, topic_coherence\n",
    "from lda2vec import LDA2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_id = int(os.getenv('CUDA_GPU', 0))\n",
    "# cuda.get_device(gpu_id).use()\n",
    "# print(\"Using GPU:\" + str(gpu_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = os.getenv('data_dir', '../data/')\n",
    "fn_vocab = 'res/vocab.pkl'\n",
    "fn_corpus = 'res/corpus.pkl'\n",
    "fn_flatnd = 'res/flattened.npy'\n",
    "fn_docids = 'res/doc_ids.npy'\n",
    "fn_vectors = 'res/vectors.npy'\n",
    "vocab = pickle.load(open(fn_vocab, 'rb'))\n",
    "corpus = pickle.load(open(fn_corpus, 'rb'))\n",
    "flattened = np.load(fn_flatnd)\n",
    "doc_ids = np.load(fn_docids)\n",
    "vectors = np.load(fn_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "# Number of documents\n",
    "n_docs = doc_ids.max() + 1\n",
    "# Number of unique words in the vocabulary\n",
    "n_vocab = flattened.max() + 1\n",
    "# 'Strength' of the dircihlet prior; 200.0 seems to work well\n",
    "clambda = 200.0\n",
    "# Number of topics to fit\n",
    "n_topics = int(os.getenv('n_topics', 20))\n",
    "batchsize = 4096\n",
    "# Power for neg sampling\n",
    "power = float(os.getenv('power', 0.75))\n",
    "# Intialize with pretrained word vectors\n",
    "pretrained = bool(int(os.getenv('pretrained', True)))\n",
    "# Sampling temperature\n",
    "temperature = float(os.getenv('temperature', 1.0))\n",
    "# Number of dimensions in a single word vector\n",
    "n_units = int(os.getenv('n_units', 300))\n",
    "# Get the string representation for every compact key\n",
    "words = corpus.word_list(vocab)[:n_vocab]\n",
    "# How many tokens are in each document\n",
    "doc_idx, lengths = np.unique(doc_ids, return_counts=True)\n",
    "doc_lengths = np.zeros(doc_ids.max() + 1, dtype='int32')\n",
    "doc_lengths[doc_idx] = lengths\n",
    "# Count all token frequencies\n",
    "tok_idx, freq = np.unique(flattened, return_counts=True)\n",
    "term_frequency = np.zeros(n_vocab, dtype='int32')\n",
    "term_frequency[tok_idx] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in sorted(locals().keys()):\n",
    "#     val = locals()[key]\n",
    "#     if len(str(val)) < 100 and '<' not in str(val):\n",
    "#         print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LDA2Vec(n_documents=n_docs, n_document_topics=n_topics,\n",
    "                n_units=n_units, n_vocab=n_vocab, counts=term_frequency,\n",
    "                n_samples=20, power=power, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists('lda2vec.hdf5'):\n",
    "#     print(\"Reloading from saved\")\n",
    "#     serializers.load_hdf5(\"lda2vec.hdf5\", model)\n",
    "\n",
    "if pretrained:\n",
    "    model.sampler.W.data[:, :] = vectors[:n_vocab, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to_gpu()\n",
    "optimizer = O.Adam()\n",
    "optimizer.setup(model)\n",
    "clip = chainer.optimizer.GradientClipping(5.0)\n",
    "optimizer.add_hook(clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "epoch = 0\n",
    "fraction = batchsize * 1.0 / flattened.shape[0]\n",
    "progress = shelve.open('res/progress.shelve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in topic 0 atmosphere delicious great price out_of_vocabulary place value best good relaxed\n",
      "Top words in topic 1 relaxed atmosphere delicious out_of_vocabulary place out_of_vocabulary price pizza great food\n",
      "Top words in topic 2 relaxed good food delicious high value best pizza price service\n",
      "Top words in topic 3 out_of_vocabulary atmosphere best service out_of_vocabulary place high good food great\n",
      "Top words in topic 4 value atmosphere service high reasonably place out_of_vocabulary out_of_vocabulary <SKIP> good\n",
      "Top words in topic 5 out_of_vocabulary service <SKIP> great place delicious good high atmosphere reasonably\n",
      "Top words in topic 6 delicious value price pizza reasonably place great best service good\n",
      "Top words in topic 7 pizza food service atmosphere delicious place great good value price\n",
      "Top words in topic 8 out_of_vocabulary <SKIP> place food value price atmosphere best out_of_vocabulary pizza\n",
      "Top words in topic 9 pizza atmosphere relaxed <SKIP> delicious service high reasonably price value\n",
      "Top words in topic 10 pizza out_of_vocabulary out_of_vocabulary service high reasonably good place price value\n",
      "Top words in topic 11 pizza good great high out_of_vocabulary food reasonably price best out_of_vocabulary\n",
      "Top words in topic 12 great best out_of_vocabulary out_of_vocabulary relaxed place good value delicious reasonably\n",
      "Top words in topic 13 atmosphere out_of_vocabulary value best relaxed high place <SKIP> service good\n",
      "Top words in topic 14 value atmosphere pizza service place best out_of_vocabulary price reasonably high\n",
      "Top words in topic 15 atmosphere reasonably relaxed food <SKIP> good price high value out_of_vocabulary\n",
      "Top words in topic 16 food relaxed atmosphere <SKIP> place reasonably pizza out_of_vocabulary good price\n",
      "Top words in topic 17 food service out_of_vocabulary high price reasonably pizza <SKIP> atmosphere relaxed\n",
      "Top words in topic 18 high atmosphere out_of_vocabulary good <SKIP> reasonably place service great best\n",
      "Top words in topic 19 good reasonably best pizza price delicious value great high food\n",
      "0\n",
      "after partial fitting: 213.65532\n",
      "J:00000 E:00000 L:2.137e+02 P:-3.980e+04 R:7.898e+03\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    data = prepare_topics(cuda.to_cpu(model.mixture.weights.W.data).copy(),\n",
    "                          cuda.to_cpu(model.mixture.factors.W.data).copy(),\n",
    "                          cuda.to_cpu(model.sampler.W.data).copy(),\n",
    "                          words)\n",
    "    top_words = print_top_words_per_topic(data)\n",
    "    if j % 100 == 0 and j > 100:\n",
    "        coherence = topic_coherence(top_words)\n",
    "        for j in range(n_topics):\n",
    "            print(j, coherence[(j, 'cv')])\n",
    "        kw = dict(top_words=top_words, coherence=coherence, epoch=epoch)\n",
    "        progress[str(epoch)] = pickle.dumps(kw)\n",
    "    data['doc_lengths'] = doc_lengths\n",
    "    data['term_frequency'] = term_frequency\n",
    "    np.savez('res/topics.pyldavis', **data)\n",
    "    print(epoch)\n",
    "    for d, f in utils.chunks(batchsize, doc_ids, flattened):\n",
    "        t0 = time.time()\n",
    "        model.cleargrads()\n",
    "        #optimizer.use_cleargrads(use=False)\n",
    "        l = model.fit_partial(d.copy(), f.copy())\n",
    "        print(\"after partial fitting:\", l)\n",
    "        prior = model.prior()\n",
    "        loss = prior * fraction\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        msg = (\"J:{j:05d} E:{epoch:05d} L:{loss:1.3e} \"\n",
    "               \"P:{prior:1.3e} R:{rate:1.3e}\")\n",
    "        prior.to_cpu()\n",
    "        loss.to_cpu()\n",
    "        t1 = time.time()\n",
    "        dt = t1 - t0\n",
    "        rate = batchsize / dt\n",
    "        logs = dict(loss=float(l), epoch=epoch, j=j,\n",
    "                    prior=float(prior.data), rate=rate)\n",
    "        print(msg.format(**logs))\n",
    "        j += 1\n",
    "    serializers.save_hdf5(\"res/lda2vec.hdf5\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SKIP>', 'atmosphere', 'best', 'delicious', 'food', 'good', 'great', 'high', 'out_of_vocabulary', 'pizza', 'place', 'price', 'reasonably', 'relaxed', 'service', 'value']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "all_topics = []\n",
    "for row in top_words:\n",
    "    for word in row:\n",
    "        all_topics.append(word)\n",
    "print(sorted(list(dict.fromkeys(all_topics))))\n",
    "print(len(sorted(list(dict.fromkeys(all_topics)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviewID</th>\n",
       "      <th>sentenceID</th>\n",
       "      <th>review</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>entity</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>type_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RL#3</td>\n",
       "      <td>RL#3:1</td>\n",
       "      <td>I am not necessarily fanatical about this plac...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>positive</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>i am not necessarily fanatical about this plac...</td>\n",
       "      <td>compound_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TR#2</td>\n",
       "      <td>TR#2:2</td>\n",
       "      <td>The high prices you're going to pay is for the...</td>\n",
       "      <td>VALUE#PRICES</td>\n",
       "      <td>negative</td>\n",
       "      <td>VALUE</td>\n",
       "      <td>the high prices you 're going to pay is for th...</td>\n",
       "      <td>complex_sentence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id reviewID sentenceID                                             review  \\\n",
       "0   0     RL#3     RL#3:1  I am not necessarily fanatical about this plac...   \n",
       "1   2     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "2   3     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "3   4     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "4   5     TR#2     TR#2:2  The high prices you're going to pay is for the...   \n",
       "\n",
       "       category  polarity entity  \\\n",
       "0  VALUE#PRICES  positive  VALUE   \n",
       "1  VALUE#PRICES  negative  VALUE   \n",
       "2  VALUE#PRICES  negative  VALUE   \n",
       "3  VALUE#PRICES  negative  VALUE   \n",
       "4  VALUE#PRICES  negative  VALUE   \n",
       "\n",
       "                               preprocessed_sentence      type_sentence  \n",
       "0  i am not necessarily fanatical about this plac...  compound_sentence  \n",
       "1  the high prices you 're going to pay is for th...   complex_sentence  \n",
       "2  the high prices you 're going to pay is for th...   complex_sentence  \n",
       "3  the high prices you 're going to pay is for th...   complex_sentence  \n",
       "4  the high prices you 're going to pay is for th...   complex_sentence  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../res_mul_all.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def aspect_topic(tipe, all_topics):\n",
    "    sf = pd.DataFrame(columns=['id','review','category','term'])\n",
    "    count = 0\n",
    "    index = 0\n",
    "    res = []\n",
    "    for sentence in df['review']:\n",
    "        lowercased = sentence.lower()\n",
    "        term = []\n",
    "        category = []\n",
    "        for cat in df['category'][index].split(','):\n",
    "            splitted = cat.split('#')\n",
    "            if splitted[1] == 'PRICES':\n",
    "                category.append('VALUE')\n",
    "            else:\n",
    "                category.append(splitted[0])\n",
    "        id_name = df['id'][index]\n",
    "        for topic in all_topics:\n",
    "            tokens = lowercased.split(' ')\n",
    "            for token in tokens:\n",
    "                if token.startswith(topic):\n",
    "                    term.append(topic)\n",
    "#         print(term)\n",
    "        if len(term) == 0:\n",
    "            print(lowercased)\n",
    "            count += 1\n",
    "        sf = sf.append({'id': id_name, 'review': sentence.strip().lower().replace('  ', ' '), 'category': '|'.join(category), 'term': '|'.join(term)}, ignore_index=True)\n",
    "        index += 1\n",
    "    print(count)\n",
    "    sf.to_csv(\"../Results/Aspect Terms Extraction/\"+ tipe +\".csv\")\n",
    "    sf.to_excel(\"../Results/Aspect Terms Extraction/\"+ tipe +\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the duck confit is always amazing and the foie gras terrine with figs was out of this world.\n",
      "chow fun was dry; pork shu mai was more than usually greasy and had to share a table with loud and rude family. \n",
      "i had the duck breast special on my last visit and it was not incredible.\n",
      "the only thing i moderately enjoyed was their grilled chicken special with edamame puree.\n",
      "i had never had edamame pureed before but i thought it was innovative and tasty (could've used a bit more salt).\n",
      "i happen to have a policy that goes along with a little bit of self-respect, which includes not letting a waiter intimidate me, i.e. make me feel bad asking for trivialities like water, or the check.\n",
      "i tend to judge a sushi restaurant by its sea urchin, which was heavenly at sushi rose.\n",
      "the sushi seemed pretty fresh and was adequately proportioned.\n",
      "the prix fixe menu is worth every penny and you get more than enough (both in quantity and quality).\n",
      "i am not a vegetarian but, almost all the dishes were bad.\n",
      "i like the somosas, chai, and the chole, but the dhosas and dhal were kinda dissapointing.\n",
      "if you've ever been along the river in weehawken you have an idea of the top of view the chart house has to offer.\n",
      "the lava cake dessert was terrible.\n",
      "once you step into cosette, you're miraculously in a small, off-the-beaten path parisian bistro.\n",
      "this tiny restaurant is as cozy as it gets, with that certain parisian flair.\n",
      "i think i've had some the worst meals of my life at minnow.\n",
      "my wife had the fried shrimp which are huge and loved it.\n",
      "my wife and i always enjoy the young, not always well trained but nevertheless friendly, staff, all of whom have a story.\n",
      "the hostess is rude to the point of being offensive.\n",
      "we were worried we would have trouble getting in, but somehow managed to have a short wait.\n",
      "the people that work there are always so friendly you forget you are in new york sometimes.\n",
      "there was a small wait, but shorter than i expected.\n",
      "first went here to enjoy their garden terrace.\n",
      "admittedly some nights inside the restaurant were rather warm, but the open kitchen is part of the charm.\n",
      "moules were excellent, lobster ravioli was very salty!\n",
      "took my mom for mother's day, and the maitre d' was pretty rude.\n",
      "tiny dessert was $8.00...just plain overpriced for what it is.\n",
      "raga's is a romantic, cozy restaurant.\n",
      "the staff is incredibly helpful and attentive.\n",
      "i loved everythig about it-especially the shows and actors.\n",
      "our server was very helpful and friendly.\n",
      "the tuna and wasabe potatoes are bad.\n",
      "two complaints- their appetizer selection stinks, it would be nice to get some mozzarella sticks on the menu.\n",
      "fine dining restaurant quality.\n",
      "the staff is no nonsense.\n",
      "when i lived upstate for a while i would buy freeze the bagels and they would still be better than any else.\n",
      "traditional french decour was pleasant though the hall was rather noisy - the restaurant was full and we had to raise our voices to be able to maintain a conversation.\n",
      "seating is always prompt, though the restaurant does fill up in the evening.\n",
      "the bagel was small.\n",
      "the workers there also absolutely load the bagel with cream cheese (gets a little messy).\n",
      "the staff is absolutely professional!! \n",
      "my chow fun and chow see was really bland and oily.\n",
      "it's boring on the inside, and our sushi was pretty below average... the tuna was soggy and the other rolls had no flavor.\n",
      "we had pam's special fried fish and it was amazing.\n",
      "salads were bad.\n",
      "ingredients are organic which is a real plus for me.\n",
      "enjoyed a very nice caesar salad while my wife had arugula and goat cheese....both very tasty.\n",
      "we both opted for a pasta dish and pasta dish were served timely and fresh.\n",
      "we even had a visit from the manager who wanted to make sure we were enjoying ourselves.\n",
      "the hanger steak was like rubber and the tuna was flavorless not to mention it tasted like it had just been thawed.\n",
      "the filet mignon dish was superb!\n",
      "i like the ambience, it's very dark and original.\n",
      "the sushi is amazing!!! \n",
      "very affordable and excellent ambience!\n",
      "not one of our meals was edible - bland and/or made with weird rosemary or orange flavoring.\n",
      "fish was overdone.\n",
      "someone else recommended the dessert - we also left that.\n",
      "their tuna tartar appetizer is to die for.\n",
      "the dining room is quietly elegant with no music to shout over -- how refreshing!\n",
      "looking around, i saw a room full of new yorkers enjoying a real meal in a real restaurant, not a clubhouse of the fabulous trying to be seen.\n",
      "the portions are large and the servers always surprise us with a different starter.\n",
      "the menu is very limited - i think we counted 4 or 5 entrees.\n",
      "we ordered the special, grilled branzino, that was so infused with bone, it was difficult to eat.\n",
      "our family never expected such incredible entertainment in a restaurant.\n",
      "and really large portions.\n",
      "the staff was the friendliest that have seen in new york.\n",
      "the characters really make for an enjoyable experience.\n",
      "delivery is fast too.\n",
      "the bagels always warm, soft on the inside, crispy on the outside and enormous in size.\n",
      "the lox is always fresh too.\n",
      "thius is a must for anyone who loves shabu-shabu.\n",
      "taxan horrible!\n",
      "i had the worst ravioli ever.\n",
      "whether it's the parmesean porcini souffle or the lamb glazed with balsamic vinegar, you will surely be transported to northern italy with one bite.\n",
      "but the staff was so horrible to us.\n",
      "the hostess and the waitress were incredibly rude and did everything they could to rush us out.\n",
      "don't dine at tamarind for the vegetarian dishes, they are simply not up to par with the non-veg selections.\n",
      "the fish was not fresh and the rice tasted old and stale.\n",
      "quite frankly, this is some of the worst sushi i have ever tried.\n",
      "honestly the worst sushi my husband and i had in our entire lives.\n",
      "the all-u-can-eat sushi is definitely in very poor quality.\n",
      "limited menu, no-so-fresh ingredients, thinly-sliced fish, fall-apart rice. \n",
      "the only things u could really taste are the very salty soy sauce (even its low sodium), the vinegar-soaked rice, and the scallion on top of the fish. \n",
      "the waitstaffs are nice though.\n",
      "the dinner was ok, nothing i would have again.\n",
      "i had their eggs benedict for brunch, which were the worst in my entire life, i tried removing the hollondaise sauce completely that was how failed it was.\n",
      "also, the sandwiches (nearing $7) didn't come with anything like chips or a side.\n",
      "the seats are uncomfortable if you are sitting against the wall on wooden benches.\n",
      "fish is so very fresh.\n",
      "waitstaff are very friendly.\n",
      "the menu is limited but almost all of the dishes are excellent.\n",
      "truly the mark of an attentive waiter.\n",
      "i recommend the jelly fish, drunken chicken and the soupy dumplings, certainly the stir fry blue crab.\n",
      "(the asparagus, truffle oil, parmesan bruschetta is a winner!)\n",
      "the wait staff is very freindly, they make it feel like you're eating in a freindly little european town.\n",
      "after dinner the manager grabbed my boyfriend, asked him: where are you from...maybe you dont know how things work in america...and in the end stormed away almost teareyed yelling that tips are the only thing they survive on.\n",
      "we did tip, i guess the model/waitress just wanted more and complained to the manager.\n",
      "decor is charming.\n",
      "i would definitely recommend sea if you like thai cuisine!\n",
      "if the weather is nice, try to snag an outside table.\n",
      "the staff has been nice, but they seemed really stressed and the unisex bathroom needs to be cleaned more often.\n",
      "from the spectacular caviar to the hospitable waitstaff, i felt like royalty and enjoyed every second of it.\n",
      "fresh ingredients and everything is made to order.\n",
      "friendly staff that actually lets you enjoy your meal and the company you're with.\n",
      "we ate out in the back patio, which is worth it as it's cool and the music is hear well there.\n",
      "the buffet had a nice selection.\n",
      "i got an excellent piece of cheesecake and we had several other nice pastries.\n",
      "consequently, their burgers fell apart in their hands and made such a mess that they did'nt feel like finishing them.\n",
      "and the tom kha soup was pathetic.\n",
      "the back garden sitting area is very pleasant, where you can see their personal herb garden.\n",
      "we had the lobster sandwich and it was fantastic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are very particular about sushi and were both please with every choice which included: ceviche mix (special), crab dumplings, assorted sashimi, sushi and rolls, two types of sake, and the banana tempura.\n",
      "we were greeted promptly by the waiter who was very nice and cordial.\n",
      "the crust is thin, the ingredients are fresh and the staff is friendly.\n",
      "the menu has so many fish items and oysters.\n",
      "the fish was really,really fresh.\n",
      "the first time the sushi was outstanding, the second time it was a little bland.\n",
      "mizu is home to creative and unique rolls not to found anywhere else.\n",
      "i ordered the smoked salmon and roe appetizer and it was off flavor.\n",
      "the entree was bland and small, dessert was not inspired.\n",
      "i expected quite a bit more from such an expensive menu.\n",
      "the cold appetizer dishes taste like the way i remember them to taste when i was growing up in taiwan.\n",
      "kind, attentive wait staff.\n",
      "i really like both the scallops and the mahi mahi (on saffron risotto-yum!).\n",
      "their calzones are horrific, bad, vomit-inducing, yuck.\n",
      "the dosas are skimpy, unattractive and drip with grease, and personally i'd drink popcorn topping before i'd eat another one of these.\n",
      "the sandwiches are dry, tasteless and way overpriced.\n",
      "the restaurant looks out over beautiful green lawns to the hudson river and the statue of liberty.\n",
      "unique apppetizers.\n",
      "the cream cheeses are out of this world and i love that coffee!!\n",
      "the turkey burgers are scary!\n",
      "the sushi was awful!\n",
      "the rice was poor quality and was cooked so badly it was hard.\n",
      "furthermore, the rice had no seasoning, so the sushi was bland and disgusting.\n",
      "the fish was adequate, but inexpertly sliced.\n",
      "the location is perfect.\n",
      "the brioche and lollies as party favors is a cute and sweet touch to a most memorable meal.\n",
      "the wait staff is pleasant, fun, and for the most part gorgeous (in the wonderful aesthetic beautification way, not in that she's-way-cuter-than-me-that-b@#$* way).\n",
      "i love their thai\n",
      "i cannot imagine a friendlier staff working in a restaurant.\n",
      "the setting is casual and romantic.\n",
      "if you're daring, try the balsamic vinegar over icecream, it's wonderful!\n",
      "i choose to go with one of the special, the braised lamb shank in red wine, which was excellent.\n",
      "terrible, terrible management - deserves to be shut-down.\n",
      "their bagels are fine, but they are a little overcooked, and not really a 'special' bagel experience.\n",
      "the lamb was tender so full of flavor, the dessert was divine!!\n",
      "the waiter was attentive.\n",
      "dessert is a joke...dont bother\n",
      "the restaurant has a family feel, not least with regard to the portions which are enormous; the veal alone could have single-handedly solved third world famine.\n",
      "the anti-pasta was excellent, especially the calamari, as were the filling pasta mains.\n",
      "not the typical nyc gimmick theme restaurant.\n",
      "the shrimp scampi was excellent and the antipasti were plentiful.\n",
      "cozy romantic atomosphere with only around 15 tables at most.\n",
      "the porcini mushroom pasta special was tasteless, so was the seafood tagliatelle.\n",
      "i also recommend the rice dishes or the different varieties of congee (rice porridge).\n",
      "i can't wait for summer, when they serve outside on their gigantic patio.\n",
      "i have never had cheescake like this.\n",
      "warm and friendly in the winter and terrific outdoor seating in the warmer months.\n",
      "people are always friendly.\n",
      "the mussles were the fishiest things i've ever tasted, the seabass was bland, the goat cheese salad was missing the goat cheese, the penne w/ chicken had bones in it... it was disgusting.\n",
      "ask for usha, the nicest bartender in manhattan.\n",
      "i really recommend the very simple unda (egg) rolls.\n",
      "delicate spices, onions, eggs and a kick-ass roti.\n",
      "toons has recently been redone, so it's now a very attractive space.\n",
      "we recently decided to try this location, and to our delight, they have outdoor seating, perfect since i had my yorkie with me.\n",
      "indoor was very cozy and cute.\n",
      "staff is very accomodating.\n",
      "excellent dumplings served amid clean, chic decor.\n",
      "the decor is very simple but comfortable.\n",
      "the staff there is very attentive and down to earth.\n",
      "i fell in love with the egg noodles in the beef broth with shrimp dumplings and slices of bbq roast pork.\n",
      "this dish is my favorite and i always get it when i go there and never get tired of it.\n",
      "yakitori (bbq meats) is tasty too.\n",
      "we were seated outside and the waiter spilled red wine and hot tea on myself and my date.\n",
      "one would think we'd get an apology or complimentary drinks - instead, we got a snobby waiter wouldn't even take our order for 15 minutes and gave us lip when we asked him to do so.\n",
      "the only problem is that the manager is a complete incompetent.\n",
      "most of the servers are very attentive, friendly and quite attractive.\n",
      "personal pans are the perfect size for those hungry nights.\n",
      "there is a downside if you're ordering in -- the delivery guys have major attitude.\n",
      "never have i had such dramatic delivery guys (a lot of huffing and panting and muttering under breath b/c i live in a walkup) who always seem disappointed with their tips.\n",
      "the mussels were fantastic and so was the dessert...definitely going to be back very soon.\n",
      "over the years the host, vittorio, and his crew, have always treated me as family--although with all the business this not-so-little gem does, it amazing he's even able to remember a consistent but not-so-frequent visitor.\n",
      "i have to say i have never had a disappointing meal here.\n",
      "we could have made a meal of the yummy dumplings from the dumpling menu.\n",
      "nice view of river and nyc.\n",
      " perfect location for those traveling in/out of the city by auto or bus\n",
      " the 8th ave location was very convenient and while busy, wasn't packed\n",
      "the location in the heart of manhattan adjacent to the port authority makes this an easy spot to grab a bite to eat\n",
      " nice environment with a wide choice of beers\n",
      "location is convienient to businesses, hotels and theaters\n",
      "  boucherie is our new favorite neighborhood spot.\n",
      "191\n"
     ]
    }
   ],
   "source": [
    "aspect_topic(\"20\",list(dict.fromkeys(all_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
